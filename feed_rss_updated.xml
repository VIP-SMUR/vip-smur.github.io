<?xml version="1.0" encoding="UTF-8" ?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel> <title>Surrogate Modeling for Urban Regeneration (SMUR)</title><description>Project page of the SMUR Vertically Integrated Project at Georgia Tech.</description><link>https://vip-smur.github.io/</link><atom:link href="https://vip-smur.github.io/feed_rss_updated.xml" rel="self" type="application/rss+xml" /> <managingEditor>Patrick Kastner</managingEditor><docs>https://github.com/VIP-SMUR/vip-smur.github.io</docs><language>en</language> <pubDate>Mon, 15 Dec 2025 23:45:49 -0000</pubDate> <lastBuildDate>Mon, 15 Dec 2025 23:45:49 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.7</generator> <image> <url>https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Feed-icon.svg/128px-Feed-icon.svg.png</url> <title>Surrogate Modeling for Urban Regeneration (SMUR)</title> <link>https://vip-smur.github.io/</link> </image> <item> <title>24-Sp-Mobility-Seg</title> <description>&lt;h1 id=&#34;segregation-in-the-15-minute-city&#34;&gt;Segregation in the 15-Minute City&lt;/h1&gt; &lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt; &lt;p&gt;This notebook focuses on the concept of the 15-minute city and investigates segregation on a basis of mobility. In this notebook, 15-minute usage is defined as the proportion of consumption-related trips made within a 15-minute walk from a home. 15-minute access is defined as the number of essential amenities within the 15-minute walk from a home. Segregation is examined within this context to measure and assess the distribution of amenities within urban areas.&lt;/p&gt; &lt;h2 id=&#34;notebook-summary&#34;&gt;Notebook Summary&lt;/h2&gt; &lt;p&gt;This project includes procedures for loading, analyzing, processing, then modeling mobility and segregation density within a defined 15-minute city. The process includes:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Data loading and initial analysis.&lt;/li&gt; &lt;li&gt;Define 15-minute city parameters for the given dataset.&lt;/li&gt; &lt;li&gt;Identifying data file tags to define residents, streets, amenities, and places of work.&lt;/li&gt; &lt;li&gt;Calculate routes between coordinates of residents and amenities through the shortest path profile.&lt;/li&gt; &lt;li&gt;Project a grid of points to routes.&lt;/li&gt; &lt;li&gt;Estimate populations in provided buildings.&lt;/li&gt; &lt;li&gt;Interpret relations between routes and intersection density (segregation) with populations weighted.&lt;/li&gt; &lt;li&gt;Calculate and model final data normalized with heatmap through Grasshopper and Rhino.&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt; &lt;p&gt;The notebook is structured to be followed sequentially. Detailed comments and markdown notes guide through each step of the analysis and modeling process.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;image&#34; src=&#34;https://github.com/VIP-SMUR/wiki/assets/80086242/42125dde-0ed8-4f24-8647-b76ec7fe20c2&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;models-and-algorithms-used&#34;&gt;Models and Algorithms Used&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Kernel Densities&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Space-Time Prisms&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Volumetric Population Estimation&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Vehicle Profile Routing (Itinero)&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;data-description&#34;&gt;Data Description&lt;/h2&gt; &lt;p&gt;Densities for segregation are calculated and output through the heatmap weighted by population. In Rhino, the heatmap overlays a segment of data from OSM that will display darker blue for greater density and red for lower. Aggregated results can be generated through dataset and certain amenity types to compare the average encounter densities.&lt;/p&gt; &lt;h2 id=&#34;key-findings-and-observations&#34;&gt;Key Findings and Observations&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Kernel densities allow for a simple calculation of segregation under the definition of interaction between pedestrians in a defined 15-minute city&lt;/li&gt; &lt;li&gt;Volumetric Method with building area, building height, and census population provides general estimate for populations with data from https://opendata.atlantaregional.com/&lt;/li&gt; &lt;li&gt;Potential for interaction is best calculated through space-time prisms which are more accurately representing spatial and temporal dynamics and constraints&lt;/li&gt; &lt;li&gt;Increased local usage correlates with higher experienced segregation for low-income residents.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt; &lt;p&gt;This notebook serves as a detailed example of using methods within provided data and activity spaces to calculate segregation values for a 15-minute city. The methodologies outlined here can be adapted and expanded for other types of assessment for pedestrian mobility and accessibility.&lt;/p&gt; &lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Abbiasov, et al. (2024) The 15-minute city quantified using human mobility data.&lt;/li&gt; &lt;li&gt;Patterson &amp;amp; Farber (2015) Potential Path Areas and Activity Spaces in Application: A Review&lt;/li&gt; &lt;li&gt;Schönfelder (2002) Measuring the size and structure of human activity spaces: The longitudinal perspective.&lt;/li&gt; &lt;/ul&gt; &lt;h1 id=&#34;itinero&#34;&gt;Itinero&lt;/h1&gt; &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;Itinero is a flexible open-source routing engine for a variety of transportation modes such as walking, cycling, and driving. It provides sophisticated tools to integrate customizable routing solutions into their applications, enabling efficient navigation. Itinero emphasizes versatility, offering support for various map data formats and allowing customization to suit specific needs. Most importantly, features like offline routing and routing across multiple transportation modes are provided. For the sake of this project, the pedestrian shortest path profile is utilized to calculate and map routes for individuals within the city.&lt;/p&gt; &lt;h2 id=&#34;repository&#34;&gt;Repository&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/itinero/routing&#34;&gt;Itinero Routing&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Routing&lt;/strong&gt;: The Router uses the RouterDb data to calculate routes for a given Profile. It starts and ends the Route at a RouterPoint.&lt;/li&gt; &lt;li&gt;RouterDb: Contains the routing network, all meta-data, restrictions and so on.&lt;/li&gt; &lt;li&gt;Profile: Defines vehicles and their behaviour.&lt;/li&gt; &lt;li&gt;RouterPoint: A location on the routing network to use as a start or endpoint of a route.&lt;/li&gt; &lt;li&gt;Router: The router is where you ask for routes.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;GeoJSON Conversion&lt;/strong&gt;: Export calculated routing to GeoJSON for use in mapping and other geospatial applications.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Open Street Maps Data Retrieval&lt;/strong&gt;: Automatically download street and building data required for demand calculations.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt; &lt;p&gt;To start using Itinero, follow these steps: 1. Install following Itinero packages to .NET project: - Itinero: The Itinero routing core, this is usually the only package you need to install. - Itinero.Geo: This package ensures compatibility with NTS. - Itinero.IO.Osm: This package contains code to load OSM data. - Itinero.IO.Shape: This package contains code to load data from shapefiles. 2. Specify OSM file as needed 3. Run project through determined routing coordinates&lt;/p&gt; &lt;h2 id=&#34;data-requirements&#34;&gt;Data Requirements&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Street data should include both OSM or FEMA tag attributes for project defined amenities and places of work&lt;/li&gt; &lt;li&gt;Open Street Maps (OSM): amenities and workplaces&lt;/li&gt; &lt;li&gt;Federal Emergency Management Agency (FEMA): residentials&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.itinero.tech/&#34;&gt;Itinero&lt;/a&gt; is open-source and commercially supported, developed by the Itinero BVBA team. Itinero was built using &lt;a href=&#34;https://www.openstreetmap.org/&#34;&gt;OpenStreetMap&lt;/a&gt;&lt;/p&gt; &lt;h1 id=&#34;future-work&#34;&gt;Future Work&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Integrate temporal layer to find effective rates of encounter between pedestrians.&lt;/li&gt; &lt;li&gt;Generate daily routines to represent more realistic behavior.&lt;/li&gt; &lt;li&gt;Normalization of results to allow comparisons across sites with different total populations.&lt;/li&gt; &lt;/ul&gt;</description> <link>https://vip-smur.github.io/24sp-mobility-seg/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:56 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/24sp-mobility-seg/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/24sp-mobility-seg/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/24sp-mobility-seg/README.png" type="image/png" length="None" /> </item> <item> <title>24-Sp-Mobility-PEI</title> <description>&lt;h1 id=&#34;pedestrian-environment-index-pei-documentation&#34;&gt;Pedestrian Environment Index (PEI) Documentation&lt;/h1&gt; &lt;p&gt;The Pedestrian Environment Index (PEI) is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments.&lt;/p&gt; &lt;h3 id=&#34;core-subindices&#34;&gt;Core Subindices&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Population Density Index (PDI)&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Measures residential population density within defined areas&lt;/li&gt; &lt;li&gt;Data sourced from Census block groups&lt;/li&gt; &lt;li&gt; &lt;p&gt;Implementation: &lt;code&gt;PDI_generator.ipynb&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Commercial Density Index (CDI)&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Evaluates density of commercial establishments per Block Group&lt;/li&gt; &lt;li&gt;Indicates availability of walkable destinations and services&lt;/li&gt; &lt;li&gt; &lt;p&gt;Implementation: &lt;code&gt;CDI_generator.ipynb&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intersection Density Index (IDI)&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Quantifies intersection density within an area&lt;/li&gt; &lt;li&gt;Evaluates route options and pedestrian safety&lt;/li&gt; &lt;li&gt; &lt;p&gt;Implementation: &lt;code&gt;IDI_generator.ipynb&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Land-use Diversity Index (LDI)&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Analyzes mix of land-use types (residential, commercial, industrial)&lt;/li&gt; &lt;li&gt;Assesses environment walkability through land use diversity&lt;/li&gt; &lt;li&gt;Implementation: &lt;code&gt;LDI_generator.ipynb&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;implementation-workflow&#34;&gt;Implementation Workflow&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Subindex Calculation&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Individual Jupyter notebooks (&lt;code&gt;*_generator.ipynb&lt;/code&gt;) process Census block group shapefiles&lt;/li&gt; &lt;li&gt;Each generator computes its respective subindex score&lt;/li&gt; &lt;li&gt; &lt;p&gt;Outputs saved as CSV or GeoJSON files&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;PEI Compilation&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;PEI_generator.ipynb&lt;/code&gt; combines subindex outputs&lt;/li&gt; &lt;li&gt; &lt;p&gt;Computes final PEI score for each block group&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visualization&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Results displayed as geographic maps&lt;/li&gt; &lt;li&gt;PEI scores visualized across census block groups&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;em&gt;Note: Project is transitioning to standardize all output files to GeoJSON format.&lt;/em&gt;&lt;/p&gt; &lt;h2 id=&#34;detailed-index-methodologies&#34;&gt;Detailed Index Methodologies&lt;/h2&gt; &lt;h3 id=&#34;commercial-density-index-cdi&#34;&gt;Commercial Density Index (CDI)&lt;/h3&gt; &lt;h4 id=&#34;overview&#34;&gt;Overview&lt;/h4&gt; &lt;p&gt;Calculates amenity counts per block group, normalized against the region&#39;s maximum commercial density.&lt;/p&gt; &lt;h4 id=&#34;input-data&#34;&gt;Input Data&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Source: &lt;code&gt;atl_bg.geojson&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Contains Atlanta neighborhood data&lt;/li&gt; &lt;li&gt;Uses OSMNx for amenity quantification&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;amenity-categories&#34;&gt;Amenity Categories&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Groceries&lt;/strong&gt;: supermarket, convenience, grocery, food, organic&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Restaurants&lt;/strong&gt;: restaurant, cafe, food_court, bistro, fast_food&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Banks&lt;/strong&gt;: bank, atm&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Schools&lt;/strong&gt;: school, college, university, kindergarten, music_school, language_school, driving_school&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Entertainment&lt;/strong&gt;: cinema, theatre, nightclub, casino, arts_centre, sports_centre, stadium, amusement_arcade, dance, bowling_alley, attraction, theme_park, zoo&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Parks&lt;/strong&gt;: recreation_ground, grass, greenfield&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;output&#34;&gt;Output&lt;/h4&gt; &lt;p&gt;Normalized commercial density values relative to regional maximum&lt;/p&gt; &lt;h3 id=&#34;intersection-density-index-idi&#34;&gt;Intersection Density Index (IDI)&lt;/h3&gt; &lt;h4 id=&#34;overview_1&#34;&gt;Overview&lt;/h4&gt; &lt;p&gt;Analyzes intersection patterns within block groups to evaluate street connectivity.&lt;/p&gt; &lt;h4 id=&#34;input-requirements&#34;&gt;Input Requirements&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;GeoJSON file containing:&lt;/li&gt; &lt;li&gt;Block group geometries&lt;/li&gt; &lt;li&gt;State and county FIPS codes&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;output-data-csv&#34;&gt;Output Data (CSV)&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Polygon: Block group geometry&lt;/li&gt; &lt;li&gt;Area: Block group area&lt;/li&gt; &lt;li&gt;Intersection: Sum of intersection-connected roads&lt;/li&gt; &lt;li&gt;IDI: Normalized intersection density value&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;processing-steps&#34;&gt;Processing Steps&lt;/h4&gt; &lt;ol&gt; &lt;li&gt;Read GeoJSON geometry data&lt;/li&gt; &lt;li&gt;Extract intersection data via OSMNx&lt;/li&gt; &lt;li&gt;Calculate equivalency factors&lt;/li&gt; &lt;li&gt;Compute population density&lt;/li&gt; &lt;li&gt;Generate visualization-ready output&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;land-diversity-index-ldi&#34;&gt;Land Diversity Index (LDI)&lt;/h3&gt; &lt;h4 id=&#34;overview_2&#34;&gt;Overview&lt;/h4&gt; &lt;p&gt;Evaluates land use diversity within block groups.&lt;/p&gt; &lt;h4 id=&#34;input-requirements_1&#34;&gt;Input Requirements&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;GeoJSON file containing:&lt;/li&gt; &lt;li&gt;Block group geometries&lt;/li&gt; &lt;li&gt;State and county FIPS codes&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;output-data-csv_1&#34;&gt;Output Data (CSV)&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Polygon: Block group geometry&lt;/li&gt; &lt;li&gt;Land_use_dict: Land use type areas&lt;/li&gt; &lt;li&gt;Entropy: Block entropy value&lt;/li&gt; &lt;li&gt;LDI: Normalized land diversity value&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;processing-steps_1&#34;&gt;Processing Steps&lt;/h4&gt; &lt;ol&gt; &lt;li&gt;Extract GeoJSON geometry&lt;/li&gt; &lt;li&gt;Gather land use data via OSMNx&lt;/li&gt; &lt;li&gt;Calculate block entropy&lt;/li&gt; &lt;li&gt;Compute land diversity&lt;/li&gt; &lt;li&gt;Prepare visualization data&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;population-density-index-pdi&#34;&gt;Population Density Index (PDI)&lt;/h3&gt; &lt;h4 id=&#34;overview_3&#34;&gt;Overview&lt;/h4&gt; &lt;p&gt;Processes Census Bureau population data to calculate density metrics.&lt;/p&gt; &lt;h4 id=&#34;input-requirements_2&#34;&gt;Input Requirements&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;GeoDataFrame with:&lt;/li&gt; &lt;li&gt;Block group geometries&lt;/li&gt; &lt;li&gt;State/county FIPS codes&lt;/li&gt; &lt;li&gt;Census API key (from parameter or &lt;code&gt;census_api_key.txt&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;output-data-geodataframe&#34;&gt;Output Data (GeoDataFrame)&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;POP: Block group population&lt;/li&gt; &lt;li&gt;POPDENSITY: Persons per square kilometer&lt;/li&gt; &lt;li&gt;NORMPOPDENSITY: Normalized population density&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;processing-steps_2&#34;&gt;Processing Steps&lt;/h4&gt; &lt;ol&gt; &lt;li&gt;Validate API credentials&lt;/li&gt; &lt;li&gt;Extract FIPS codes&lt;/li&gt; &lt;li&gt;Retrieve Census data&lt;/li&gt; &lt;li&gt;Integrate population data&lt;/li&gt; &lt;li&gt;Calculate density metrics&lt;/li&gt; &lt;li&gt;Clean and format output&lt;/li&gt; &lt;/ol&gt; &lt;h4 id=&#34;error-handling&#34;&gt;Error Handling&lt;/h4&gt; &lt;p&gt;Raises ValueError if Census API key is unavailable&lt;/p&gt;</description> <link>https://vip-smur.github.io/24sp-mobility-pei/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:56 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/24sp-mobility-pei/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/24sp-mobility-pei/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/24sp-mobility-pei/README.png" type="image/png" length="None" /> </item> <item> <title>24-Fa-Microclimate-LSTM-Kriging</title> <description>&lt;h1 id=&#34;24fa-microclimate-geo-lstm-kriging&#34;&gt;24Fa-Microclimate-Geo-LSTM-Kriging&lt;/h1&gt; &lt;p&gt;Urban Weather Generator Deep Learning: LSTM-Kriging Model&lt;/p&gt; &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt; &lt;p&gt;This project aims to understand and reproduce data published by the National University of Singapore&#39;s (NUS) approach for microclimate prediction, the Geo-LSTM-Kriging Model. This model meshes three key layers to provide accurate microclimate predictions using local weatherstation data. The model takes together LULC data, historical data, and spatial distance information to learn from previous data and apply such learnings to present data. This combination is a novel combination of the strengths of LSTM&#39;s time series predictions and Kriging&#39;s spatial data dependencies.&lt;/p&gt; &lt;p&gt;This team spent work cleaning up the open-source code from NUS to understand the model&#39;s inputs better. Having improved legibility, the adapatability of the model was clear to the team and allowed them to integrate campus-specific data. The team&#39;s work this semester was focused to replicate the NUS&#39;s model for Georgia Tech campus. The team used real weather data collected on GT campus coupled with Tech&#39;s Tree Viewer App to improve the accuracy of results for the campus. &lt;/p&gt; &lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Python&lt;/li&gt; &lt;li&gt;Pandas&lt;/li&gt; &lt;li&gt;Numpy&lt;/li&gt; &lt;li&gt;OSMNX&lt;/li&gt; &lt;li&gt;Scikit-Learn&lt;/li&gt; &lt;li&gt;Pytorch&lt;/li&gt; &lt;li&gt;Pykrige&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;In addition this program requires that you provide a dataframe for the features you want to measure, as well as gridpoint data for the Kriging Regression. We’ve provided test dataframes that you can find within the “weather_station_5min” and “weather_station_60min” folders. &lt;/p&gt; &lt;h2 id=&#34;repository-structure&#34;&gt;Repository Structure&lt;/h2&gt; &lt;p&gt;This repo contains the aspects needed to replicate the Geo-Kriging LSTM Model. Inside the “python” folder, you will find the necessary notebook files to execute it. The main ones to focus on are “Organized_Model_Eval.ipynb” and “osmnx 2.ipynb”. The latter is used to gather the necessary gridpoint data for the kriging aspect and the former is utilized for execution of the models onto the data.&lt;/p&gt; &lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt; &lt;p&gt;Each of the required libraries can be easily installed with pip. For OSMNX, a separate process is required. You can find it at this &lt;a href=&#34;https://osmnx.readthedocs.io/en/stable/installation.html&#34;&gt;link&lt;/a&gt;. Once installed, run the “osmnx 2.ipynb” with the OX kernel.&lt;/p&gt; &lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt; &lt;p&gt;&lt;img alt=&#34;&#34; src=&#34;Figures/1Methodology.png&#34; /&gt;&lt;/p&gt; &lt;p&gt;For the methodology, the team used three wokflows: pre-processing, machine learning (ML) training, &amp;amp; prediction and plotting. Pre-processing involves cleaning up the data and making it usable for the ML training workflow. For the spatial method that the team incorporated into the model, the OpenStreetMap Python library osmnx, and using the library, a map of Georgia Tech&#39;s campus was used as a basis. Overlayed on top of the map is system of equally spaced out points forming a grid. For each of the equidistant points, 12 distance vectors were obtained. Theses distances are from each point on the grid to the nearest centers of various variables; these various variables are buildings, libraries, parks, parking, footways, grass, fitness centers, woods, wetlands, trees on campus, and trees in Atlanta off Tech&#39;s campus. The tree data was not easily accessible through osmnx, so the team utilized Georgia Tech&#39;s Tree Viewer App for the tree location data and distances. In the Geo-LSTM-Kriging model that our team followed, Kriging is a statistical method for spacial interpolation, predicting unknown values at locations that don’t have measured values by using spatial correlations. These spatial correlations, the 12 distance vectors for each x,y point, are based off of relationships between variables. Dr. Brian Stone&#39;s weather data obtained from the several weather stations he set up a year ago on Tech&#39;s campus was used as an input for pre-processing as well, and it mainly provided information on temperatures, dew point, and relative humidity. This is the data that our group tried to find out and this data will be used as a means for comparison and training the machine learning model. The weather data from Dr. Stone&#39;s weather stations were quite messy and required cleaning. The coordinates for each of the weather stations were obtained and separated into folders. Within each of the weather station files, the averages of the data columns, namely the temperatures, dew point, and relative humidities columns, were obtained. This normalization of data to a value of zero to one ensures that during training, there will not be any errors that come up when predicting new values. Each of the normalized values were then appended into a dictionary for machine learning training. Originally, our team tried to train the weather station files in one single large data set, however it was too much for a computer to handle, so splitting it up to dictionaries ensure that it was able to run very smoothly. The outputs of the pre-processing workflow are the CSV file for the grid distances and a CSV for the normalized weather station values. &lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;&#34; src=&#34;Figures/2Trees.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/3Grid_data.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/4station_id.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/5coord.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/6weather_dict.png&#34; /&gt;&lt;/p&gt; &lt;p&gt;Using PyTorch, the team set the main target for the prediction as the temperature and main features as relative humidity and dew point. A sequence for the LSTM was created and set as default the 10 time steps. The team did not change the parameter values too much, as the team followed the documentation&#39;s recommendations. The hidden size was changed to about 8 layers and 200 epochs, which are how many iterations one wants the program to run through the training and ensures that the program is decently trained and not too overfitted. After training each of the weather station files independently, they are all appended into one single data frame to obtain the average prediction results for each of the stations.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;&#34; src=&#34;Figures/7station_loop.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/8station_results.png&#34; /&gt;&lt;/p&gt; &lt;p&gt;The distance vectors obtained from each of the approximately 1300 different grid points mentioned earlier were used for the actual Geo-Kriging part of the project. The model is based off the random forest regression because random forest typically works well with a lot of different types of parameters, especially if the data turns out to be non linear.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;&#34; src=&#34;Figures/9features.png&#34; /&gt; &lt;img alt=&#34;&#34; src=&#34;Figures/10regression.png&#34; /&gt;&lt;/p&gt; &lt;p&gt;The team finally fit the model with these parameters to obtain a temperature graph displaying the heat distribution of Georgia Tech&#39;s campus. &lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;&#34; src=&#34;Figures/11output.png&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;future-work&#34;&gt;Future Work&lt;/h2&gt; &lt;p&gt;The team would like to run further validation studies on the model to ensure its functionality in different climates and with consistent data. As the NUS ran their model using a month&#39;s data, given steady annual temperature data, and our weather station data is inconsistent, the model should be continute to be validated before considered for further application.&lt;/p&gt; &lt;p&gt;To enhance the robustness and applicability of the LSTM-Kriging Model for urban weather generation, the following future developments are proposed: 1. Accuracy Validation&lt;/p&gt; &lt;p&gt;A critical next step is to rigorously test the accuracy of the model under various scenarios. Comparative analysis with existing models and observations will help assess the reliability and identify potential areas for refinement, including:&lt;/p&gt; &lt;p&gt;• Assessing the model&#39;s predictions across various time scales, such as hourly, daily, and seasonal trends, to identify performance consistency over short- and long-term periods. &lt;/p&gt; &lt;p&gt;• Performing a detailed breakdown of prediction errors to uncover biases or patterns associated with specific weather variables (temperature, humidity, wind speed) and urban contexts.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Handling Missing Data&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Addressing missing data in weather and spatial datasets remains a key challenge. Future work will focus on integrating advanced imputation techniques or machine learning methods to fill data gaps effectively without compromising the model&#39;s performance, including:&lt;/p&gt; &lt;p&gt;• Using diffusion models to reconstruct missing data patterns.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Generalizability Testing&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The model will be tested on additional university campuses with contexts similar to Georgia Tech, particularly those featuring comparable weather station setups and spatial characteristics. This will help evaluate the model&#39;s adaptability to different urban microclimates and provide insights for broader applications. &lt;/p&gt; &lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt; &lt;p&gt;Jintong Han, Adrian Chong, Joie Lim, Savitha Ramasamy, Nyuk Hien Wong, Filip Biljecki, (2024). Microclimate spatio-temporal prediction using deep learning and land use data. Building and Environment. &lt;a href=&#34;https://doi.org/10.1016/j.buildenv.2024.111358&#34;&gt;https://doi.org/10.1016/j.buildenv.2024.111358&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=deMabiRxBAA&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/deMabiRxBAA/maxresdefault.jpg&#34; width=&#34;480&#34; alt=&#34;Final Presentation --- 24Fa --- Microclimate-LSTM-Kriging&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;Department&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Sofia Mujica&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Mechanical Engineering&lt;/td&gt; &lt;td&gt;ME&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sofia-mujica&#34;&gt;sofia-mujica&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ze Yu Jiang&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;COC&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/zeyujiang8800&#34;&gt;zeyujiang8800&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Krish Gupta&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Civil Engineering&lt;/td&gt; &lt;td&gt;CEE&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/krishgupta-CE&#34;&gt;krishgupta-CE&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Thanasarn Changnawa&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Thanasarn-Changnawa&#34;&gt;Thanasarn-Changnawa&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/24fa-microclimate-lstm-kriging/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:55 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/24fa-microclimate-lstm-kriging/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/24fa-microclimate-lstm-kriging/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/24fa-microclimate-lstm-kriging/README.png" type="image/png" length="None" /> </item> <item> <title>Data Extraction</title> <description>&lt;p&gt;&lt;strong&gt;Data Extraction&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Identification&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Title &lt;/li&gt; &lt;li&gt;Author &lt;/li&gt; &lt;li&gt;Country in which the study conducted&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Methods&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Study design &lt;/li&gt; &lt;li&gt;A Survey-based study &lt;/li&gt; &lt;li&gt;Randomised controlled trial &lt;/li&gt; &lt;li&gt;Case-control study &lt;/li&gt; &lt;li&gt;Historically controlled trial &lt;/li&gt; &lt;li&gt;Prospective cohort study &lt;/li&gt; &lt;li&gt;Retrospective cohort study &lt;/li&gt; &lt;li&gt;Hypothesis study &lt;/li&gt; &lt;li&gt;Cross-sectional observational study &lt;/li&gt; &lt;li&gt;K-means cluster analyses &lt;/li&gt; &lt;li&gt;Others&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Population&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Population description &lt;/li&gt; &lt;li&gt;Inclusion Criteria &lt;/li&gt; &lt;li&gt;Exclusion Criteria (because some of the participants in the articles do not meet the include criteria, but the proportion is very small) &lt;/li&gt; &lt;li&gt;Group difference &lt;/li&gt; &lt;li&gt;Method of recruitment of participants &lt;/li&gt; &lt;li&gt;Population data &lt;/li&gt; &lt;li&gt;Total number of participants &lt;/li&gt; &lt;li&gt;Number of withdrawals &lt;/li&gt; &lt;li&gt;Reason for withdrawals &lt;/li&gt; &lt;li&gt;Other &lt;/li&gt; &lt;li&gt;Population Characteristics &lt;/li&gt; &lt;li&gt;Mean age (years) ± SD &lt;/li&gt; &lt;li&gt;Age Category(Range) &lt;/li&gt; &lt;li&gt;Gender Distribution &lt;/li&gt; &lt;li&gt;Identity &lt;/li&gt; &lt;li&gt;Educational level &lt;/li&gt; &lt;li&gt;Ethnic Background &lt;/li&gt; &lt;li&gt;Language Proficiency &lt;/li&gt; &lt;li&gt;Physical Ability &lt;/li&gt; &lt;li&gt;Nationality &lt;/li&gt; &lt;li&gt;Marital Status &lt;/li&gt; &lt;li&gt;Residency or Migrant(e.g Participants must have lived in the city for &lt;strong&gt;at least six months&lt;/strong&gt;.) &lt;/li&gt; &lt;li&gt;Household income &lt;/li&gt; &lt;li&gt;Job &lt;/li&gt; &lt;li&gt;Health &lt;/li&gt; &lt;li&gt;Family composition &lt;/li&gt; &lt;li&gt;Others&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Intervention / Exposure&lt;/strong&gt; &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Intervention categories &lt;/li&gt; &lt;li&gt;Outdoor Built environment &lt;ul&gt; &lt;li&gt;Urban environment &lt;/li&gt; &lt;li&gt;Public open space &lt;/li&gt; &lt;li&gt;Plazas and square &lt;/li&gt; &lt;li&gt;Urban green space &lt;/li&gt; &lt;li&gt;Sports and Recreation Areas &lt;/li&gt; &lt;li&gt;Accessibility to transportation &lt;/li&gt; &lt;li&gt;Proximity to city center &lt;/li&gt; &lt;li&gt;Visual appeal &lt;/li&gt; &lt;li&gt;Walkable accessibility/distances/ pedestrian walkway &lt;/li&gt; &lt;li&gt;Sub-urban environment &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Environmental factors &lt;ul&gt; &lt;li&gt;Air pollution &lt;/li&gt; &lt;li&gt;Sunlight &lt;/li&gt; &lt;li&gt;Temperature &lt;/li&gt; &lt;li&gt;Humidity &lt;/li&gt; &lt;li&gt;Noise &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Intervention characteristics &lt;/li&gt; &lt;li&gt;Number of participants allocated &lt;/li&gt; &lt;li&gt;Frequency &lt;/li&gt; &lt;li&gt;Percentages &lt;/li&gt; &lt;li&gt;Other&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Outcome&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Outcome categories &lt;/li&gt; &lt;li&gt;Mental health &lt;/li&gt; &lt;li&gt;Well-being &lt;ul&gt; &lt;li&gt;Subjective Well Being (SWB) &lt;/li&gt; &lt;li&gt;Comfort &lt;/li&gt; &lt;li&gt;Satisfaction &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outcome Type &lt;/p&gt; &lt;ul&gt; &lt;li&gt;continuous(e.g data,score) &lt;/li&gt; &lt;li&gt;dichotomous(e.g true or false)&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Outcome details &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;CR:Composite Reliability &lt;/p&gt; &lt;/li&gt; &lt;li&gt;Cα: Cronbach&#39;s Alpha &lt;/li&gt; &lt;li&gt;SFL: standardized factor loading &lt;/li&gt; &lt;li&gt;AVE:average variance extracted &lt;/li&gt; &lt;li&gt;VIF:variance inflation factor. &lt;/li&gt; &lt;li&gt;Fornell–Larcker(F-L)criteria &lt;/li&gt; &lt;li&gt;heterotrait–monotrait(HTMT)ratio &lt;/li&gt; &lt;li&gt;T Value &lt;/li&gt; &lt;li&gt;beta coefficients(β) &lt;/li&gt; &lt;li&gt;95% CI &lt;/li&gt; &lt;li&gt;P-value&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h3 id=&#34;continuous-data&#34;&gt;Continuous data&lt;/h3&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Mean &lt;/p&gt; &lt;/li&gt; &lt;li&gt;Sum &lt;/li&gt; &lt;li&gt;Median &lt;/li&gt; &lt;li&gt;IQR(Interquartile Range) &lt;/li&gt; &lt;li&gt;Range &lt;/li&gt; &lt;li&gt;P-value &lt;/li&gt; &lt;li&gt;beta coefficients(β) &lt;/li&gt; &lt;li&gt;95% confidence intervals(95%CI) &lt;/li&gt; &lt;li&gt; &lt;p&gt;Others&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;h3 id=&#34;dichotomous-data&#34;&gt;Dichotomous data&lt;/h3&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Ratio&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;</description> <link>https://vip-smur.github.io/24fa-neuroarchitecture/selecting_process/Data%20Extraction/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:55 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/24fa-neuroarchitecture/selecting_process/Data%20Extraction/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/24fa-neuroarchitecture/selecting_process/Data%20Extraction/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/24fa-neuroarchitecture/selecting_process/Data Extraction.png" type="image/png" length="40256" /> </item> <item> <title>25-Sp-Mobility-PEI</title> <description>&lt;h1 id=&#34;pedestrian-environment-index-pei-documentation-spring-2025&#34;&gt;Pedestrian Environment Index (PEI) Documentation - Spring 2025&lt;/h1&gt; &lt;p&gt;This project implements the Pedestrian Environment Index (PEI) methodology as developed at the University of Illinois Chicago (see the research paper: &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0966692314001343&#34;&gt;https://www.sciencedirect.com/science/article/pii/S0966692314001343&lt;/a&gt;). The PEI provides a composite measure of the walkability of an environment, incorporating the following subindices:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Population Density Index (PDI)&lt;/li&gt; &lt;li&gt;Commercial Density Index (CDI)&lt;/li&gt; &lt;li&gt;Intersection Density Index (IDI)&lt;/li&gt; &lt;li&gt;Land-use Diversity Index (LDI)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;1-motivation-and-introduction&#34;&gt;1. Motivation and Introduction&lt;/h2&gt; &lt;p&gt;The &lt;strong&gt;Pedestrian Environment Index (PEI)&lt;/strong&gt; is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments. This implementation of the PEI is useful for researchers aiming to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Assess the current walkability of neighborhoods or regions.&lt;/li&gt; &lt;li&gt;Compare walkability across different areas.&lt;/li&gt; &lt;li&gt;Identify areas with potential for improvement.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;2-getting-started&#34;&gt;2. Getting Started&lt;/h2&gt; &lt;h3 id=&#34;prerequisites&#34;&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Python 3.x&lt;/strong&gt;:&lt;br /&gt; Ensure Python is installed and available in your system path. Check using: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--version &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Required Libraries&lt;/strong&gt;:&lt;br /&gt; Install the following Python libraries:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;osmnx&lt;/li&gt; &lt;li&gt;pandas&lt;/li&gt; &lt;li&gt;numpy&lt;/li&gt; &lt;li&gt;matplotlib.pyplot&lt;/li&gt; &lt;li&gt;csv&lt;/li&gt; &lt;li&gt; &lt;p&gt;census&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Census API Key&lt;/strong&gt;:&lt;br /&gt; Obtain a Census API key from &lt;a href=&#34;https://api.census.gov/data/key_signup.html&#34;&gt;Census API Key Signup&lt;/a&gt;.&lt;br /&gt; Save the key in a text file named &lt;code&gt;census_api_key.txt&lt;/code&gt; in the same directory as &lt;code&gt;PDI_generator.ipynb&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;installation&#34;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Install the required libraries using pip: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;osmnx&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pandas&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;numpy&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;matplotlib&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;csv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;census &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;3-core-subindices&#34;&gt;3. Core Subindices&lt;/h2&gt; &lt;h3 id=&#34;population-density-index-pdi&#34;&gt;&lt;strong&gt;Population Density Index (PDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Measures residential population density within defined areas.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Population and area data are downloaded from the Missouri Census Data Center.&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Calculation&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\text{Population Density} = \frac{\text{Total Population}}{\text{Total Area (Square Miles)}}\)&lt;/span&gt;&lt;br /&gt; - &lt;strong&gt;PDI&lt;/strong&gt;: Percentile rank of Population Density across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;commercial-density-index-cdi&#34;&gt;&lt;strong&gt;Commercial Density Index (CDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Evaluates the density of commercial establishments per block group.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Data is sourced using the Overpass API.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Tags used include shops, restaurants, cafes, banks, schools, cinemas, parks, sports centers, and stadiums.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Area is derived from census tracts in the US Census GeoJSON files.&lt;/p&gt; &lt;p&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\text{Commercial Density} = \frac{\text{Count of Commercial POIs}}{\text{Total Land Area (Square Miles)}}\)&lt;/span&gt;&lt;br /&gt; - &lt;strong&gt;CDI&lt;/strong&gt;: Percentile rank of Commercial Density across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;intersection-density-index-idi&#34;&gt;&lt;strong&gt;Intersection Density Index (IDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Quantifies the density of intersections in a given area.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Retrieved using the Overpass API.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: &lt;span class=&#34;arithmatex&#34;&gt;\(\text{Intersection Density} = \frac{\text{Number of Nodes Part of More than One Way (Intersections)}}{\text{Area (Square Miles)}}\)&lt;/span&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;IDI&lt;/strong&gt;: Percentile rank of Intersection Densities across all years and cities.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;land-use-diversity-index-ldi&#34;&gt;&lt;strong&gt;Land-use Diversity Index (LDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Analyzes the diversity of land-use types within an area.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Land-use data is retrieved from OpenStreetMap using the Overpass API with the &#34;landuse&#34; tag.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: &lt;span class=&#34;arithmatex&#34;&gt;\(\text{Entropy} = \sum \left( \frac{\text{Area of Land Use Type}}{\text{Total Area}} \cdot \ln \left( \frac{\text{Area of Land Use Type}}{\text{Total Area}} \right) \right)\)&lt;/span&gt; (for all land-use types with non-zero area). &lt;ul&gt; &lt;li&gt;Normalized by: &lt;span class=&#34;arithmatex&#34;&gt;\(\frac{\text{Entropy}}{\ln(\text{Number of Land Use Types with Non-Zero Area})}\)&lt;/span&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;LDI&lt;/strong&gt;: Percentile rank of Entropies across all years and cities.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;4-pei-formula&#34;&gt;4. PEI Formula&lt;/h2&gt; &lt;p&gt;The PEI is calculated using the following formula:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ PEI = \frac{{(1 + PDI) \cdot (1 + IDI) \cdot (1 + LDI) \cdot (1 + CDI)}}{16} \]&lt;/div&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-implementation-workflow&#34;&gt;5. Implementation Workflow&lt;/h2&gt; &lt;h3 id=&#34;step-1-files&#34;&gt;Step 1: Files&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Download population data files from the Missouri Census Data Center (MCDC) for each required year.&lt;/li&gt; &lt;li&gt;Download block group and census tract files from the US Census Bureau website.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-2-subindex-calculation&#34;&gt;Step 2: Subindex Calculation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Run individual generator scripts (e.g., &lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.ipynb&lt;/code&gt;) for each subindex.&lt;/li&gt; &lt;li&gt;Outputs include CSV and GeoJSON files with fields for block group, year, and the &#34;raw subindex&#34; values:&lt;/li&gt; &lt;li&gt;Population Density&lt;/li&gt; &lt;li&gt;Commercial Density&lt;/li&gt; &lt;li&gt;Intersection Density&lt;/li&gt; &lt;li&gt;Entropy&lt;/li&gt; &lt;li&gt;Append all results to master files (&lt;code&gt;all_PDI&lt;/code&gt;, &lt;code&gt;all_CDI&lt;/code&gt;, &lt;code&gt;all_IDI&lt;/code&gt;, &lt;code&gt;all_LDI&lt;/code&gt;) for comprehensive cross-year/city comparison.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-3-normalization&#34;&gt;Step 3: Normalization&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Normalize raw subindex data - between 1 and 0:&lt;/li&gt; &lt;li&gt;This normalization is done by taking each block group/tract&#39;s percentile rank for each &#34;raw subindex&#34; versus every other city and every other year:&lt;/li&gt; &lt;li&gt;Because we normalize across all cities and years, our subindex values can be compared seamlessly against any other block group regardless of time/location.&lt;/li&gt; &lt;li&gt;We are able to normalize across all cities and years thanks to these aforementioned 4 files - &lt;code&gt;all_PDI.csv&lt;/code&gt;, &lt;code&gt;all_CDI.csv&lt;/code&gt;, &lt;code&gt;all_IDI.csv&lt;/code&gt;, &lt;code&gt;all_LDI.csv&lt;/code&gt; - which contain raw data for all years/cities.&lt;/li&gt; &lt;li&gt;Once we normalize the raw subindex we can now call it an actual subindex - e.g. the normalized &lt;code&gt;Commercial Density&lt;/code&gt; becomes &lt;code&gt;CDI&lt;/code&gt;, normalized &lt;code&gt;Entropy&lt;/code&gt; becomes &lt;code&gt;LDI&lt;/code&gt;, etc.&lt;/li&gt; &lt;li&gt; &lt;p&gt;The file also updates the CSV &amp;amp; GeoJSON files for each subindex and city with a new field - one of &lt;code&gt;CDI&lt;/code&gt;, &lt;code&gt;LDI&lt;/code&gt;, &lt;code&gt;PDI&lt;/code&gt;, &lt;code&gt;IDI&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Now we finally have finalized CSV and GeoJSON files for the 4 subindexes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-4-pei-calculation&#34;&gt;Step 4: PEI Calculation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Combine normalized subindices using the PEI formula for each block group/tract.&lt;/li&gt; &lt;li&gt;Generate CSV and GeoJSON files (&lt;code&gt;PEI_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;).&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-5-web-app-integration&#34;&gt;Step 5: Web App Integration&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Upload finalized GeoJSON files to AWS S3 buckets.&lt;/li&gt; &lt;li&gt;Implement and visualize data on the web app.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;6-usage&#34;&gt;6. Usage&lt;/h2&gt; &lt;h3 id=&#34;inside-the-fall24-folder-you-will-find-3-folders&#34;&gt;Inside the Fall24 folder you will find 3 folders:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Tract_Files - we mainly used this folder for testing:&lt;/li&gt; &lt;li&gt;This contains the relevant &lt;code&gt;ipynb&lt;/code&gt; files for creating the subindexes.&lt;/li&gt; &lt;li&gt; &lt;p&gt;It also contains &lt;code&gt;tracts.geojson&lt;/code&gt; which has the first 10 rows of tracts in the US - useful for testing. - Please download full tract files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;BlockGroup_Files:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;This contains the relevant &lt;code&gt;ipynb&lt;/code&gt; files for creating the subindexes. (In the PDI file, only run code blocks after the &lt;code&gt;#NEW&lt;/code&gt; comment).&lt;/li&gt; &lt;li&gt;It also contains &lt;code&gt;block_groups.geojson&lt;/code&gt; which has the first 10 rows of blockgroups in Atlanta - useful for testing. - Please create the full files using the &lt;code&gt;./Spring24/Blockgroup GeoJSON Generator&lt;/code&gt; folder (you need to rename the output of this to &lt;code&gt;block_groups.geojson&lt;/code&gt;), downlaod the full files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-1-data-download&#34;&gt;Step 1: Data Download&lt;/h3&gt; &lt;p&gt;Download the required data files from the following sources: - &lt;strong&gt;Population Data&lt;/strong&gt;: Obtain CSV files from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt;. - &lt;strong&gt;Census Block Groups/Tract GeoJSON&lt;/strong&gt;: Retrieve the required GeoJSON files from the US Census Bureau or relevant sources: - As described above, download files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/p&gt; &lt;h3 id=&#34;step-2-update-generator-scripts&#34;&gt;Step 2: Update Generator Scripts&lt;/h3&gt; &lt;p&gt;Modify the generator scripts (&lt;code&gt;PDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;CDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;LDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;IDI_Generator.ipynb&lt;/code&gt;) to include your specific file paths and input parameters. For all the subindex files, they will have a portion like the code shown below. This is the only part you must update as required:&lt;/p&gt; &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-2&#34;&gt;&lt;a id=&#34;__codelineno-2-2&#34; name=&#34;__codelineno-2-2&#34; href=&#34;#__codelineno-2-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-3&#34;&gt;&lt;a id=&#34;__codelineno-2-3&#34; name=&#34;__codelineno-2-3&#34; href=&#34;#__codelineno-2-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-4&#34;&gt;&lt;a id=&#34;__codelineno-2-4&#34; name=&#34;__codelineno-2-4&#34; href=&#34;#__codelineno-2-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2013&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-5&#34;&gt;&lt;a id=&#34;__codelineno-2-5&#34; name=&#34;__codelineno-2-5&#34; href=&#34;#__codelineno-2-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-6&#34;&gt;&lt;a id=&#34;__codelineno-2-6&#34; name=&#34;__codelineno-2-6&#34; href=&#34;#__codelineno-2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-7&#34;&gt;&lt;a id=&#34;__codelineno-2-7&#34; name=&#34;__codelineno-2-7&#34; href=&#34;#__codelineno-2-7&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-8&#34;&gt;&lt;a id=&#34;__codelineno-2-8&#34; name=&#34;__codelineno-2-8&#34; href=&#34;#__codelineno-2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-9&#34;&gt;&lt;a id=&#34;__codelineno-2-9&#34; name=&#34;__codelineno-2-9&#34; href=&#34;#__codelineno-2-9&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-10&#34;&gt;&lt;a id=&#34;__codelineno-2-10&#34; name=&#34;__codelineno-2-10&#34; href=&#34;#__codelineno-2-10&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-11&#34;&gt;&lt;a id=&#34;__codelineno-2-11&#34; name=&#34;__codelineno-2-11&#34; href=&#34;#__codelineno-2-11&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2017&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-12&#34;&gt;&lt;a id=&#34;__codelineno-2-12&#34; name=&#34;__codelineno-2-12&#34; href=&#34;#__codelineno-2-12&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-13&#34;&gt;&lt;a id=&#34;__codelineno-2-13&#34; name=&#34;__codelineno-2-13&#34; href=&#34;#__codelineno-2-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-14&#34;&gt;&lt;a id=&#34;__codelineno-2-14&#34; name=&#34;__codelineno-2-14&#34; href=&#34;#__codelineno-2-14&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-15&#34;&gt;&lt;a id=&#34;__codelineno-2-15&#34; name=&#34;__codelineno-2-15&#34; href=&#34;#__codelineno-2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-16&#34;&gt;&lt;a id=&#34;__codelineno-2-16&#34; name=&#34;__codelineno-2-16&#34; href=&#34;#__codelineno-2-16&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-17&#34;&gt;&lt;a id=&#34;__codelineno-2-17&#34; name=&#34;__codelineno-2-17&#34; href=&#34;#__codelineno-2-17&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-18&#34;&gt;&lt;a id=&#34;__codelineno-2-18&#34; name=&#34;__codelineno-2-18&#34; href=&#34;#__codelineno-2-18&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-19&#34;&gt;&lt;a id=&#34;__codelineno-2-19&#34; name=&#34;__codelineno-2-19&#34; href=&#34;#__codelineno-2-19&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-20&#34;&gt;&lt;a id=&#34;__codelineno-2-20&#34; name=&#34;__codelineno-2-20&#34; href=&#34;#__codelineno-2-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;step-3-run-scripts-in-the-following-order&#34;&gt;Step 3: Run Scripts in the Following Order&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Run the Subindex Generators&lt;/strong&gt;:&lt;br /&gt; Execute the following scripts to calculate raw subindices:&lt;/li&gt; &lt;li&gt;&lt;code&gt;CDI_Generator.ipynb&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;LDI_Generator.ipynb&lt;/code&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;IDI_Generator.ipynb&lt;/code&gt;&lt;br /&gt; These can be run in any order.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run PDI&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;For small input files (not many tracts or geojsons), run our current &lt;code&gt;PDI_Generator.ipynb&lt;/code&gt;.&lt;/li&gt; &lt;li&gt; &lt;p&gt;For larger files, a custom approach using CSV files from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt; is requied: - For this, please contact cnguyen369@gatech.edu&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Normalize Subindices&lt;/strong&gt;:&lt;br /&gt; Run &lt;code&gt;Normalizer.ipynb&lt;/code&gt; to normalize the raw subindices across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generate PEI&lt;/strong&gt;:&lt;br /&gt; Finally, run &lt;code&gt;PEI_Generator.ipynb&lt;/code&gt; to calculate the Pedestrian Environment Index.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;step-4-output&#34;&gt;Step 4: Output&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;This process will output normalized subindex files and the final PEI results as CSV and GeoJSON files.&lt;/li&gt; &lt;li&gt;The file format will be:&lt;ul&gt; &lt;li&gt;&lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Utilize the &lt;code&gt;Subindex_Visualizer.ipynb&lt;/code&gt; file to visualize your geojson file output!&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;7-challenges&#34;&gt;7. Challenges&lt;/h2&gt; &lt;h3 id=&#34;the-biggest-challege-in-our-statistic-generators-was-developing-the-pdi-generator&#34;&gt;The biggest challege in our statistic generators was developing the PDI Generator.&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;While most of our subindexes - &lt;code&gt;CDI&lt;/code&gt;, &lt;code&gt;LDI&lt;/code&gt;, &lt;code&gt;IDI&lt;/code&gt; - use the &lt;code&gt;Overpass API (OSM data)&lt;/code&gt; to gather data, this is not possible for the &lt;code&gt;PDI&lt;/code&gt; as population data is not provided by OSM.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Because of this, we were forced to utilize the &lt;code&gt;Census API&lt;/code&gt;, which had 2 main issues:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It often returned simply the latest data i.e. 2024 data - even when we requested historical population data.&lt;/li&gt; &lt;li&gt;On large geoJSONs, where we have to make hundreds and thousands of API calls, the Census API frequently errored due to API call limits.&lt;ul&gt; &lt;li&gt;This became a considerable problem when running our files using &lt;code&gt;PACE&lt;/code&gt; to generate Census Tract data for Dr Ku. Our code would run for 10 or so hours and then fail - as we would run out of API tokens.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;We got over this challenge by downloading population data by tract/block group directly - from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;We could then easily calculate &lt;code&gt;Population Density&lt;/code&gt; and hence &lt;code&gt;PDI&lt;/code&gt; by block_group/tract by merging this data with our block_groups/tracts geoJSON files - which contain an area column.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;8-spring-2025-aditions-pei-dynamic-adjustment-documentation&#34;&gt;&lt;strong&gt;8. Spring 2025 Aditions - PEI Dynamic Adjustment Documentation&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The purpose of this tool is to load block groups sequentially with their individual and combined subindex scores and change a subindex value at a specified block group to observe trends and distinguishing factors from adjacent block groups. This proffers insight into how adjacent block groups can become more cohesive and bolster existing infrastructure to create a more pedestrian-friendly environment.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;:&lt;br /&gt; The tool takes in a GeoDataFrame with GEOID&#39;d block groups, along with the four subindices and its composite PEI, plus user-provided selections for block group, subindex, and new value.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;:&lt;br /&gt; The output is a live-updated GeoDataFrame where the specified subindex value is modified for the chosen block group, enabling visualization of the resulting changes to the map and overall infrastructure.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Challenges&lt;/strong&gt;:&lt;br /&gt; Key challenges included maintaining data integrity after edits, and beginning the design of the function for seamless integration with interactive visualization tools on the web app.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future Work&lt;/strong&gt;:&lt;br /&gt; Future improvements include adding functionality to adjust multiple subindices at once, creating a user-friendly and non-terminal application to the web app to visualize theoretical metropolitan PEI changes, and integrating model-based recalculations of PEI rather than direct manual edits.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;:&lt;br /&gt; The PEI slider tool provides an intuitive way to experiment with subindex values and better understand the sensitivity of walkability metrics at a granular level, paving the way for more informed urban planning discussions.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;9-spring-2025-aditions-public-transport-accessibility-level-ptal&#34;&gt;&lt;strong&gt;9. Spring 2025 Aditions - Public Transport Accessibility Level (PTAL)&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;This project also implements the Public Transport Accessibility Level (PTAL) methodology, adapted from Transport for London’s (TfL) standard practices (Reference: &lt;em&gt;PTAL Methodology, Transport for London, April 2010&lt;/em&gt;). PTAL measures the accessibility of locations to public transit services based on walking distance and service frequency.&lt;/p&gt; &lt;hr /&gt; &lt;h4 id=&#34;1-motivation-and-introduction_1&#34;&gt;1. Motivation and Introduction&lt;/h4&gt; &lt;p&gt;The PTAL score quantifies how easily a location is served by public transit. This project adapts the PTAL method for U.S. cities like Atlanta, enabling:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Quantitative assessments of transit accessibility.&lt;/li&gt; &lt;li&gt;Cross-region comparison of transit service quality.&lt;/li&gt; &lt;li&gt;Identification of underserved and well-served areas for urban planning.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h4 id=&#34;2-getting-started_1&#34;&gt;2. Getting Started&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Python 3.x&lt;/li&gt; &lt;li&gt;Libraries: &lt;code&gt;geopandas&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;shapely&lt;/code&gt;, &lt;code&gt;math&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Public Transit Stop Data (GeoJSON) with service frequency information (data pulled from UrbanFootprint and Mobility Database).&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h4 id=&#34;3-core-components&#34;&gt;3. Core Components&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Walk Access Time&lt;/strong&gt;:&lt;br /&gt; Time taken to walk from a Point-of-Interest (POI) to a Service Access Point (SAP) like a bus stop or rail station.&lt;/li&gt; &lt;li&gt;Walk speed: 80 meters/minute (4.8 km/hr).&lt;/li&gt; &lt;li&gt; &lt;p&gt;Max distances: 640m for buses, 960m for rail.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Service Frequency and Reliability&lt;/strong&gt;:&lt;br /&gt; Number of transit services per hour.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Add 2 minutes reliability penalty for buses.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Add 0.75 minutes reliability penalty for rail.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Equivalent Doorstep Frequency (EDF)&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Formula:&lt;br /&gt; $$ EDF = \frac{30}{\text{Walk Time} + \text{Average Waiting Time}} $$&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accessibility Index (AI)&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Calculation: Sum of EDFs, with secondary routes discounted by 50% to avoid overrepresentation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;PTAL Level Assignment&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Accessibility Index values are normalized similar to other subindices.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h4 id=&#34;4-ptal-calculation-workflow&#34;&gt;4. PTAL Calculation Workflow&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Load POIs (e.g., block groups).&lt;/li&gt; &lt;li&gt; &lt;p&gt;Load Transit Stops with service frequency attributes.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Walk Access Calculation&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Filter stops within the walking thresholds.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access Time and EDF Calculation&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Compute walk time and average waiting time.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Calculate EDF for each nearby route.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accessibility Index Computation&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Sum EDFs, applying 50% discount to non-dominant routes per transport mode.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;PTAL Assignment&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Assign final PTAL levels based on AI bands.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h4 id=&#34;5-outputs&#34;&gt;5. Outputs&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Final outputs are available as CSV and GeoJSON files with PTAL scores for each geographic unit.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h4 id=&#34;6-challenges&#34;&gt;6. Challenges&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Limited transit stop data coverage in non-dense areas.&lt;/li&gt; &lt;li&gt;Incomplete GTFS feeds for certain systems.&lt;/li&gt; &lt;li&gt;Simplified pedestrian network modeling.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;6-limitations&#34;&gt;&lt;strong&gt;6. Limitations&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Quality and Completeness&lt;/strong&gt;:&lt;br /&gt; PEI heavily relies on OpenStreetMap (OSM) data and census datasets, which may have missing or outdated entries, especially outside major urban centers.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplified Walkability&lt;/strong&gt;:&lt;br /&gt; Current PEI calculations assume basic walk access without modeling detailed pedestrian barriers (e.g., highways, rivers, unsafe crossings).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transit Data Challenges&lt;/strong&gt;:&lt;br /&gt; PTAL relies on accurate service frequency data, which is often incomplete, inconsistent, or missing for certain cities or transit providers.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;7-future-work&#34;&gt;&lt;strong&gt;7. Future Work&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Integrate complete GTFS schedule data for previous years.&lt;/li&gt; &lt;li&gt;Merge with walkability indices like PEI for a full mobility landscape.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;10-spring-2025-aditions-nationwide-data-generation-for-dr-ku&#34;&gt;&lt;strong&gt;10. Spring 2025 Aditions - Nationwide Data Generation for Dr Ku.&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;We also created a nationwide data dataset using the PEI methodologies we described above. We simple ran the relevant PEI files in the aforementioned way (see &lt;strong&gt;6. Usage&lt;/strong&gt;), but with a &lt;code&gt;national_tracts.geojson&lt;/code&gt; file. - This dataset containts CDI, LDI, IDI, PDI, and PEI files as a CSV. - We created the files on both a Tract and County level (County Level data is new to Spring 2025).&lt;/p&gt; &lt;p&gt;In order to access raw files, please contact: abeesen3@gatech.edu&lt;/p&gt; &lt;h3 id=&#34;nationwide-dataset-examples&#34;&gt;Nationwide dataset examples:&lt;/h3&gt; &lt;table&gt; &lt;tr&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/Boston.png?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;Boston&lt;/strong&gt; &lt;/td&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/Chicago.png?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;Chicago&lt;/strong&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/Miami.png?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;Miami&lt;/strong&gt; &lt;/td&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/NewYork.png?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;New York&lt;/strong&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/SanFrancisco.jpeg?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;San Francisco&lt;/strong&gt; &lt;/td&gt; &lt;td align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/VIP-SMUR/25Sp-Mobility-PEI/blob/main/NationwideImages/WashingtonDC.png?raw=true&#34; width=&#34;45%&#34;&gt;&lt;br/&gt; &lt;strong&gt;Washington, DC&lt;/strong&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;h2 id=&#34;11-spring-2025-aditions-pei-documentation&#34;&gt;&lt;strong&gt;11. Spring 2025 Aditions - PEI Documentation.&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;We also created an easy-to-share pdf file that summarizes our PEI methodologies to be used for exposure, funding, etc. This can be found in this repository as &lt;code&gt;VIP_PEI_Documentation.pdf&lt;/code&gt;.&lt;/p&gt; &lt;h2 id=&#34;12-overall-future-work&#34;&gt;12. Overall Future Work&lt;/h2&gt; &lt;p&gt;To improve the comprehensiveness of the Public Infrastructure Environment (PIE) framework, a major future goal is to expand the number of subindices beyond the current set.&lt;br /&gt; If we were to do this, we also want to make sure that they are properly integrated into PEI.&lt;/p&gt; &lt;p&gt;Planned improvements include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support for New Subindices&lt;/strong&gt;:&lt;br /&gt; Add visualization options for future subindices.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expansion to More Cities&lt;/strong&gt;:&lt;br /&gt; Make additional cities available for viewing.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Official Publication&lt;/strong&gt;:&lt;br /&gt; Publish our research officially and publicly to help advance urban sustainability.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Verification via Overpass API&lt;/strong&gt;:&lt;br /&gt; Fully integrate data checking against Overpass API to verify the accuracy of inputted data.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ground-Truthing&lt;/strong&gt;:&lt;br /&gt; Conduct surveys and other research to validate PEI accuracy and compare with other walkability models.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;hr /&gt; &lt;h2 id=&#34;13-contributing&#34;&gt;13. Contributing&lt;/h2&gt; &lt;p&gt;We welcome contributions to this project. &lt;/p&gt; &lt;h3 id=&#34;steps-to-contribute&#34;&gt;Steps to Contribute:&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Fork the repository.&lt;/li&gt; &lt;li&gt;Create a feature branch: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;checkout&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-b&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;feature/new-feature &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Push your changes and submit a pull request.&lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;14-license&#34;&gt;14. License&lt;/h2&gt; &lt;p&gt;This project is shared for research and educational purposes. Please do not redistribute for commercial use.&lt;/p&gt; &lt;hr /&gt; &lt;h1 id=&#34;web-app-documentation&#34;&gt;Web App Documentation&lt;/h1&gt; &lt;p&gt;The web app is currently deployed at this link: https://vip-pei-app-2.onrender.com/ 😊&lt;/p&gt; &lt;p&gt;This deployment is dynamic and so any updates to our codebase (https://github.com/AtharvaBeesen/vip-pei-app-2) will automatically be displayed.&lt;/p&gt; &lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;App Name&lt;/strong&gt;: VIP SMUR PEI Proof of Concept&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Visualize the work we have done in creating the aforementioned subindexes. We also wanted to allow the data we generate to be available online in a visually appealing, paletable, and easy-to-download way.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;key-features&#34;&gt;Key Features:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Interactive map with GeoJSON visualization for the subindexes - PDI, IDI, CDI, LDI, PEI - across different cities and years.&lt;/li&gt; &lt;li&gt;Dynamic city, statistic, and year selection.&lt;/li&gt; &lt;li&gt;Ability to download CSV and GeoJSON files for selected data.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;technology-stack&#34;&gt;Technology Stack:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React, JavaScript, HTML, CSS&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: All functionality contained within JavaScript&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mapping Library&lt;/strong&gt;: Leaflet&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Amazon S3 Buckets&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;2-getting-started_2&#34;&gt;2. Getting Started&lt;/h2&gt; &lt;h3 id=&#34;prerequisites_1&#34;&gt;Prerequisites&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Node.js and npm/yarn&lt;/strong&gt;:&lt;br /&gt; Ensure Node.js and npm (or yarn) are installed on your system. You can check this by running: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;node&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-v &lt;/span&gt;&lt;span id=&#34;__span-4-2&#34;&gt;&lt;a id=&#34;__codelineno-4-2&#34; name=&#34;__codelineno-4-2&#34; href=&#34;#__codelineno-4-2&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-v &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; If not installed, download them from &lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js official site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code Editor (Optional)&lt;/strong&gt;:&lt;br /&gt; Install a code editor like &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;Visual Studio Code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Browser&lt;/strong&gt;:&lt;br /&gt; A modern browser like Chrome, Firefox, or Edge to test your app.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Git&lt;/strong&gt;:&lt;br /&gt; Install Git for cloning the repository. Check installation by running: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--version &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leaflet Library Dependencies&lt;/strong&gt;:&lt;br /&gt; The app uses Leaflet for maps, which requires:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;A valid internet connection to download Leaflet assets via npm or yarn.&lt;/li&gt; &lt;li&gt;Ensure the browser supports Leaflet.&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;installation_1&#34;&gt;Installation&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Clone the repository: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;clone&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;https://github.com/AtharvaBeesen/vip-pei-app-2.git &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Install dependencies: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-7-1&#34;&gt;&lt;a id=&#34;__codelineno-7-1&#34; name=&#34;__codelineno-7-1&#34; href=&#34;#__codelineno-7-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Ensure Leaflet is installed: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-8-1&#34;&gt;&lt;a id=&#34;__codelineno-8-1&#34; name=&#34;__codelineno-8-1&#34; href=&#34;#__codelineno-8-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;leaflet &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Run the application: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-9-1&#34;&gt;&lt;a id=&#34;__codelineno-9-1&#34; name=&#34;__codelineno-9-1&#34; href=&#34;#__codelineno-9-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;start &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Access the app at &lt;code&gt;http://localhost:3000&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;deployment&#34;&gt;Deployment&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Already deployed! We deployed using &lt;code&gt;Render&lt;/code&gt;:&lt;br /&gt; &lt;a href=&#34;https://vip-pei-app-2.onrender.com/&#34;&gt;https://vip-pei-app-2.onrender.com/&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;3-features&#34;&gt;3. Features&lt;/h2&gt; &lt;h3 id=&#34;31-interactive-map&#34;&gt;3.1 Interactive Map&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Displays GeoJSON data visualized on a Leaflet map.&lt;/li&gt; &lt;li&gt;Map dynamically updates based on city, statistic, and year selections.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;32-city-statistic-and-year-selection&#34;&gt;3.2 City, Statistic, and Year Selection&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Dropdown menus for users to select:&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Cities&lt;/strong&gt;: Atlanta, New York, Los Angeles.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Statistics&lt;/strong&gt;: IDI, PDI, CDI, LDI, PEI.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Years&lt;/strong&gt;: 2022, 2013.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;33-file-downloads&#34;&gt;3.3 File Downloads&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;CSV and GeoJSON files for the selected data can be downloaded with a single click.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;4-components&#34;&gt;4. Components&lt;/h2&gt; &lt;h3 id=&#34;41-appjs&#34;&gt;4.1 App.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;The main entry point for the application.&lt;/li&gt; &lt;li&gt;Manages state for selected city, statistic, and year.&lt;/li&gt; &lt;li&gt;Renders &lt;code&gt;CitySelector&lt;/code&gt;, &lt;code&gt;DownloadButton&lt;/code&gt;, and &lt;code&gt;MapComponent&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;42-cityselectorjs&#34;&gt;4.2 CitySelector.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Dropdown menus for selecting city, statistic, and year.&lt;/li&gt; &lt;li&gt;Capitalizes city names and statistics for user-friendly display.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;43-mapcomponentjs&#34;&gt;4.3 MapComponent.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Displays the Leaflet map and GeoJSON data.&lt;/li&gt; &lt;li&gt;Dynamically fetches data from S3 Buckets based on user selections (more on this below).&lt;/li&gt; &lt;li&gt;Highlights GeoJSON features with a color-coded scheme based on statistic values.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;44-downloadbuttonjs&#34;&gt;4.4 DownloadButton.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Provides buttons to download CSV and GeoJSON files from S3.&lt;/li&gt; &lt;li&gt;Dynamically constructs download URLs based on user selections.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-api-integration&#34;&gt;5. API Integration&lt;/h2&gt; &lt;p&gt;The app dynamically fetches GeoJSON data from an Amazon S3 bucket: - URL format:&lt;br /&gt; &lt;code&gt;https://vip-censusdata.s3.us-east-2.amazonaws.com/{city}_blockgroup_{statistic}_{year}.geojson&lt;/code&gt;&lt;/p&gt; &lt;h3 id=&#34;example&#34;&gt;Example:&lt;/h3&gt; &lt;p&gt;For Atlanta, IDI, and 2022:&lt;br /&gt; &lt;code&gt;https://vip-censusdata.s3.us-east-2.amazonaws.com/atlanta_blockgroup_IDI_2022.geojson&lt;/code&gt;&lt;/p&gt; &lt;hr /&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-city-comparison-tool-spring-2025&#34;&gt;5. City Comparison Tool (Spring 2025)&lt;/h2&gt; &lt;h3 id=&#34;1-overview&#34;&gt;&lt;strong&gt;1. Overview&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;We created a City Comparison Tool MVP to allow users to dynamically compare changes in walkability-related subindices (IDI, PDI, CDI, LDI, PEI) between two different years for a selected city.&lt;/p&gt; &lt;p&gt;This tool calculates and visualizes the &lt;strong&gt;percentage change&lt;/strong&gt; in the selected statistic for each census block group, helping to identify areas that have improved or declined over time.&lt;/p&gt; &lt;h3 id=&#34;2-key-features&#34;&gt;&lt;strong&gt;2. Key Features&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;City Selection&lt;/strong&gt;:&lt;br /&gt; Compare changes for Atlanta, New York, or Los Angeles.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Statistic Selection&lt;/strong&gt;:&lt;br /&gt; Choose one of the following subindices to analyze:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Intersection Density Index (IDI)&lt;/li&gt; &lt;li&gt;Population Density Index (PDI)&lt;/li&gt; &lt;li&gt;Commercial Density Index (CDI)&lt;/li&gt; &lt;li&gt;Land-use Diversity Index (LDI)&lt;/li&gt; &lt;li&gt; &lt;p&gt;Pedestrian Environment Index (PEI)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Year Selection&lt;/strong&gt;:&lt;br /&gt; Select two different years to calculate the percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic GeoJSON Visualization&lt;/strong&gt;:&lt;br /&gt; The map displays block groups color-coded by the percentage change in the selected statistic.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive Tooltips&lt;/strong&gt;:&lt;br /&gt; Hovering over a block group shows its GEOID and computed percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Custom Color Scale&lt;/strong&gt;:&lt;br /&gt; The visualization uses a diverging color scheme to easily distinguish between positive and negative changes.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;3-technical-workflow&#34;&gt;&lt;strong&gt;3. Technical Workflow&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Fetching&lt;/strong&gt;:&lt;br /&gt; The tool fetches the respective city&#39;s GeoJSON files for both selected years from the Amazon S3 bucket.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Difference Calculation&lt;/strong&gt;: &lt;/p&gt; &lt;/li&gt; &lt;li&gt;For most subindices (IDI, PDI, CDI, PEI), block groups are matched by &lt;strong&gt;GEOID&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt; &lt;p&gt;For LDI (which currently lacks GEOIDs), features are temporarily matched by their &lt;strong&gt;array index&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Percent Change Computation&lt;/strong&gt;:&lt;br /&gt; The percent change for each block group is calculated as:&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{Percent Change} = \frac{(\text{After Value} - \text{Before Value})}{\text{Before Value}} \times 100 \]&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Visualization&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Block groups are shaded according to the magnitude of their percent change.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Tooltips display the block group ID and the exact percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Robust Edge Case Handling&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;If both before and after values are zero, the percent change is set to 0.&lt;/li&gt; &lt;li&gt;If a before value is zero and after is nonzero, the block group is highlighted accordingly without division errors.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;4-known-limitations&#34;&gt;&lt;strong&gt;4. Known Limitations&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;LDI currently matches features by array index due to missing GEOIDs (planned to be fixed in future data versions).&lt;/li&gt; &lt;li&gt;Only a few cities and years are currently available.&lt;/li&gt; &lt;li&gt;No smoothing or statistical aggregation (e.g., at the neighborhood level) yet applied — purely block group level.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;5-future-work&#34;&gt;&lt;strong&gt;5. Future Work&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Add more cities and historical years to expand the tool’s coverage.&lt;/li&gt; &lt;li&gt;Improve LDI data quality by assigning proper GEOIDs.&lt;/li&gt; &lt;li&gt;Integrate this comparison tool directly into the main PEI web app navigation.&lt;/li&gt; &lt;li&gt;Add multi-year trend graphs and regional aggregation for deeper urban insights.&lt;/li&gt; &lt;li&gt;Allow users to select multiple subindices at once for richer comparisons.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;6-future-work&#34;&gt;6. Future Work&lt;/h2&gt; &lt;h3 id=&#34;there-are-3-key-goals-we-hope-to-achieve&#34;&gt;There are 3 key goals we hope to achieve:&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Increase the number of cities and years supported&lt;/strong&gt;:&lt;br /&gt; This would simply require us to continue running our subindex generators over the course of the next semester(s) in order to continue to grow the size of our database.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Seek Collaboration/Monetization Opportunities&lt;/strong&gt;:&lt;br /&gt; As we grow the site and our footprint in the space, we could seek to replicate WalkScore&#39;s monetization and collaboration business model:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Collaborate with products/sites&lt;/strong&gt;:&lt;br /&gt; Work with products or sites that require walkability statistics (e.g., Zillow and City Planning Companies) to create customized statistics at a cost.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Direct collaboration with local government&lt;/strong&gt;:&lt;br /&gt; Assist local governments in achieving their goals of improving walkability in urban areas.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Developing a for-cost API&lt;/strong&gt;:&lt;br /&gt; Create an API that allows third-party researchers to use our data. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;For Example: Collaborating with researchers like Dr. Ku, who uses our data to enhance his psychology research.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improve the UI&lt;/strong&gt;:&lt;br /&gt; This goal is less essential and is more about improving user-experience in the case that we decide to push towards becoming a standalone software for third-parties to gather walkability data on different urban areas.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;7-contributing&#34;&gt;7. Contributing&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Please contact abeesen3@gatech.edu before doing so.&lt;/li&gt; &lt;li&gt;Example of how to contribute:&lt;/li&gt; &lt;li&gt;Fork the repository (https://github.com/AtharvaBeesen/vip-pei-app-2)&lt;/li&gt; &lt;li&gt;Create a feature branch: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-10-1&#34;&gt;&lt;a id=&#34;__codelineno-10-1&#34; name=&#34;__codelineno-10-1&#34; href=&#34;#__codelineno-10-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;checkout&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-b&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;feature/new-feature &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Push your changes and submit a pull request.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;8-license&#34;&gt;8. License&lt;/h2&gt; &lt;p&gt;This project is shared for research and educational purposes. Please do not redistribute for commercial use.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2OY8LxKQn4o&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/2OY8LxKQn4o/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;Department&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Yao Xiao&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;COC&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Xyrro&#34;&gt;Xyrro&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mason DeWitt&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Electrical Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Masonrd&#34;&gt;Masonrd&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Joshua Cohen&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Civil Engineering&lt;/td&gt; &lt;td&gt;CEE&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/paradoxwalk&#34;&gt;paradoxwalk&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nicholas Stone&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;COC&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nstone213&#34;&gt;nstone213&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Atharva Beesen&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;COC&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AtharvaBeesen&#34;&gt;AtharvaBeesen&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-mobility-pei/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:55 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-mobility-pei/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-mobility-pei/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-mobility-pei/README.png" type="image/png" length="None" /> </item> <item> <title>25-Sp-Microclimate-UMCF</title> <description>&lt;h1 id=&#34;microclimate-umcf-project-documentation&#34;&gt;Microclimate-UMCF Project Documentation&lt;/h1&gt; &lt;p&gt;This document provides a comprehensive overview of the VIP-SMUR Spring 25 - Microclimate-UMCF project, which focuses on simulating and analyzing microclimate effects, particularly those involving vegetation and building materials.&lt;/p&gt; &lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt; &lt;p&gt;The overarching goals of this project are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;To simulate various microclimate scenarios using computational fluid dynamics (CFD) tools such as OpenFOAM&#39;s &lt;code&gt;urbanMicroclimateFoam&lt;/code&gt; solver and explore alternative tools like ENVI-met.&lt;/li&gt; &lt;li&gt;To understand how different parameters, including vegetation properties (like leaf area index, tree types, and root systems) and building material characteristics, influence microclimate conditions like temperature, humidity, and wind flow.&lt;/li&gt; &lt;li&gt;To validate simulation results against established benchmarks, such as the HAMSTAD benchmarks, and to refine simulation methodologies.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;key-research-areas&#34;&gt;Key Research Areas&lt;/h2&gt; &lt;h3 id=&#34;vegetation-effects-on-temperature&#34;&gt;Vegetation Effects on Temperature&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Sensitivity Analysis:&lt;/strong&gt; Determining how sensitive temperature changes are to variations in vegetation parameters like Leaf Area Index (LAI), tree species, and root system characteristics.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Experimental Design:&lt;/strong&gt; Developing a series of simulation experiments to isolate and study the impacts of key vegetation variables.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Simulation and Iteration:&lt;/strong&gt; Conducting simulations, analyzing results, and iteratively refining models to identify the most influential vegetation factors.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;building-materials&#34;&gt;Building Materials&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Solver Research:&lt;/strong&gt; Reviewing solver documentation (wikis) and published research to understand how building materials are modeled and implemented.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Case Study Formulation:&lt;/strong&gt; Developing relevant case studies, possibly based on the Georgia Tech campus or other real-world projects, to test the effects of different building materials.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Simulation Runs:&lt;/strong&gt; Conducting simulations to observe and quantify the impact of various building materials on the surrounding microclimate.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;technical-implementation-and-challenges&#34;&gt;Technical Implementation and Challenges&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Terrain Modeling:&lt;/strong&gt; Implementing terrain features in the UMCF (Urban Microclimate CFD) model, including the creation of terrain patches and handling underground cells.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Grass Geometry:&lt;/strong&gt; Integrating grass geometry into the simulation domain.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Solver Exploration:&lt;/strong&gt; Investigating the &lt;code&gt;hamFoam&lt;/code&gt; solver, including its governing equations, assumptions, and wiki documentation.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Error Handling:&lt;/strong&gt; Addressing and resolving various warnings and errors encountered during simulations, such as &lt;code&gt;FaceWarning&lt;/code&gt; messages.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mesh Generation:&lt;/strong&gt; Optimizing mesh creation processes to reduce computational time and improve accuracy.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;progress-and-weekly-updates&#34;&gt;Progress and Weekly Updates&lt;/h2&gt; &lt;p&gt;The project progressed through several phases, documented by weekly updates, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Weeks 1/27 &amp;amp; 2/6:&lt;/strong&gt; Initial setup, parameter sensitivity analysis, and implementation of Foamonary and Foamist.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Weeks 2/13 &amp;amp; 2/20:&lt;/strong&gt; Implementing terrain features, creating terrain patches, and addressing boundary condition issues, particularly with &lt;code&gt;mappedWall&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Weeks 2/27 &amp;amp; 03/06:&lt;/strong&gt; Continued troubleshooting with ENVI-met and revisiting its use for comparison. Refinement of terrain parsing and processing.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Weeks 03/13 &amp;amp; 03/31:&lt;/strong&gt; Facing slow simulation speeds with ENVI-met, encountering timestep errors in OpenFOAM, and working with &lt;code&gt;viewFactorsGen&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Week 04/07 &amp;amp; After Break:&lt;/strong&gt; Analyzing simulation results, varying wind parameters, and attempting to probe points for data collection.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;detailed-technical-issues-and-solutions&#34;&gt;Detailed Technical Issues and Solutions&lt;/h2&gt; &lt;h3 id=&#34;facewarning-messages&#34;&gt;FaceWarning Messages&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Encountering &lt;code&gt;FaceWarning&lt;/code&gt; messages during mesh creation.&lt;/li&gt; &lt;li&gt;Investigating the relevance of these warnings and their potential impact on simulation accuracy.&lt;/li&gt; &lt;li&gt;Exploring methods to optimize mesh creation and reduce/eliminate these warnings.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;boundary-condition-issues&#34;&gt;Boundary Condition Issues&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Troubleshooting issues with the &lt;code&gt;mappedWall&lt;/code&gt; boundary condition.&lt;/li&gt; &lt;li&gt;Ensuring correct face mapping between building geometries and the air region.&lt;/li&gt; &lt;li&gt;Resolving discrepancies in the number of faces between different regions.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;solver-errors&#34;&gt;Solver Errors&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Debugging crashes of &lt;code&gt;urbanMicroclimateFoam&lt;/code&gt; due to timestep issues.&lt;/li&gt; &lt;li&gt;Addressing &lt;code&gt;FOAM FATAL ERROR&lt;/code&gt; related to dynamic list capacity in &lt;code&gt;viewFactorsGen&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;envi-met-challenges&#34;&gt;ENVI-met Challenges&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Encountering difficulties saving SIMX files in ENVI-met.&lt;/li&gt; &lt;li&gt;Experiencing slow simulation speeds and limitations in the trial version.&lt;/li&gt; &lt;li&gt;Issues with remote desktop access and administrator permissions.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;benchmarking-and-validation&#34;&gt;Benchmarking and Validation&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;HAMSTAD Benchmarks:&lt;/strong&gt; Utilizing the HAMSTAD benchmarks to compare simulation results and validate model accuracy.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;ETH Zurich Resources:&lt;/strong&gt; Accessing and utilizing benchmark descriptions, input data, and result data from ETH Zurich&#39;s Gitlab repository.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;simulation-parameters-and-analysis&#34;&gt;Simulation Parameters and Analysis&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Wind Conditions:&lt;/strong&gt; Varying wind speed and direction to observe their impact on temperature, humidity, and CO2 levels.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Temperature and Humidity:&lt;/strong&gt; Analyzing the spatial distribution and variation of temperature and humidity within the simulation domain.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;CO2 Levels:&lt;/strong&gt; Investigating CO2 concentration at different heights.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Probing Points:&lt;/strong&gt; Attempting to probe specific points within the brick blocks to collect detailed data.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;tools-and-software-used&#34;&gt;Tools and Software Used&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;OpenFOAM:&lt;/strong&gt; Primary CFD software used, particularly the &lt;code&gt;urbanMicroclimateFoam&lt;/code&gt; and &lt;code&gt;hamFoam&lt;/code&gt; solvers.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;ENVI-met:&lt;/strong&gt; Explored for comparative analysis but faced several challenges.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Rhino:&lt;/strong&gt; Potential use for 3D modeling and geometry preparation.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;WSL (Windows Subsystem for Linux):&lt;/strong&gt; Used to run simulations on an Ubuntu 20.04 environment.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;blueCFD-Core-2020:&lt;/strong&gt; Specific distribution of OpenFOAM used for the project.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;current-status&#34;&gt;Current Status&lt;/h2&gt; &lt;p&gt;The project involves ongoing efforts to refine simulations, troubleshoot persistent issues, and validate results against established benchmarks. Continued work on ENVI-met and debugging specific solver errors is in progress.&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qj7gHptpZig&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/qj7gHptpZig/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Marcelo Álvarez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (DC)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/alvarezdmarch&#34;&gt;alvarezdmarch&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Marcellus English&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Civil Engineering&lt;/td&gt; &lt;td&gt;CEE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mcenglish&#34;&gt;mcenglish&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Victor Wang&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/vdwang&#34;&gt;vdwang&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gonzalo Vegas&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/gvegasol&#34;&gt;gvegasol&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sina Rahimi&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architectural Science&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sinarhm&#34;&gt;sinarahimi&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-microclimate-umcf/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-microclimate-umcf/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-microclimate-umcf/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-microclimate-umcf/README.png" type="image/png" length="None" /> </item> <item> <title>25-Sp-Microclimate-LSTM-Kriging</title> <description>&lt;h1 id=&#34;urban-microclimate-prediction-hybrid-lstm-transformer-kriging&#34;&gt;Urban-Microclimate-Prediction-Hybrid-LSTM-Transformer-Kriging&lt;/h1&gt; &lt;p&gt;&lt;img src=&#34;./Figures/prediction_result_image.png&#34; width=&#34;300&#34; /&gt; &lt;img src=&#34;./Figures/prediction_result_2.png&#34; width=&#34;300&#34; /&gt;&lt;/p&gt; &lt;h1 id=&#34;microclimate-prediction-model&#34;&gt;🌦️ Microclimate Prediction Model&lt;/h1&gt; &lt;h2 id=&#34;overview&#34;&gt;🧭 Overview&lt;/h2&gt; &lt;p&gt;&lt;img src=&#34;./Figures/Diagram_1.jpg&#34; width=&#34;300&#34; /&gt; This project introduces a hybrid machine learning approach for urban microclimate prediction. It integrates time series forecasting (using LSTM and Transformer architecture) with spatial interpolation (Kriging) to model environmental conditions across the urban canopy layer.&lt;/p&gt; &lt;p&gt;Key inputs include: - Meteorological data: temperature, humidity, dew point - Urban features: land cover, 3D elevation, surface materials, shadow coverage, sun angle&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;work-distribution&#34;&gt;Work Distribution&lt;/h2&gt; &lt;p&gt;We’d like to share a quick update on what the team has been working on. For our convenience in tracking files, please see the suggested file naming guide below. If possible, kindly consider revising your file names accordingly. However, if the file name cannot be changed for any reason, please feel free to let me know.&lt;/p&gt; &lt;p&gt;1_ExtractUrbanFeatures.ipynb -- /krishgupta-CE /Thanasarn-Changnawa&lt;/p&gt; &lt;p&gt;1_1_ExtractBuildings.ipynb -- /krishgupta-CE /Thanasarn-Changnawa&lt;/p&gt; &lt;p&gt;1_2_ExtractShadows.ipynb -- /daytss /Thanasarn-Changnawa&lt;/p&gt; &lt;p&gt;1_3_ExtractSurfaceMaterials.ipnb -- /BenjaminHansyun&lt;/p&gt; &lt;p&gt;2_TrainModel.ipynb -- /yupengtang /zeyujiang8800 /Thanasarn-Changnawa&lt;/p&gt; &lt;p&gt;2_1_LSTM_Model_Eval.ipynb&lt;/p&gt; &lt;p&gt;2_2_(Model Name)&lt;/p&gt; &lt;p&gt;3_Inference.ipynb -- /zeyujiang8800 /Thanasarn-Changnawa&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;./Figures/Responsibilities.png&#34; width=&#34;300&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;geospatial-feature-engineering&#34;&gt;🌐 Geospatial Feature Engineering&lt;/h2&gt; &lt;h3 id=&#34;2d-spatial-data&#34;&gt;2D Spatial Data&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;12 distance vectors per grid point to features such as buildings, parks, libraries, parking, footways, grass, fitness centers, woods, and wetlands&lt;/li&gt; &lt;li&gt;Data sourced from OSMnx and GT Tree Viewer&lt;/li&gt; &lt;li&gt;Returns .csv file: grid_analysis.csv &lt;img src=&#34;./Figures/Spatial%20Table.png&#34; width=&#34;300&#34; /&gt; &lt;img src=&#34;./Figures/Spatial%20Map.png&#34; width=&#34;300&#34; /&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;building-elevation&#34;&gt;Building Elevation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Derived from DSM and DTM to compute building heights&lt;/li&gt; &lt;li&gt;Digital Terrain Model (DTM) for GT’s campus (.tif file) obtained through USGS EarthExplorer&lt;/li&gt; &lt;li&gt;Digital Surface Model (DSM) for GT’s campus (.tif file) obtained through OpenTopography&lt;/li&gt; &lt;li&gt;Returns .csv file: grid_with_ground_and_building_elevation.csv &lt;img src=&#34;./Figures/DTM%20figure.png&#34; width=&#34;300&#34; /&gt; &lt;img src=&#34;./Figures/elevation%20map.png&#34; width=&#34;300&#34; /&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;building-area-density&#34;&gt;Building Area Density&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Utilizes osmnx to find total building footprint per spatial unit&lt;/li&gt; &lt;li&gt;Returns .csv file: squares_with_building_areas.csv &lt;img src=&#34;./Figures/building%20areas%20map.png&#34; width=&#34;300&#34; /&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;surface-materials&#34;&gt;Surface Materials&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;OSM map tiles converted to material categories by pixel color &lt;img src=&#34;./Figures/Surface_Material_Workfow.png&#34; width=&#34;300&#34; /&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;shadow-coverage&#34;&gt;Shadow Coverage&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Calculated using Pybdshadow and Astral for sunlight/shadow estimation&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;sun-angle-dynamics&#34;&gt;Sun Angle Dynamics&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Sun angle included as a physical feature for seasonal generalization&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;project-structure&#34;&gt;📁 Project Structure&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Data Collection&lt;/strong&gt;: Automated via Selenium&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;: Spatial and environmental attributes&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Modeling&lt;/strong&gt;: Temporal Fusion Transformer with LSTM-Attention Encoder (TFT-LAE)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt;: Adam optimizer + MSE loss + early stopping&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: RMSE, MAPE, R², residual tracking&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;model-architecture-tft-lae&#34;&gt;🧠 Model Architecture: TFT-LAE&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;VSN&lt;/strong&gt;: Variable Selection Network&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Time2Vec&lt;/strong&gt;: Temporal embedding module&lt;/li&gt; &lt;li&gt;&lt;strong&gt;LSTM + Attention&lt;/strong&gt;: Captures time dependencies&lt;/li&gt; &lt;li&gt;&lt;strong&gt;GRN Decoder&lt;/strong&gt;: Multi-step forecast generation&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Workflow: Input → VSN → Time2Vec → LSTM+Attention → GRN → Output&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;feature-engineering-selection&#34;&gt;🧮 Feature Engineering &amp;amp; Selection&lt;/h2&gt; &lt;p&gt;Selected Features: - Meteorological: RH, DewPt, Azimuth, Altitude, ΔTemp - Temporal: hour_sin, hour_cos - Scaled with MinMaxScaler to ensure consistency&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;training-process&#34;&gt;🏋️‍♂️ Training Process&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Loss&lt;/strong&gt;: MSE&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;: Adam with weight decay&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Early stopping&lt;/strong&gt;: Prevents overfitting&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;: tqdm + best model saving&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;evaluation-process&#34;&gt;🌍 Evaluation Process&lt;/h2&gt; &lt;h3 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h3&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Source&lt;/th&gt; &lt;th&gt;Use&lt;/th&gt; &lt;th&gt;Location&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Atlanta Weather&lt;/td&gt; &lt;td&gt;Train time series&lt;/td&gt; &lt;td&gt;Atlanta, GA&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Singapore Grid&lt;/td&gt; &lt;td&gt;Train spatial Kriging&lt;/td&gt; &lt;td&gt;Singapore&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;GT Campus&lt;/td&gt; &lt;td&gt;Final test&lt;/td&gt; &lt;td&gt;Georgia Tech&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3 id=&#34;tools&#34;&gt;Tools&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Selenium for data scraping&lt;/li&gt; &lt;li&gt;Python for processing&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;workflow&#34;&gt;Workflow&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Scrape and clean data&lt;/li&gt; &lt;li&gt;Train time series model (Atlanta)&lt;/li&gt; &lt;li&gt;Train spatial interpolation (Singapore)&lt;/li&gt; &lt;li&gt;Apply both to Georgia Tech data&lt;/li&gt; &lt;li&gt;Evaluate with real measurements&lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;evaluation-and-prediction&#34;&gt;📊 Evaluation and Prediction&lt;/h2&gt; &lt;p&gt;Functions: - &lt;code&gt;predict_and_plot&lt;/code&gt;, &lt;code&gt;plot_full_sequence&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Metrics: - RMSE, MAPE, R²&lt;/p&gt; &lt;p&gt;Residuals: - Histogram and time-series plots to detect bias&lt;/p&gt; &lt;p&gt;Overfitting: - Train/test error comparison&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;problem-outlier-distortion&#34;&gt;🐞 Problem: Outlier Distortion&lt;/h2&gt; &lt;p&gt;Initial training data contained extreme values: - &lt;strong&gt;-51°C to 174°C&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Distorted MinMaxScaler and flattened predictions.&lt;/p&gt; &lt;h3 id=&#34;solution&#34;&gt;Solution&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Filtered to &lt;strong&gt;-15°C to 40°C&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Result: Better scaling, more generalization&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Lesson: Always validate input ranges before normalization.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;post-fix-evaluation&#34;&gt;📉 Post-Fix Evaluation&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Residuals became balanced and centered&lt;/li&gt; &lt;li&gt;Predictions improved but remained smooth&lt;/li&gt; &lt;li&gt;Future work: increase expressiveness and precision&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;summary&#34;&gt;✅ Summary&lt;/h2&gt; &lt;p&gt;This workflow combines spatial and temporal modeling for urban microclimate forecasting using: - Deep learning (TFT-LAE) - Spatial Kriging interpolation - Automated feature extraction and evaluation&lt;/p&gt; &lt;p&gt;It provides a framework for scalable, data-driven urban climate resilience solutions.&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=knRSFEzkwDA&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/knRSFEzkwDA/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Han‑Syun Shih&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/hshih38&#34;&gt;Benjaminhansyun&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Thanasarn Changnawa&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Thanasarn-Changnawa&#34;&gt;Thanasarn‑Changnawa&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Krish Gupta&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Civil Engineering&lt;/td&gt; &lt;td&gt;CEE&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/krishgupta-CE&#34;&gt;krishgupta‑CE&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Yupeng Tang&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/yupengtang&#34;&gt;yupengtang&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Dayeon Song&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/daytss&#34;&gt;daytss&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ze Yu Jiang&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/zeyujiang8800&#34;&gt;zeyujiang8800&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-microclimate-lstm-kriging/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-microclimate-lstm-kriging/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-microclimate-lstm-kriging/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-microclimate-lstm-kriging/README.png" type="image/png" length="None" /> </item> <item> <title>25-Sp-Energy</title> <description>&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&#34;#rhino-energy-prediction-plugin&#34;&gt;Rhino Energy Prediction Plugin&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#architecture&#34;&gt;Architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#workflow&#34;&gt;Workflow&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#tech-stack&#34;&gt;Tech Stack&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#energy-map&#34;&gt;Energy Map&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#overview-1&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#repository-structure&#34;&gt;Repository Structure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#getting-started&#34;&gt;Getting Started&lt;/a&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=&#34;#requirements-1&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#set-up-to-run-locally&#34;&gt;Set up to run locally&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#map-information&#34;&gt;Map Information&lt;/a&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=&#34;#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#extracting-vegetation-data&#34;&gt;Extracting Vegetation Data&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#overview-2&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#ndvi-analysis&#34;&gt;NDVI Analysis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#treecountsegheight&#34;&gt;TreeCountSegHeight&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#next-steps&#34;&gt;Next Steps&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#presentation&#34;&gt;Presentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;#team&#34;&gt;Team&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h1 id=&#34;rhino-energy-prediction-plugin&#34;&gt;&lt;a href=&#34;https://github.com/VIP-SMUR/25Sp-EnergyPlugin&#34;&gt;Rhino Energy Prediction Plugin&lt;/a&gt;&lt;/h1&gt; &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;Rhino Energy Prediction Plugin is designed to support architects in making energy-informed design decisions early in the building process. The plugin enables users to create or modify building models and receive predictions for heating and cooling loads using a machine learning (ML) model. Architects can gauge building energy performance early (concept stage) using the Rhino Energy Prediction Plugin. The plugin embeds a self-contained ONNX runtime directly in Grasshopper.&lt;/p&gt; &lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Initialization&lt;/strong&gt;&lt;br /&gt; Reads an ONNX model file path and sets up an &lt;code&gt;InferenceSession&lt;/code&gt; that exposes each input tensor’s name, datatype, and shape.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-Time Inference&lt;/strong&gt;&lt;br /&gt; Packs Grasshopper inputs into dense tensors, executes the ONNX model, and returns the first element of the output array as an energy load estimate.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;br /&gt; Companion Python script reads 3D building geometry and computes features such as roof area, window-to-wall ratio, floor area, and number of stories.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pure C# Runtime&lt;/strong&gt;&lt;br /&gt; Runs entirely in .NET via Microsoft’s ONNX Runtime—no Python interpreter required at inference time.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Component Initialization&lt;/strong&gt;&lt;br /&gt; The plugin reads the ONNX model path from the Grasshopper input.&lt;br /&gt; It then creates an &lt;code&gt;InferenceSession&lt;/code&gt; and retrieves input tensor metadata.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Input Packing&lt;/strong&gt;&lt;br /&gt; Grasshopper values are loaded into dense tensors that match the ONNX input shapes.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Inference&lt;/strong&gt;&lt;br /&gt; The plugin runs the ONNX model with the packed inputs and receives an output array.&lt;br /&gt; The first element of that array is sent to the Grasshopper output.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Feature Extraction Script&lt;/strong&gt;&lt;br /&gt; A Python helper extracts building features automatically by classifying layers named &lt;code&gt;Wall&lt;/code&gt;, &lt;code&gt;Slab&lt;/code&gt;, &lt;code&gt;Window&lt;/code&gt;, and &lt;code&gt;Roof&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Download the &lt;code&gt;VIP_Energy_Plugin&lt;/code&gt; folder. &lt;/li&gt; &lt;li&gt;Copy it to your Grasshopper Libraries folder: &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;C:\Users\YourUserName\AppData\Roaming\Grasshopper\Libraries &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Launch Rhino and open Grasshopper. &lt;/li&gt; &lt;li&gt;Drag the &lt;strong&gt;VIPPlugin&lt;/strong&gt; component from the Params tab onto the canvas. &lt;/li&gt; &lt;li&gt;Provide the ONNX model file path to the component input. &lt;/li&gt; &lt;li&gt;View the energy load prediction on the second output parameter.&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;workflow&#34;&gt;Workflow&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Open Rhino and start Grasshopper. &lt;/li&gt; &lt;li&gt;Place the VIPPlugin component and connect the ONNX model path. &lt;/li&gt; &lt;li&gt;Sketch or import a building mass in Rhino. &lt;/li&gt; &lt;li&gt;Run the feature extraction script to compute geometry parameters. &lt;/li&gt; &lt;li&gt;Grasshopper packs the inputs and runs the ONNX model. &lt;/li&gt; &lt;li&gt;Inspect the real-time energy load estimate.&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Rhino 7+&lt;/strong&gt; – Plugin host environment &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Windows OS&lt;/strong&gt; – .NET and Rhino SDK compatibility &lt;/li&gt; &lt;li&gt;&lt;strong&gt;.NET Framework 4.8+&lt;/strong&gt; – ONNX Runtime support &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Python 3.8+&lt;/strong&gt; – Feature extraction and model conversion scripts &lt;/li&gt; &lt;li&gt;&lt;strong&gt;ONNX model file&lt;/strong&gt; – Trained energy prediction model &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;tech-stack&#34;&gt;Tech Stack&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Rhino SDK (C#)&lt;/strong&gt; – Core plugin development and geometry handling &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Grasshopper (C#)&lt;/strong&gt; – Dynamic component architecture &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Microsoft ONNX Runtime&lt;/strong&gt; – High-performance model inference &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; – Building feature extraction and &lt;code&gt;.joblib&lt;/code&gt; → &lt;code&gt;.onnx&lt;/code&gt; conversion &lt;/li&gt; &lt;li&gt;&lt;strong&gt;scikit-learn / sklearn-onnx&lt;/strong&gt; – Model training and conversion &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;roadmap&#34;&gt;Roadmap&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-Time EUI Feedback&lt;/strong&gt;&lt;br /&gt; Provide energy use intensity updates as users modify height, WWR, and story count.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible Model Inputs&lt;/strong&gt;&lt;br /&gt; Detect parameter names and types automatically to support multiple climates and typologies.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-Format Support&lt;/strong&gt;&lt;br /&gt; Add seamless handling of both &lt;code&gt;.onnx&lt;/code&gt; and &lt;code&gt;.joblib&lt;/code&gt; models with built-in feature mapping.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Map Integration&lt;/strong&gt;&lt;br /&gt; Link with an energy prediction map to import existing building geometry and simulate retrofits.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h1 id=&#34;energy-map&#34;&gt;Energy Map&lt;/h1&gt; &lt;h2 id=&#34;overview_1&#34;&gt;Overview&lt;/h2&gt; &lt;div align=&#34;center&#34;&gt; &lt;img src=&#34;./Figures/heating.png&#34; width=&#34;400&#34;&gt; &lt;img src=&#34;./Figures/cooling.png&#34; width=&#34;400&#34;&gt; &lt;/div&gt; &lt;p&gt;The energy map provides visualizations of predicted building energy loads (heating and cooling) across an urban environment. Users can click on individual buildings to inspect specific feature details such as building height and estimated energy loads.&lt;/p&gt; &lt;p&gt;Given a GeoJSON file, the application calculates various building features, including height, shape (e.g., L-shaped, H-shaped), number of stories, building type (residential, commercial, etc.), energy code classification, HVAC category, roof area, rotation, wall area, and window area. These extracted features are then fed into a machine learning model, as described here.&lt;/p&gt; &lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt; &lt;p&gt;It is currently deployed on &lt;a href=&#34;https://render.com/&#34;&gt;Render&lt;/a&gt; at: https://two5sp-energyinbuildings-1.onrender.com/&lt;/p&gt; &lt;h3 id=&#34;render-frontend-settings&#34;&gt;Render Frontend Settings&lt;/h3&gt; &lt;p&gt;It&#39;s deployed as a Static Service with the following settings: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Service as &lt;strong&gt;Static Service&lt;/strong&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Root Directory set as &lt;code&gt;/energy_map/&lt;/code&gt; &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Pushlish Directory as &lt;code&gt;dist&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Build Command set as &lt;code&gt;yarn &amp;amp;&amp;amp; yarn build&lt;/code&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;render-backend-settings&#34;&gt;Render Backend Settings&lt;/h3&gt; &lt;p&gt;It&#39;s deployed as a Web Service with the following settings: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Service as &lt;strong&gt;Web Service&lt;/strong&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Root Directory set as &lt;code&gt;/energy_map/flask-api/&lt;/code&gt; &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Build Command set as &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; &lt;/p&gt; &lt;/li&gt; &lt;li&gt;Start Command as &lt;code&gt;python app.py&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;repository-structure&#34;&gt;Repository Structure&lt;/h2&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;energy map &lt;/span&gt;&lt;span id=&#34;__span-1-2&#34;&gt;&lt;a id=&#34;__codelineno-1-2&#34; name=&#34;__codelineno-1-2&#34; href=&#34;#__codelineno-1-2&#34;&gt;&lt;/a&gt;├─ api &lt;/span&gt;&lt;span id=&#34;__span-1-3&#34;&gt;&lt;a id=&#34;__codelineno-1-3&#34; name=&#34;__codelineno-1-3&#34; href=&#34;#__codelineno-1-3&#34;&gt;&lt;/a&gt;| ├─ calculate_building_features # Scripts to calculate building-level features like height, area, rotation &lt;/span&gt;&lt;span id=&#34;__span-1-4&#34;&gt;&lt;a id=&#34;__codelineno-1-4&#34; name=&#34;__codelineno-1-4&#34; href=&#34;#__codelineno-1-4&#34;&gt;&lt;/a&gt;| └─ route.ts # API routing configuration for feature calculations &lt;/span&gt;&lt;span id=&#34;__span-1-5&#34;&gt;&lt;a id=&#34;__codelineno-1-5&#34; name=&#34;__codelineno-1-5&#34; href=&#34;#__codelineno-1-5&#34;&gt;&lt;/a&gt;| &lt;/span&gt;&lt;span id=&#34;__span-1-6&#34;&gt;&lt;a id=&#34;__codelineno-1-6&#34; name=&#34;__codelineno-1-6&#34; href=&#34;#__codelineno-1-6&#34;&gt;&lt;/a&gt;├─ flask-api # Backend Flask server &lt;/span&gt;&lt;span id=&#34;__span-1-7&#34;&gt;&lt;a id=&#34;__codelineno-1-7&#34; name=&#34;__codelineno-1-7&#34; href=&#34;#__codelineno-1-7&#34;&gt;&lt;/a&gt;| &lt;/span&gt;&lt;span id=&#34;__span-1-8&#34;&gt;&lt;a id=&#34;__codelineno-1-8&#34; name=&#34;__codelineno-1-8&#34; href=&#34;#__codelineno-1-8&#34;&gt;&lt;/a&gt;├─ node_modules # Dependency libraries (auto-generated) &lt;/span&gt;&lt;span id=&#34;__span-1-9&#34;&gt;&lt;a id=&#34;__codelineno-1-9&#34; name=&#34;__codelineno-1-9&#34; href=&#34;#__codelineno-1-9&#34;&gt;&lt;/a&gt;├─ public # Static public assets &lt;/span&gt;&lt;span id=&#34;__span-1-10&#34;&gt;&lt;a id=&#34;__codelineno-1-10&#34; name=&#34;__codelineno-1-10&#34; href=&#34;#__codelineno-1-10&#34;&gt;&lt;/a&gt;├─ src &lt;/span&gt;&lt;span id=&#34;__span-1-11&#34;&gt;&lt;a id=&#34;__codelineno-1-11&#34; name=&#34;__codelineno-1-11&#34; href=&#34;#__codelineno-1-11&#34;&gt;&lt;/a&gt;| ├─ assets # Static files such as icons or images &lt;/span&gt;&lt;span id=&#34;__span-1-12&#34;&gt;&lt;a id=&#34;__codelineno-1-12&#34; name=&#34;__codelineno-1-12&#34; href=&#34;#__codelineno-1-12&#34;&gt;&lt;/a&gt;| ├─ App.tsx # Main application file &lt;/span&gt;&lt;span id=&#34;__span-1-13&#34;&gt;&lt;a id=&#34;__codelineno-1-13&#34; name=&#34;__codelineno-1-13&#34; href=&#34;#__codelineno-1-13&#34;&gt;&lt;/a&gt;| ├─ App.css # Application-level styling &lt;/span&gt;&lt;span id=&#34;__span-1-14&#34;&gt;&lt;a id=&#34;__codelineno-1-14&#34; name=&#34;__codelineno-1-14&#34; href=&#34;#__codelineno-1-14&#34;&gt;&lt;/a&gt;| ├─ index.css # Global styles &lt;/span&gt;&lt;span id=&#34;__span-1-15&#34;&gt;&lt;a id=&#34;__codelineno-1-15&#34; name=&#34;__codelineno-1-15&#34; href=&#34;#__codelineno-1-15&#34;&gt;&lt;/a&gt;| ├─ main.tsx # Application bootstrap and render entry &lt;/span&gt;&lt;span id=&#34;__span-1-16&#34;&gt;&lt;a id=&#34;__codelineno-1-16&#34; name=&#34;__codelineno-1-16&#34; href=&#34;#__codelineno-1-16&#34;&gt;&lt;/a&gt;| └─ components # React components for UI (buttons, feature displays, map container, map view) &lt;/span&gt;&lt;span id=&#34;__span-1-17&#34;&gt;&lt;a id=&#34;__codelineno-1-17&#34; name=&#34;__codelineno-1-17&#34; href=&#34;#__codelineno-1-17&#34;&gt;&lt;/a&gt;| ├─ ButtonComponent.tsx &lt;/span&gt;&lt;span id=&#34;__span-1-18&#34;&gt;&lt;a id=&#34;__codelineno-1-18&#34; name=&#34;__codelineno-1-18&#34; href=&#34;#__codelineno-1-18&#34;&gt;&lt;/a&gt;| | ├─ FeatureDisplay.tsx &lt;/span&gt;&lt;span id=&#34;__span-1-19&#34;&gt;&lt;a id=&#34;__codelineno-1-19&#34; name=&#34;__codelineno-1-19&#34; href=&#34;#__codelineno-1-19&#34;&gt;&lt;/a&gt;| | ├─ MapContainer.tsx &lt;/span&gt;&lt;span id=&#34;__span-1-20&#34;&gt;&lt;a id=&#34;__codelineno-1-20&#34; name=&#34;__codelineno-1-20&#34; href=&#34;#__codelineno-1-20&#34;&gt;&lt;/a&gt;| | ├─ MapView.tsx &lt;/span&gt;&lt;span id=&#34;__span-1-21&#34;&gt;&lt;a id=&#34;__codelineno-1-21&#34; name=&#34;__codelineno-1-21&#34; href=&#34;#__codelineno-1-21&#34;&gt;&lt;/a&gt;| └─ utils &lt;/span&gt;&lt;span id=&#34;__span-1-22&#34;&gt;&lt;a id=&#34;__codelineno-1-22&#34; name=&#34;__codelineno-1-22&#34; href=&#34;#__codelineno-1-22&#34;&gt;&lt;/a&gt;| └─ building.ts # Utility functions for parsing and handling building feature data &lt;/span&gt;&lt;span id=&#34;__span-1-23&#34;&gt;&lt;a id=&#34;__codelineno-1-23&#34; name=&#34;__codelineno-1-23&#34; href=&#34;#__codelineno-1-23&#34;&gt;&lt;/a&gt;└─ ... &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt; &lt;h3 id=&#34;requirements_1&#34;&gt;Requirements&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;Run with Python 3.12.5 (otherwise there are issues with the .pkl files)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Install &lt;a href=&#34;https://nodejs.org/en&#34;&gt;node.js&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;set-up-to-run-locally&#34;&gt;Set up to run locally&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Clone the repository using &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;git clone https://github.com/VIP-SMUR/25Sp-EnergyInBuildings-Com.git &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Navigate to the project folder &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;cd energy_map &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Run front end locally using &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;npm run dev &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;To run the flask backend, open a new terminal and navigate to the energy_map/app/flask-api folder. Make sure to have the required python libraries. You can then run app.py without any errors &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;pip install -r /path/to/requirements.txt &lt;/span&gt;&lt;span id=&#34;__span-5-2&#34;&gt;&lt;a id=&#34;__codelineno-5-2&#34; name=&#34;__codelineno-5-2&#34; href=&#34;#__codelineno-5-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-3&#34;&gt;&lt;a id=&#34;__codelineno-5-3&#34; name=&#34;__codelineno-5-3&#34; href=&#34;#__codelineno-5-3&#34;&gt;&lt;/a&gt;python app.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h1 id=&#34;map-information&#34;&gt;Map Information&lt;/h1&gt; &lt;h3 id=&#34;datasets&#34;&gt;Datasets&lt;/h3&gt; &lt;p&gt;The dataset is derived from the &lt;a href=&#34;https://overturemaps.org/&#34;&gt;Overture Maps Foundation&lt;/a&gt; building footprints, provided in GeoJSON&lt;/p&gt; &lt;hr /&gt; &lt;h1 id=&#34;extracting-vegetation-data&#34;&gt;Extracting Vegetation Data&lt;/h1&gt; &lt;h2 id=&#34;overview_2&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;We examined various methods of extracting vegetation data for use with the models due to the effect of shading on the heating and cooling load of nearby buildings.&lt;/p&gt; &lt;h2 id=&#34;ndvi-analysis&#34;&gt;NDVI Analysis&lt;/h2&gt; &lt;p&gt;NDVI (Normalized Difference Vegetation Index) is a metric used to quantify the health and density of vegetation from satellite imagery. Seemed promising at first, but does not provide any way of estimating vegetation height, which is likely needed as a metric for the model to be trained on.&lt;/p&gt; &lt;h2 id=&#34;treecountsegheight&#34;&gt;&lt;a href=&#34;https://github.com/sizhuoli/TreeCountSegHeight&#34;&gt;TreeCountSegHeight&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;A recently developed model called TreeCountSegHeight was also examined for potential integration with the model. It seemed to fit our purposes quite well, returning an estimate of tree height from input satellite imagery, but was found to be very computationally intensive. It may have the potential to yield results given sufficient hardware, but this was a stumbling point in the workflow. &lt;/p&gt; &lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt; &lt;p&gt;Continue searching for a lightweight/efficient way to extract vegetation height from satellite imagery.&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4AXZ__TYZlY&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/4AXZ__TYZlY/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Joseph M. Aerathu&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (HPB)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jma1999&#34;&gt;jma1999&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Anubha Mahajan&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/amahajan68&#34;&gt;amahajan68&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jessica Hernandez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jhernandez312&#34;&gt;jhernandez312&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hang Xu&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/HangXXXu&#34;&gt;HangXXXu&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jiayi Li&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jli3307&#34;&gt;jli3307&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Kavya Lalith&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/kavya-oop&#34;&gt;kavya‑oop&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Johnny Chen&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jxchen21&#34;&gt;jxchen21&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Shivam Patel&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/FlippyShivam&#34;&gt;FlippyShivam&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Yichao Shi&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture (DC)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/SHIyichao98&#34;&gt;SHIyichao98&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-energyinbuildings/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-energyinbuildings/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-energyinbuildings/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-energyinbuildings/README.png" type="image/png" length="None" /> </item> <item> <title>25-Sp-Neuroarchitecture</title> <description>&lt;h1 id=&#34;25sp-neuroarchitecture&#34;&gt;25Sp-Neuroarchitecture&lt;/h1&gt; &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt; &lt;p&gt;During the COVID-19 pandemic, lockdown measures like home isolation, online learning, and public space closures helped control the virus but also increased social isolation, loneliness, and mental health issues such as depression and anxiety. These challenges, including restricted freedom, limited mental health access, and financial stress, underscored the urgent need to address mental well-being.&lt;/p&gt; &lt;p&gt;Neuroarchitecture is an interdisciplinary field that combines principles of neuroscience with architecture and urban design. It studies how the built environment influences human behavior, emotions, and cognitive functions&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Current studies in &#34;Neuroarchitecture&#34; mainly emphasize physical health rather than mental health&lt;/li&gt; &lt;li&gt;&#34;Neuroarchitecture&#34; research remains at a conceptual level&lt;/li&gt; &lt;li&gt;The relationship between mental health and the urban built environment is nearly never explored across different age groups.&lt;/li&gt; &lt;li&gt;Many studies rely on subjective survey-based data collection instead of data-driven&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img alt=&#34;Description&#34; src=&#34;Figure/Description.jpg&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;spring-2025-neuroarchitecture-plan&#34;&gt;Spring 2025 Neuroarchitecture Plan&lt;/h2&gt; &lt;p&gt;Since In Fall 2024, we have already filtered papers which are aligned with our eligibility criteria, so we focused on the data extraction and text mining in this semester.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;Plan&#34; src=&#34;Figure/Plan.jpg&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;data-extraction&#34;&gt;Data Extraction&lt;/h2&gt; &lt;p&gt;Based on the Prisma we concluded last semester, we have 69 papers for data extraction continually(). We divided our data extraction templete into 4 part: Study Characteristics, Exposures, Outcomes, and main findings.Each section has corresponding subtopics. We allocate for extracting, Changda is responsible for 1-35, Sydney is reponsible for 36-69, Catherine odd studies, and Sam even studyies After we finished out part, we compare and conclude each of them into our final extraction to prepare for the next step of summarizing and reviewing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Data extraction template link:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;1-35:https://docs.google.com/spreadsheets/d/1dmjwXb4HLyvpfUUZywa7am7V2aKzJbMcyEQSukTinsg/edit?usp=sharing&lt;/p&gt; &lt;p&gt;36-69：https://docs.google.com/spreadsheets/d/1ZH4K2hzg9c5WXQHB95zIHeHFIp6cPviqGr89F73DKlU/edit?usp=sharing&lt;/p&gt; &lt;p&gt;Odd studies: https://docs.google.com/spreadsheets/d/1QcBIreRME7fBgll861OODxGawknsswH9EIXd4c0AnFA/edit?usp=sharing&lt;/p&gt; &lt;p&gt;Even studies: https://docs.google.com/spreadsheets/d/1W7AGIvFBVuOaBzlWEwXGdXNMYHH14X3dbDm6qOQqFyE/edit?usp=sharing&lt;/p&gt; &lt;h3 id=&#34;study-characteristics&#34;&gt;Study Characteristics&lt;/h3&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;study_metadata &lt;/span&gt;&lt;span id=&#34;__span-0-2&#34;&gt;&lt;a id=&#34;__codelineno-0-2&#34; name=&#34;__codelineno-0-2&#34; href=&#34;#__codelineno-0-2&#34;&gt;&lt;/a&gt;├── basic_info &lt;/span&gt;&lt;span id=&#34;__span-0-3&#34;&gt;&lt;a id=&#34;__codelineno-0-3&#34; name=&#34;__codelineno-0-3&#34; href=&#34;#__codelineno-0-3&#34;&gt;&lt;/a&gt;│ ├── Study ID (first author last name_year of publication &lt;/span&gt;&lt;span id=&#34;__span-0-4&#34;&gt;&lt;a id=&#34;__codelineno-0-4&#34; name=&#34;__codelineno-0-4&#34; href=&#34;#__codelineno-0-4&#34;&gt;&lt;/a&gt;│ ├── Full study title &lt;/span&gt;&lt;span id=&#34;__span-0-5&#34;&gt;&lt;a id=&#34;__codelineno-0-5&#34; name=&#34;__codelineno-0-5&#34; href=&#34;#__codelineno-0-5&#34;&gt;&lt;/a&gt;│ ├── List of authors &lt;/span&gt;&lt;span id=&#34;__span-0-6&#34;&gt;&lt;a id=&#34;__codelineno-0-6&#34; name=&#34;__codelineno-0-6&#34; href=&#34;#__codelineno-0-6&#34;&gt;&lt;/a&gt;│ ├── Year the study was published &lt;/span&gt;&lt;span id=&#34;__span-0-7&#34;&gt;&lt;a id=&#34;__codelineno-0-7&#34; name=&#34;__codelineno-0-7&#34; href=&#34;#__codelineno-0-7&#34;&gt;&lt;/a&gt;│ ├── ournal or source of publication &lt;/span&gt;&lt;span id=&#34;__span-0-8&#34;&gt;&lt;a id=&#34;__codelineno-0-8&#34; name=&#34;__codelineno-0-8&#34; href=&#34;#__codelineno-0-8&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-0-9&#34;&gt;&lt;a id=&#34;__codelineno-0-9&#34; name=&#34;__codelineno-0-9&#34; href=&#34;#__codelineno-0-9&#34;&gt;&lt;/a&gt;├── study_design &lt;/span&gt;&lt;span id=&#34;__span-0-10&#34;&gt;&lt;a id=&#34;__codelineno-0-10&#34; name=&#34;__codelineno-0-10&#34; href=&#34;#__codelineno-0-10&#34;&gt;&lt;/a&gt;│ ├── options &lt;/span&gt;&lt;span id=&#34;__span-0-11&#34;&gt;&lt;a id=&#34;__codelineno-0-11&#34; name=&#34;__codelineno-0-11&#34; href=&#34;#__codelineno-0-11&#34;&gt;&lt;/a&gt;│ │ ├── analytical_cross_sectional &lt;/span&gt;&lt;span id=&#34;__span-0-12&#34;&gt;&lt;a id=&#34;__codelineno-0-12&#34; name=&#34;__codelineno-0-12&#34; href=&#34;#__codelineno-0-12&#34;&gt;&lt;/a&gt;│ │ ├── case_report &lt;/span&gt;&lt;span id=&#34;__span-0-13&#34;&gt;&lt;a id=&#34;__codelineno-0-13&#34; name=&#34;__codelineno-0-13&#34; href=&#34;#__codelineno-0-13&#34;&gt;&lt;/a&gt;│ │ ├── case_series &lt;/span&gt;&lt;span id=&#34;__span-0-14&#34;&gt;&lt;a id=&#34;__codelineno-0-14&#34; name=&#34;__codelineno-0-14&#34; href=&#34;#__codelineno-0-14&#34;&gt;&lt;/a&gt;│ │ ├── case_control &lt;/span&gt;&lt;span id=&#34;__span-0-15&#34;&gt;&lt;a id=&#34;__codelineno-0-15&#34; name=&#34;__codelineno-0-15&#34; href=&#34;#__codelineno-0-15&#34;&gt;&lt;/a&gt;│ │ ├── cohort_observational &lt;/span&gt;&lt;span id=&#34;__span-0-16&#34;&gt;&lt;a id=&#34;__codelineno-0-16&#34; name=&#34;__codelineno-0-16&#34; href=&#34;#__codelineno-0-16&#34;&gt;&lt;/a&gt;│ │ ├── prevalence &lt;/span&gt;&lt;span id=&#34;__span-0-17&#34;&gt;&lt;a id=&#34;__codelineno-0-17&#34; name=&#34;__codelineno-0-17&#34; href=&#34;#__codelineno-0-17&#34;&gt;&lt;/a&gt;│ │ ├── qualitative &lt;/span&gt;&lt;span id=&#34;__span-0-18&#34;&gt;&lt;a id=&#34;__codelineno-0-18&#34; name=&#34;__codelineno-0-18&#34; href=&#34;#__codelineno-0-18&#34;&gt;&lt;/a&gt;│ │ ├── quasi_experimental &lt;/span&gt;&lt;span id=&#34;__span-0-19&#34;&gt;&lt;a id=&#34;__codelineno-0-19&#34; name=&#34;__codelineno-0-19&#34; href=&#34;#__codelineno-0-19&#34;&gt;&lt;/a&gt;│ │ ├── randomized_controlled_trial &lt;/span&gt;&lt;span id=&#34;__span-0-20&#34;&gt;&lt;a id=&#34;__codelineno-0-20&#34; name=&#34;__codelineno-0-20&#34; href=&#34;#__codelineno-0-20&#34;&gt;&lt;/a&gt;│ │ └── longitudinal &lt;/span&gt;&lt;span id=&#34;__span-0-21&#34;&gt;&lt;a id=&#34;__codelineno-0-21&#34; name=&#34;__codelineno-0-21&#34; href=&#34;#__codelineno-0-21&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-0-22&#34;&gt;&lt;a id=&#34;__codelineno-0-22&#34; name=&#34;__codelineno-0-22&#34; href=&#34;#__codelineno-0-22&#34;&gt;&lt;/a&gt;├── participant_info &lt;/span&gt;&lt;span id=&#34;__span-0-23&#34;&gt;&lt;a id=&#34;__codelineno-0-23&#34; name=&#34;__codelineno-0-23&#34; href=&#34;#__codelineno-0-23&#34;&gt;&lt;/a&gt;│ ├── age_range(16-60, Age eligibility criteria) &lt;/span&gt;&lt;span id=&#34;__span-0-24&#34;&gt;&lt;a id=&#34;__codelineno-0-24&#34; name=&#34;__codelineno-0-24&#34; href=&#34;#__codelineno-0-24&#34;&gt;&lt;/a&gt;│ ├── Mean (SD) of age &lt;/span&gt;&lt;span id=&#34;__span-0-25&#34;&gt;&lt;a id=&#34;__codelineno-0-25&#34; name=&#34;__codelineno-0-25&#34; href=&#34;#__codelineno-0-25&#34;&gt;&lt;/a&gt;│ ├── Number and percentage male/female &lt;/span&gt;&lt;span id=&#34;__span-0-26&#34;&gt;&lt;a id=&#34;__codelineno-0-26&#34; name=&#34;__codelineno-0-26&#34; href=&#34;#__codelineno-0-26&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-0-27&#34;&gt;&lt;a id=&#34;__codelineno-0-27&#34; name=&#34;__codelineno-0-27&#34; href=&#34;#__codelineno-0-27&#34;&gt;&lt;/a&gt;├── setting_and_context &lt;/span&gt;&lt;span id=&#34;__span-0-28&#34;&gt;&lt;a id=&#34;__codelineno-0-28&#34; name=&#34;__codelineno-0-28&#34; href=&#34;#__codelineno-0-28&#34;&gt;&lt;/a&gt;│ ├── Study population and setting &lt;/span&gt;&lt;span id=&#34;__span-0-29&#34;&gt;&lt;a id=&#34;__codelineno-0-29&#34; name=&#34;__codelineno-0-29&#34; href=&#34;#__codelineno-0-29&#34;&gt;&lt;/a&gt;│ ├── geographic_location(Country, city, region) &lt;/span&gt;&lt;span id=&#34;__span-0-30&#34;&gt;&lt;a id=&#34;__codelineno-0-30&#34; name=&#34;__codelineno-0-30&#34; href=&#34;#__codelineno-0-30&#34;&gt;&lt;/a&gt;│ └── Socioeconomic_factors &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;img alt=&#34;Research_type&#34; src=&#34;Figure/research_type.png&#34; /&gt; &lt;img alt=&#34;Population_type&#34; src=&#34;Figure/Population_types.png&#34; /&gt; A Brief Summary: 40 papers use cross sectional studies, most papers are from Asia, Europe, and North America, as well as virtual enviroment, for participant, most are university students and public.&lt;/p&gt; &lt;h3 id=&#34;exposures&#34;&gt;Exposures&lt;/h3&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;Exposures_metadata &lt;/span&gt;&lt;span id=&#34;__span-1-2&#34;&gt;&lt;a id=&#34;__codelineno-1-2&#34; name=&#34;__codelineno-1-2&#34; href=&#34;#__codelineno-1-2&#34;&gt;&lt;/a&gt;├── Exposure Type &lt;/span&gt;&lt;span id=&#34;__span-1-3&#34;&gt;&lt;a id=&#34;__codelineno-1-3&#34; name=&#34;__codelineno-1-3&#34; href=&#34;#__codelineno-1-3&#34;&gt;&lt;/a&gt;│ ├── Green &amp;amp; Blue Spaces &lt;/span&gt;&lt;span id=&#34;__span-1-4&#34;&gt;&lt;a id=&#34;__codelineno-1-4&#34; name=&#34;__codelineno-1-4&#34; href=&#34;#__codelineno-1-4&#34;&gt;&lt;/a&gt;│ ├── Public Spaces &lt;/span&gt;&lt;span id=&#34;__span-1-5&#34;&gt;&lt;a id=&#34;__codelineno-1-5&#34; name=&#34;__codelineno-1-5&#34; href=&#34;#__codelineno-1-5&#34;&gt;&lt;/a&gt;│ ├── Transportation and Mobility &lt;/span&gt;&lt;span id=&#34;__span-1-6&#34;&gt;&lt;a id=&#34;__codelineno-1-6&#34; name=&#34;__codelineno-1-6&#34; href=&#34;#__codelineno-1-6&#34;&gt;&lt;/a&gt;│ ├── Programmatic Function &lt;/span&gt;&lt;span id=&#34;__span-1-7&#34;&gt;&lt;a id=&#34;__codelineno-1-7&#34; name=&#34;__codelineno-1-7&#34; href=&#34;#__codelineno-1-7&#34;&gt;&lt;/a&gt;│ ├── Other &lt;/span&gt;&lt;span id=&#34;__span-1-8&#34;&gt;&lt;a id=&#34;__codelineno-1-8&#34; name=&#34;__codelineno-1-8&#34; href=&#34;#__codelineno-1-8&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-1-9&#34;&gt;&lt;a id=&#34;__codelineno-1-9&#34; name=&#34;__codelineno-1-9&#34; href=&#34;#__codelineno-1-9&#34;&gt;&lt;/a&gt;├── Categories &lt;/span&gt;&lt;span id=&#34;__span-1-10&#34;&gt;&lt;a id=&#34;__codelineno-1-10&#34; name=&#34;__codelineno-1-10&#34; href=&#34;#__codelineno-1-10&#34;&gt;&lt;/a&gt;├── Mesures &lt;/span&gt;&lt;span id=&#34;__span-1-11&#34;&gt;&lt;a id=&#34;__codelineno-1-11&#34; name=&#34;__codelineno-1-11&#34; href=&#34;#__codelineno-1-11&#34;&gt;&lt;/a&gt;├── Metrics &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;img alt=&#34;Exposure_type&#34; src=&#34;Figure/Exposure_type.png&#34; /&gt; &lt;img alt=&#34;Meaure_metrics&#34; src=&#34;Figure/Green_blue_categories_measure_metrics.jpg&#34; /&gt; &lt;/p&gt; &lt;p&gt;As for urban built environment, we divided into four categories: urban &amp;amp; blue space, public space, transportation and program function. There are 40 papers discussing green &amp;amp;blue space. Therefore, in this category, Park/Nature Reserve are mainly talking aboot, and most of them are meaured by survey, image(view analysis), and GIS method, in this case, the metric of vegetation percentage/density are used most among all the papers.&lt;/p&gt; &lt;h3 id=&#34;outcomes&#34;&gt;Outcomes&lt;/h3&gt; &lt;p&gt;&lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;Mental health or Well-Being &lt;/span&gt;&lt;span id=&#34;__span-2-2&#34;&gt;&lt;a id=&#34;__codelineno-2-2&#34; name=&#34;__codelineno-2-2&#34; href=&#34;#__codelineno-2-2&#34;&gt;&lt;/a&gt;├── Subcategories &lt;/span&gt;&lt;span id=&#34;__span-2-3&#34;&gt;&lt;a id=&#34;__codelineno-2-3&#34; name=&#34;__codelineno-2-3&#34; href=&#34;#__codelineno-2-3&#34;&gt;&lt;/a&gt;│ ├── Mental Health &lt;/span&gt;&lt;span id=&#34;__span-2-4&#34;&gt;&lt;a id=&#34;__codelineno-2-4&#34; name=&#34;__codelineno-2-4&#34; href=&#34;#__codelineno-2-4&#34;&gt;&lt;/a&gt;│ │ ├── Depression &lt;/span&gt;&lt;span id=&#34;__span-2-5&#34;&gt;&lt;a id=&#34;__codelineno-2-5&#34; name=&#34;__codelineno-2-5&#34; href=&#34;#__codelineno-2-5&#34;&gt;&lt;/a&gt;│ │ ├── Anxiety &lt;/span&gt;&lt;span id=&#34;__span-2-6&#34;&gt;&lt;a id=&#34;__codelineno-2-6&#34; name=&#34;__codelineno-2-6&#34; href=&#34;#__codelineno-2-6&#34;&gt;&lt;/a&gt;│ │ ├── PTSD &lt;/span&gt;&lt;span id=&#34;__span-2-7&#34;&gt;&lt;a id=&#34;__codelineno-2-7&#34; name=&#34;__codelineno-2-7&#34; href=&#34;#__codelineno-2-7&#34;&gt;&lt;/a&gt;│ ├── Well-Being &lt;/span&gt;&lt;span id=&#34;__span-2-8&#34;&gt;&lt;a id=&#34;__codelineno-2-8&#34; name=&#34;__codelineno-2-8&#34; href=&#34;#__codelineno-2-8&#34;&gt;&lt;/a&gt;│ │ ├── Psychological &lt;/span&gt;&lt;span id=&#34;__span-2-9&#34;&gt;&lt;a id=&#34;__codelineno-2-9&#34; name=&#34;__codelineno-2-9&#34; href=&#34;#__codelineno-2-9&#34;&gt;&lt;/a&gt;│ │ ├── Social &lt;/span&gt;&lt;span id=&#34;__span-2-10&#34;&gt;&lt;a id=&#34;__codelineno-2-10&#34; name=&#34;__codelineno-2-10&#34; href=&#34;#__codelineno-2-10&#34;&gt;&lt;/a&gt;│ │ ├── Physical &lt;/span&gt;&lt;span id=&#34;__span-2-11&#34;&gt;&lt;a id=&#34;__codelineno-2-11&#34; name=&#34;__codelineno-2-11&#34; href=&#34;#__codelineno-2-11&#34;&gt;&lt;/a&gt;│ │ ├── Life satisfaction &lt;/span&gt;&lt;span id=&#34;__span-2-12&#34;&gt;&lt;a id=&#34;__codelineno-2-12&#34; name=&#34;__codelineno-2-12&#34; href=&#34;#__codelineno-2-12&#34;&gt;&lt;/a&gt;│ │ ├── Other &lt;/span&gt;&lt;span id=&#34;__span-2-13&#34;&gt;&lt;a id=&#34;__codelineno-2-13&#34; name=&#34;__codelineno-2-13&#34; href=&#34;#__codelineno-2-13&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-2-14&#34;&gt;&lt;a id=&#34;__codelineno-2-14&#34; name=&#34;__codelineno-2-14&#34; href=&#34;#__codelineno-2-14&#34;&gt;&lt;/a&gt;├── Measures &lt;/span&gt;&lt;span id=&#34;__span-2-15&#34;&gt;&lt;a id=&#34;__codelineno-2-15&#34; name=&#34;__codelineno-2-15&#34; href=&#34;#__codelineno-2-15&#34;&gt;&lt;/a&gt;│ ├── Mental Health &lt;/span&gt;&lt;span id=&#34;__span-2-16&#34;&gt;&lt;a id=&#34;__codelineno-2-16&#34; name=&#34;__codelineno-2-16&#34; href=&#34;#__codelineno-2-16&#34;&gt;&lt;/a&gt;│ │ ├── Diagnoses &lt;/span&gt;&lt;span id=&#34;__span-2-17&#34;&gt;&lt;a id=&#34;__codelineno-2-17&#34; name=&#34;__codelineno-2-17&#34; href=&#34;#__codelineno-2-17&#34;&gt;&lt;/a&gt;│ │ ├── Symptoms &lt;/span&gt;&lt;span id=&#34;__span-2-18&#34;&gt;&lt;a id=&#34;__codelineno-2-18&#34; name=&#34;__codelineno-2-18&#34; href=&#34;#__codelineno-2-18&#34;&gt;&lt;/a&gt;│ │ ├── Others &lt;/span&gt;&lt;span id=&#34;__span-2-19&#34;&gt;&lt;a id=&#34;__codelineno-2-19&#34; name=&#34;__codelineno-2-19&#34; href=&#34;#__codelineno-2-19&#34;&gt;&lt;/a&gt;│ ├── Well-Being &lt;/span&gt;&lt;span id=&#34;__span-2-20&#34;&gt;&lt;a id=&#34;__codelineno-2-20&#34; name=&#34;__codelineno-2-20&#34; href=&#34;#__codelineno-2-20&#34;&gt;&lt;/a&gt;│ │ ├── Interview &lt;/span&gt;&lt;span id=&#34;__span-2-21&#34;&gt;&lt;a id=&#34;__codelineno-2-21&#34; name=&#34;__codelineno-2-21&#34; href=&#34;#__codelineno-2-21&#34;&gt;&lt;/a&gt;│ │ ├── Questionare &lt;/span&gt;&lt;span id=&#34;__span-2-22&#34;&gt;&lt;a id=&#34;__codelineno-2-22&#34; name=&#34;__codelineno-2-22&#34; href=&#34;#__codelineno-2-22&#34;&gt;&lt;/a&gt;│ │ ├── Survey &lt;/span&gt;&lt;span id=&#34;__span-2-23&#34;&gt;&lt;a id=&#34;__codelineno-2-23&#34; name=&#34;__codelineno-2-23&#34; href=&#34;#__codelineno-2-23&#34;&gt;&lt;/a&gt;│ │ ├── Other &lt;/span&gt;&lt;span id=&#34;__span-2-24&#34;&gt;&lt;a id=&#34;__codelineno-2-24&#34; name=&#34;__codelineno-2-24&#34; href=&#34;#__codelineno-2-24&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-2-25&#34;&gt;&lt;a id=&#34;__codelineno-2-25&#34; name=&#34;__codelineno-2-25&#34; href=&#34;#__codelineno-2-25&#34;&gt;&lt;/a&gt;├── Specific Measures &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;img alt=&#34;Outcomes&#34; src=&#34;Figure/outcomes.png&#34; /&gt; &lt;/p&gt; &lt;p&gt;We begin by identifying whether each paper addresses mental health, well-being, or both. We then categorize them into specific subdomains: for mental health, the categories include depression, anxiety, and PTSD; for well-being, the categories cover psychological, social, physical well-being, and life satisfaction. Following this, we identify the instruments used to assess these outcomes—such as questionnaires or surveys—and specify the exact measurement tools applied. Among the reviewed studies, 37 focus exclusively on well-being, 16 exclusively on mental health, and 9 address both.&lt;/p&gt; &lt;h3 id=&#34;main-findings&#34;&gt;Main Findings&lt;/h3&gt; &lt;p&gt;&lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;Main Findings &lt;/span&gt;&lt;span id=&#34;__span-3-2&#34;&gt;&lt;a id=&#34;__codelineno-3-2&#34; name=&#34;__codelineno-3-2&#34; href=&#34;#__codelineno-3-2&#34;&gt;&lt;/a&gt;├── Aims/Research Questions &lt;/span&gt;&lt;span id=&#34;__span-3-3&#34;&gt;&lt;a id=&#34;__codelineno-3-3&#34; name=&#34;__codelineno-3-3&#34; href=&#34;#__codelineno-3-3&#34;&gt;&lt;/a&gt;├── Main Findings &lt;/span&gt;&lt;span id=&#34;__span-3-4&#34;&gt;&lt;a id=&#34;__codelineno-3-4&#34; name=&#34;__codelineno-3-4&#34; href=&#34;#__codelineno-3-4&#34;&gt;&lt;/a&gt;├── Statistical methods used &lt;/span&gt;&lt;span id=&#34;__span-3-5&#34;&gt;&lt;a id=&#34;__codelineno-3-5&#34; name=&#34;__codelineno-3-5&#34; href=&#34;#__codelineno-3-5&#34;&gt;&lt;/a&gt;├── Effect Size (if reported) &lt;/span&gt;&lt;span id=&#34;__span-3-6&#34;&gt;&lt;a id=&#34;__codelineno-3-6&#34; name=&#34;__codelineno-3-6&#34; href=&#34;#__codelineno-3-6&#34;&gt;&lt;/a&gt;├── Strengths &lt;/span&gt;&lt;span id=&#34;__span-3-7&#34;&gt;&lt;a id=&#34;__codelineno-3-7&#34; name=&#34;__codelineno-3-7&#34; href=&#34;#__codelineno-3-7&#34;&gt;&lt;/a&gt;├── Limitations &lt;/span&gt;&lt;span id=&#34;__span-3-8&#34;&gt;&lt;a id=&#34;__codelineno-3-8&#34; name=&#34;__codelineno-3-8&#34; href=&#34;#__codelineno-3-8&#34;&gt;&lt;/a&gt;├── Policy Implications &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;img alt=&#34;statistic_method&#34; src=&#34;Figure/statistic_method.png&#34; /&gt; &lt;/p&gt; &lt;p&gt;Finally, we extract the “main findings” section from each study, focusing on the research aim, statistical methods, effect sizes, strengths, limitations, and policy implications. Given the complexity of statistical findings, a detailed summary will be provided at a later stage. For now, we visualized the types of statistical methods used across the 69 studies. Among these, Structural Equation Modeling (SEM) emerged as one of the most common techniques.&lt;/p&gt; &lt;p&gt;## Text Mining ## ### PDF Inititial Collecting and Cleaning ###&lt;/p&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;mistral_workflow &lt;/span&gt;&lt;span id=&#34;__span-4-2&#34;&gt;&lt;a id=&#34;__codelineno-4-2&#34; name=&#34;__codelineno-4-2&#34; href=&#34;#__codelineno-4-2&#34;&gt;&lt;/a&gt;├── call_mistral_api # Step 1: Call the Mistral API &lt;/span&gt;&lt;span id=&#34;__span-4-3&#34;&gt;&lt;a id=&#34;__codelineno-4-3&#34; name=&#34;__codelineno-4-3&#34; href=&#34;#__codelineno-4-3&#34;&gt;&lt;/a&gt;├── generate_json_output # Step 2: Generate JSON output(Using OCR Scanning) &lt;/span&gt;&lt;span id=&#34;__span-4-4&#34;&gt;&lt;a id=&#34;__codelineno-4-4&#34; name=&#34;__codelineno-4-4&#34; href=&#34;#__codelineno-4-4&#34;&gt;&lt;/a&gt;│ └── table_characteristic # If JSON is tabular, it&amp;#39;s convenient to clean &lt;/span&gt;&lt;span id=&#34;__span-4-5&#34;&gt;&lt;a id=&#34;__codelineno-4-5&#34; name=&#34;__codelineno-4-5&#34; href=&#34;#__codelineno-4-5&#34;&gt;&lt;/a&gt;├── reindex_json_sections # Step 3: Re-index JSON sections &lt;/span&gt;&lt;span id=&#34;__span-4-6&#34;&gt;&lt;a id=&#34;__codelineno-4-6&#34; name=&#34;__codelineno-4-6&#34; href=&#34;#__codelineno-4-6&#34;&gt;&lt;/a&gt;├── remove_unwanted_sections # Step 4: Remove unnecessary sections &lt;/span&gt;&lt;span id=&#34;__span-4-7&#34;&gt;&lt;a id=&#34;__codelineno-4-7&#34; name=&#34;__codelineno-4-7&#34; href=&#34;#__codelineno-4-7&#34;&gt;&lt;/a&gt;└── Initial Cleanin Details # Step 5: Initial Cleanin Details &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h4 id=&#34;pdf-initial-cleaning-results-paper-json-after-initial-cleaning&#34;&gt;PDF Initial Cleaning Results: 📁 &lt;a href=&#34;./paper%20json%20after%20initial%20cleaning/&#34;&gt;&lt;code&gt;paper json after initial cleaning&lt;/code&gt;&lt;/a&gt;&lt;/h4&gt; &lt;h3 id=&#34;using-nltk-filtering-wanted-and-unwanted-tokens&#34;&gt;Using NLTK Filtering wanted and unwanted tokens&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;FLow Chart&lt;/strong&gt;&lt;/p&gt; &lt;pre class=&#34;mermaid&#34;&gt;&lt;code&gt;flowchart TD A[Tokenize and preprocess text: lowercase, clean symbols url,etc, keep collocations] B[Filter unnecessary symbols: remove degree, ampersand, percent, hash, at, exclam] C[Count word frequencies and delete common content] D[Remove text in parentheses] E[Ignore numbered lists like 1-dot item, 2-dot item] F[Handle compound words: keep phrases like machine learning together] A --&amp;gt; B --&amp;gt; C --&amp;gt; D --&amp;gt; E --&amp;gt; F&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;import nltk &lt;/span&gt;&lt;span id=&#34;__span-5-2&#34;&gt;&lt;a id=&#34;__codelineno-5-2&#34; name=&#34;__codelineno-5-2&#34; href=&#34;#__codelineno-5-2&#34;&gt;&lt;/a&gt;from nltk.corpus import names, stopwords &lt;/span&gt;&lt;span id=&#34;__span-5-3&#34;&gt;&lt;a id=&#34;__codelineno-5-3&#34; name=&#34;__codelineno-5-3&#34; href=&#34;#__codelineno-5-3&#34;&gt;&lt;/a&gt;from nltk.tokenize import word_tokenize &lt;/span&gt;&lt;span id=&#34;__span-5-4&#34;&gt;&lt;a id=&#34;__codelineno-5-4&#34; name=&#34;__codelineno-5-4&#34; href=&#34;#__codelineno-5-4&#34;&gt;&lt;/a&gt;import re &lt;/span&gt;&lt;span id=&#34;__span-5-5&#34;&gt;&lt;a id=&#34;__codelineno-5-5&#34; name=&#34;__codelineno-5-5&#34; href=&#34;#__codelineno-5-5&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-6&#34;&gt;&lt;a id=&#34;__codelineno-5-6&#34; name=&#34;__codelineno-5-6&#34; href=&#34;#__codelineno-5-6&#34;&gt;&lt;/a&gt;# Download required resources &lt;/span&gt;&lt;span id=&#34;__span-5-7&#34;&gt;&lt;a id=&#34;__codelineno-5-7&#34; name=&#34;__codelineno-5-7&#34; href=&#34;#__codelineno-5-7&#34;&gt;&lt;/a&gt;nltk.download(&amp;quot;punkt&amp;quot;) &lt;/span&gt;&lt;span id=&#34;__span-5-8&#34;&gt;&lt;a id=&#34;__codelineno-5-8&#34; name=&#34;__codelineno-5-8&#34; href=&#34;#__codelineno-5-8&#34;&gt;&lt;/a&gt;nltk.download(&amp;quot;averaged_perceptron_tagger&amp;quot;) &lt;/span&gt;&lt;span id=&#34;__span-5-9&#34;&gt;&lt;a id=&#34;__codelineno-5-9&#34; name=&#34;__codelineno-5-9&#34; href=&#34;#__codelineno-5-9&#34;&gt;&lt;/a&gt;nltk.download(&amp;quot;names&amp;quot;) &lt;/span&gt;&lt;span id=&#34;__span-5-10&#34;&gt;&lt;a id=&#34;__codelineno-5-10&#34; name=&#34;__codelineno-5-10&#34; href=&#34;#__codelineno-5-10&#34;&gt;&lt;/a&gt;nltk.download(&amp;quot;stopwords&amp;quot;) &lt;/span&gt;&lt;span id=&#34;__span-5-11&#34;&gt;&lt;a id=&#34;__codelineno-5-11&#34; name=&#34;__codelineno-5-11&#34; href=&#34;#__codelineno-5-11&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-12&#34;&gt;&lt;a id=&#34;__codelineno-5-12&#34; name=&#34;__codelineno-5-12&#34; href=&#34;#__codelineno-5-12&#34;&gt;&lt;/a&gt;# Load resources &lt;/span&gt;&lt;span id=&#34;__span-5-13&#34;&gt;&lt;a id=&#34;__codelineno-5-13&#34; name=&#34;__codelineno-5-13&#34; href=&#34;#__codelineno-5-13&#34;&gt;&lt;/a&gt;all_names = set(names.words()) &lt;/span&gt;&lt;span id=&#34;__span-5-14&#34;&gt;&lt;a id=&#34;__codelineno-5-14&#34; name=&#34;__codelineno-5-14&#34; href=&#34;#__codelineno-5-14&#34;&gt;&lt;/a&gt;custom_stopwords = set(stopwords.words(&amp;quot;english&amp;quot;)) &lt;/span&gt;&lt;span id=&#34;__span-5-15&#34;&gt;&lt;a id=&#34;__codelineno-5-15&#34; name=&#34;__codelineno-5-15&#34; href=&#34;#__codelineno-5-15&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-16&#34;&gt;&lt;a id=&#34;__codelineno-5-16&#34; name=&#34;__codelineno-5-16&#34; href=&#34;#__codelineno-5-16&#34;&gt;&lt;/a&gt;# Define custom collocations &lt;/span&gt;&lt;span id=&#34;__span-5-17&#34;&gt;&lt;a id=&#34;__codelineno-5-17&#34; name=&#34;__codelineno-5-17&#34; href=&#34;#__codelineno-5-17&#34;&gt;&lt;/a&gt;custom_collocations = { &lt;/span&gt;&lt;span id=&#34;__span-5-18&#34;&gt;&lt;a id=&#34;__codelineno-5-18&#34; name=&#34;__codelineno-5-18&#34; href=&#34;#__codelineno-5-18&#34;&gt;&lt;/a&gt; &amp;quot;machine learning&amp;quot;, &amp;quot;deep learning&amp;quot;, &amp;quot;artificial intelligence&amp;quot;, &amp;quot;neural network&amp;quot;, &lt;/span&gt;&lt;span id=&#34;__span-5-19&#34;&gt;&lt;a id=&#34;__codelineno-5-19&#34; name=&#34;__codelineno-5-19&#34; href=&#34;#__codelineno-5-19&#34;&gt;&lt;/a&gt; &amp;quot;natural language processing&amp;quot;, &amp;quot;computer vision&amp;quot;, &amp;quot;data science&amp;quot;, &amp;quot;big data&amp;quot;, &lt;/span&gt;&lt;span id=&#34;__span-5-20&#34;&gt;&lt;a id=&#34;__codelineno-5-20&#34; name=&#34;__codelineno-5-20&#34; href=&#34;#__codelineno-5-20&#34;&gt;&lt;/a&gt; &amp;quot;number theory&amp;quot;, &amp;quot;complex analysis&amp;quot;, &amp;quot;linear algebra&amp;quot;, &amp;quot;gradient descent&amp;quot;, &lt;/span&gt;&lt;span id=&#34;__span-5-21&#34;&gt;&lt;a id=&#34;__codelineno-5-21&#34; name=&#34;__codelineno-5-21&#34; href=&#34;#__codelineno-5-21&#34;&gt;&lt;/a&gt; &amp;quot;support vector machine&amp;quot;, &amp;quot;random forest&amp;quot;, &amp;quot;decision tree&amp;quot;, &amp;quot;reinforcement learning&amp;quot;, &lt;/span&gt;&lt;span id=&#34;__span-5-22&#34;&gt;&lt;a id=&#34;__codelineno-5-22&#34; name=&#34;__codelineno-5-22&#34; href=&#34;#__codelineno-5-22&#34;&gt;&lt;/a&gt; &amp;quot;urban planning&amp;quot;, &amp;quot;photo simulation&amp;quot;, &amp;quot;green spaces&amp;quot;, &amp;quot;climate change&amp;quot;, &lt;/span&gt;&lt;span id=&#34;__span-5-23&#34;&gt;&lt;a id=&#34;__codelineno-5-23&#34; name=&#34;__codelineno-5-23&#34; href=&#34;#__codelineno-5-23&#34;&gt;&lt;/a&gt; &amp;quot;pedestrian streets&amp;quot;, &amp;quot;traffic congestion&amp;quot;, &amp;quot;sustainability policies&amp;quot; &lt;/span&gt;&lt;span id=&#34;__span-5-24&#34;&gt;&lt;a id=&#34;__codelineno-5-24&#34; name=&#34;__codelineno-5-24&#34; href=&#34;#__codelineno-5-24&#34;&gt;&lt;/a&gt;} &lt;/span&gt;&lt;span id=&#34;__span-5-25&#34;&gt;&lt;a id=&#34;__codelineno-5-25&#34; name=&#34;__codelineno-5-25&#34; href=&#34;#__codelineno-5-25&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-26&#34;&gt;&lt;a id=&#34;__codelineno-5-26&#34; name=&#34;__codelineno-5-26&#34; href=&#34;#__codelineno-5-26&#34;&gt;&lt;/a&gt;# Text cleaning and tokenization &lt;/span&gt;&lt;span id=&#34;__span-5-27&#34;&gt;&lt;a id=&#34;__codelineno-5-27&#34; name=&#34;__codelineno-5-27&#34; href=&#34;#__codelineno-5-27&#34;&gt;&lt;/a&gt;def clean_and_tokenize(text): &lt;/span&gt;&lt;span id=&#34;__span-5-28&#34;&gt;&lt;a id=&#34;__codelineno-5-28&#34; name=&#34;__codelineno-5-28&#34; href=&#34;#__codelineno-5-28&#34;&gt;&lt;/a&gt; text = text.lower() &lt;/span&gt;&lt;span id=&#34;__span-5-29&#34;&gt;&lt;a id=&#34;__codelineno-5-29&#34; name=&#34;__codelineno-5-29&#34; href=&#34;#__codelineno-5-29&#34;&gt;&lt;/a&gt; text = re.sub(r&amp;quot;\bwww\.|\S+\.\w{2,3}\b&amp;quot;, &amp;quot; &amp;quot;, text) &lt;/span&gt;&lt;span id=&#34;__span-5-30&#34;&gt;&lt;a id=&#34;__codelineno-5-30&#34; name=&#34;__codelineno-5-30&#34; href=&#34;#__codelineno-5-30&#34;&gt;&lt;/a&gt; text = re.sub(r&amp;quot;\b(et|et\s+al|et\sal)\b&amp;quot;, &amp;quot; &amp;quot;, text) &lt;/span&gt;&lt;span id=&#34;__span-5-31&#34;&gt;&lt;a id=&#34;__codelineno-5-31&#34; name=&#34;__codelineno-5-31&#34; href=&#34;#__codelineno-5-31&#34;&gt;&lt;/a&gt; text = re.sub(r&amp;quot;\b\d+(st|nd|rd|th)\b&amp;quot;, &amp;quot; &amp;quot;, text) &lt;/span&gt;&lt;span id=&#34;__span-5-32&#34;&gt;&lt;a id=&#34;__codelineno-5-32&#34; name=&#34;__codelineno-5-32&#34; href=&#34;#__codelineno-5-32&#34;&gt;&lt;/a&gt; text = re.sub(r&amp;quot;[^a-z\s]&amp;quot;, &amp;quot; &amp;quot;, text) &lt;/span&gt;&lt;span id=&#34;__span-5-33&#34;&gt;&lt;a id=&#34;__codelineno-5-33&#34; name=&#34;__codelineno-5-33&#34; href=&#34;#__codelineno-5-33&#34;&gt;&lt;/a&gt; text = re.sub(r&amp;quot;\b[a-z]{1,2}\b&amp;quot;, &amp;quot; &amp;quot;, text) &lt;/span&gt;&lt;span id=&#34;__span-5-34&#34;&gt;&lt;a id=&#34;__codelineno-5-34&#34; name=&#34;__codelineno-5-34&#34; href=&#34;#__codelineno-5-34&#34;&gt;&lt;/a&gt; return word_tokenize(text) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;h3 id=&#34;bigrams-and-colocations-compound-words-and-solutions-to-getting-them&#34;&gt;Bigrams and Colocations: Compound words and solutions to getting them&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;# Define a threshold for frequent bigrams &lt;/span&gt;&lt;span id=&#34;__span-6-2&#34;&gt;&lt;a id=&#34;__codelineno-6-2&#34; name=&#34;__codelineno-6-2&#34; href=&#34;#__codelineno-6-2&#34;&gt;&lt;/a&gt;frequent_bigrams = { &lt;/span&gt;&lt;span id=&#34;__span-6-3&#34;&gt;&lt;a id=&#34;__codelineno-6-3&#34; name=&#34;__codelineno-6-3&#34; href=&#34;#__codelineno-6-3&#34;&gt;&lt;/a&gt; &amp;quot;_&amp;quot;.join(bg) for bg, freq in bigram_freq.items() &lt;/span&gt;&lt;span id=&#34;__span-6-4&#34;&gt;&lt;a id=&#34;__codelineno-6-4&#34; name=&#34;__codelineno-6-4&#34; href=&#34;#__codelineno-6-4&#34;&gt;&lt;/a&gt; if freq &amp;gt; 5 and is_valid_bigram(bg) &lt;/span&gt;&lt;span id=&#34;__span-6-5&#34;&gt;&lt;a id=&#34;__codelineno-6-5&#34; name=&#34;__codelineno-6-5&#34; href=&#34;#__codelineno-6-5&#34;&gt;&lt;/a&gt;} &lt;/span&gt;&lt;span id=&#34;__span-6-6&#34;&gt;&lt;a id=&#34;__codelineno-6-6&#34; name=&#34;__codelineno-6-6&#34; href=&#34;#__codelineno-6-6&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-6-7&#34;&gt;&lt;a id=&#34;__codelineno-6-7&#34; name=&#34;__codelineno-6-7&#34; href=&#34;#__codelineno-6-7&#34;&gt;&lt;/a&gt;# Merge detected bigrams + predefined collocations &lt;/span&gt;&lt;span id=&#34;__span-6-8&#34;&gt;&lt;a id=&#34;__codelineno-6-8&#34; name=&#34;__codelineno-6-8&#34; href=&#34;#__codelineno-6-8&#34;&gt;&lt;/a&gt;all_collocations = frequent_bigrams.union(custom_collocations) &lt;/span&gt;&lt;span id=&#34;__span-6-9&#34;&gt;&lt;a id=&#34;__codelineno-6-9&#34; name=&#34;__codelineno-6-9&#34; href=&#34;#__codelineno-6-9&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-6-10&#34;&gt;&lt;a id=&#34;__codelineno-6-10&#34; name=&#34;__codelineno-6-10&#34; href=&#34;#__codelineno-6-10&#34;&gt;&lt;/a&gt;# Reconstruct tokens with collocations &lt;/span&gt;&lt;span id=&#34;__span-6-11&#34;&gt;&lt;a id=&#34;__codelineno-6-11&#34; name=&#34;__codelineno-6-11&#34; href=&#34;#__codelineno-6-11&#34;&gt;&lt;/a&gt;i = 0 &lt;/span&gt;&lt;span id=&#34;__span-6-12&#34;&gt;&lt;a id=&#34;__codelineno-6-12&#34; name=&#34;__codelineno-6-12&#34; href=&#34;#__codelineno-6-12&#34;&gt;&lt;/a&gt;merged_tokens = [] &lt;/span&gt;&lt;span id=&#34;__span-6-13&#34;&gt;&lt;a id=&#34;__codelineno-6-13&#34; name=&#34;__codelineno-6-13&#34; href=&#34;#__codelineno-6-13&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-6-14&#34;&gt;&lt;a id=&#34;__codelineno-6-14&#34; name=&#34;__codelineno-6-14&#34; href=&#34;#__codelineno-6-14&#34;&gt;&lt;/a&gt;while i &amp;lt; len(tokens) - 1: &lt;/span&gt;&lt;span id=&#34;__span-6-15&#34;&gt;&lt;a id=&#34;__codelineno-6-15&#34; name=&#34;__codelineno-6-15&#34; href=&#34;#__codelineno-6-15&#34;&gt;&lt;/a&gt; bigram = f&amp;quot;{tokens[i]}_{tokens[i+1]}&amp;quot; &lt;/span&gt;&lt;span id=&#34;__span-6-16&#34;&gt;&lt;a id=&#34;__codelineno-6-16&#34; name=&#34;__codelineno-6-16&#34; href=&#34;#__codelineno-6-16&#34;&gt;&lt;/a&gt; if bigram in all_collocations: &lt;/span&gt;&lt;span id=&#34;__span-6-17&#34;&gt;&lt;a id=&#34;__codelineno-6-17&#34; name=&#34;__codelineno-6-17&#34; href=&#34;#__codelineno-6-17&#34;&gt;&lt;/a&gt; merged_tokens.append(bigram) &lt;/span&gt;&lt;span id=&#34;__span-6-18&#34;&gt;&lt;a id=&#34;__codelineno-6-18&#34; name=&#34;__codelineno-6-18&#34; href=&#34;#__codelineno-6-18&#34;&gt;&lt;/a&gt; i += 2 &lt;/span&gt;&lt;span id=&#34;__span-6-19&#34;&gt;&lt;a id=&#34;__codelineno-6-19&#34; name=&#34;__codelineno-6-19&#34; href=&#34;#__codelineno-6-19&#34;&gt;&lt;/a&gt; else: &lt;/span&gt;&lt;span id=&#34;__span-6-20&#34;&gt;&lt;a id=&#34;__codelineno-6-20&#34; name=&#34;__codelineno-6-20&#34; href=&#34;#__codelineno-6-20&#34;&gt;&lt;/a&gt; merged_tokens.append(tokens[i]) &lt;/span&gt;&lt;span id=&#34;__span-6-21&#34;&gt;&lt;a id=&#34;__codelineno-6-21&#34; name=&#34;__codelineno-6-21&#34; href=&#34;#__codelineno-6-21&#34;&gt;&lt;/a&gt; i += 1 &lt;/span&gt;&lt;span id=&#34;__span-6-22&#34;&gt;&lt;a id=&#34;__codelineno-6-22&#34; name=&#34;__codelineno-6-22&#34; href=&#34;#__codelineno-6-22&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-6-23&#34;&gt;&lt;a id=&#34;__codelineno-6-23&#34; name=&#34;__codelineno-6-23&#34; href=&#34;#__codelineno-6-23&#34;&gt;&lt;/a&gt;# Append the last token if it wasn&amp;#39;t part of a bigram &lt;/span&gt;&lt;span id=&#34;__span-6-24&#34;&gt;&lt;a id=&#34;__codelineno-6-24&#34; name=&#34;__codelineno-6-24&#34; href=&#34;#__codelineno-6-24&#34;&gt;&lt;/a&gt;if i == len(tokens) - 1: &lt;/span&gt;&lt;span id=&#34;__span-6-25&#34;&gt;&lt;a id=&#34;__codelineno-6-25&#34; name=&#34;__codelineno-6-25&#34; href=&#34;#__codelineno-6-25&#34;&gt;&lt;/a&gt; merged_tokens.append(tokens[i]) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; Bigrams: pairs of consecutive words. If the bigrams are used often, chances are they are legitimate compound words. Therefore, we merge those with high frequencies. Essentially, we check the current iteration and its next element. If the frequency Ex: [&#34;Machine&#34;, &#34;Learning&#34;, &#34;is&#34;, &#34;fun&#34; ], the output is : [&#34;Machine_Learning&#34;, &#34;is&#34;, &#34;fun&#34; ]!&lt;/p&gt; &lt;h3 id=&#34;convert-to-dictionary-token-count-file&#34;&gt;Convert to Dictionary {Token : Count} File&lt;/h3&gt; &lt;p&gt;After we cleaning, we convert all the words we get into dictionary, also count the frequency of each word, Here are the top 20 word frequencies, and top 20 compound words frequencies.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;word_freq&#34; src=&#34;Figure/word_freq.png&#34; /&gt; &lt;img alt=&#34;Compound_words_freq&#34; src=&#34;Figure/Compound_words_freq.png&#34; /&gt; &lt;/p&gt; &lt;h3 id=&#34;labeling-keys-with-respective-category&#34;&gt;Labeling Keys with Respective Category&lt;/h3&gt; &lt;p&gt;We utilize pre-trained Hugging Face NLP model and manual labeling to classify the words from the pdf cleaning into 4 category: - Urban Built Environment - Environment Factors - Mental Health and Well-Being - Measure&lt;/p&gt; &lt;p&gt;Based on the relationship between each categories, we explore: - In neuroarchitecture, the association between different environmental factors and different urban built environments. - Which urban built environment or environment factors are popular in mental health and well-being and which one are less affected.&lt;/p&gt; &lt;h3 id=&#34;visualization&#34;&gt;Visualization&lt;/h3&gt; &lt;h4 id=&#34;method-flow-chart&#34;&gt;Method Flow Chart&lt;/h4&gt; &lt;p&gt;&lt;img alt=&#34;v_method&#34; src=&#34;Figure/Visualization_Method.png&#34; /&gt; &lt;/p&gt; &lt;p&gt;After cleaning the PDFs, the resulting word dictionary is sorted in descending order of term frequency and saved as &lt;a href=&#34;Visualization_input_data/sorted_final_combined_dict.txt&#34;&gt;voc.txt&lt;/a&gt;. This vocabulary file is then fed into a Word2Vec model to train the word embeddings, producing &lt;a href=&#34;Visualization_input_data/sorted_final_combined_dict.emb&#34;&gt;embedding_vec.emb&lt;/a&gt;. The high‑dimensional embeddings are further reduced with PCA, UMAP, and t‑SNE, and the low‑dimensional coordinates are stored in &lt;a href=&#34;Visualization_input_data/sorted_final_combined_dict.json&#34;&gt;bookmark.json&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For visualization, we generates:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;N‑gram similarity matrix heat map&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Correlation matrix heat map&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hierarchical agglomerative clustering dendrogram&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cross‑correlation matrix&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Distance‑threshold projection&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;2D relation‑projection clusters using Louvain community detection.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;ngram-similarity-matrix-heat-map&#34;&gt;N‑gram similarity matrix heat map&lt;/h4&gt; &lt;p&gt;1.First ,whwn we input &lt;a href=&#34;Visualization_input_data/sorted_final_combined_dict.emb&#34;&gt;embedding_vec.emb&lt;/a&gt;，We use N-gram Co‑occurrence Frequency, which is shown as below, in order to counts how many times each adjacent word pair appear. When frequency is greater than 5, both of two words will be the compound words(bigram), which are included in the row and column with other words we collected. (Check for missing compond words)&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{freq}(W_a,W_b) \;=\ \sum_{t=1}^{T-1} \mathbf{1}\bigl[w_t = W_a\land\ w_{t+1} = W_b\bigr]&amp;gt;5 \]&lt;/div&gt; &lt;p&gt;2.Second, using the embedding vectors of each word, we compute the cosine similarity between every row word and every column word to obtain the similarity scores. When a similarity score exceeds 0.05, the corresponding word pair is treated as related, and the score is recorded as the cell value and color intensity in the heat‑map; scores below the threshold are left blank.&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \cos(\mathbf v_{W_a}\, \mathbf v_{W_b}) = \frac{\mathbf v_{W_a}\cdot \mathbf v_{W_b}} {\lVert \mathbf v_{W_a}\rVert\lVert \mathbf v_{W_b}\rVert} \&amp;gt;0.05 \]&lt;/div&gt; &lt;ol&gt; &lt;li&gt;Finally, the resulting similarity matrix is rendered as a &lt;a href=&#34;N-gram_similarity_matrix/heatmap&#34;&gt;heat map&lt;/a&gt;, (the relation between urban built environment and mental health or well-being shown below),and generate &lt;a href=&#34;N-gram_similarity_matrix/csv&#34;&gt;*.csv file&lt;/a&gt;of each relationship&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;img alt=&#34;N-gram&#34; src=&#34;N-gram_similarity_matrix/heatmap/mental_health_and_well_being-urban_built_environment_clusterd-01.png&#34; /&gt;&lt;/p&gt; &lt;h4 id=&#34;hierarchical-agglomerative-clustering-and-corelation-matrix&#34;&gt;Hierarchical Agglomerative Clustering and Corelation Matrix&lt;/h4&gt; &lt;ol&gt; &lt;li&gt;First, extract all nodes from the N‑gram similarity matrix heat map and write their 300‑dimensional word vectors to &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/embedding_matrix.tsv&#34;&gt;embedding_matrix.tsv&lt;/a&gt;, then read&lt;a href=&#34;N-gram_similarity_matrix/csv&#34;&gt;*.csv file&lt;/a&gt;of each relationship retrieve the 300 D vector for every column word, and perform hierarchical clustering with Ward’s method and Euclidean distance (minimizing within‑cluster variance). The resulting &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/dendrogram_groups&#34;&gt;dendrogram groups&lt;/a&gt; semantically similar words into clusters and automatically assigns a distinct colour to each branch for the legend.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Euclidean distance – input to Ward’s algorithm： For any two 300‑dimensional word embeddings &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt;\)&lt;/span&gt; and &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(\mathbf{x}_j\)&lt;/span&gt;\)&lt;/span&gt;,&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ d(\mathbf x_i,\mathbf x_j) = \lVert \mathbf x_i - \mathbf x_j \rVert_{2} \]&lt;/div&gt; &lt;p&gt;Ward linkage cost&lt;br /&gt; (extra within‑cluster sum‑of‑squares created by merging clusters (A) and (B))&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \Delta(A,B) = \frac{|A||B|}{|A|+|B|} \bigl\lVert \mu_A - \mu_B \bigr\rVert_2^{2} \]&lt;/div&gt; &lt;p&gt;where $${\mu}_A $$ and analogously $${\mu}_B $$ is the centroid of cluster (A).&lt;/p&gt; &lt;p&gt;2.Second, reorder the rows and columns according to the dendrogram’s leaf order, then compute the column‑wise Pearson correlation coefficients and display them in a red scale &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/Coreltaion_heatmap&#34;&gt;heat map&lt;/a&gt;, exporting the reordered original matrix to a &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/csv&#34;&gt;CSV file&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Pearson correlation coefficient (heat‑map cell value)&lt;/p&gt; &lt;p&gt;For two column vectors &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(X_i\)&lt;/span&gt;\)&lt;/span&gt; and &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(X_j\)&lt;/span&gt;\)&lt;/span&gt;:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ r_{ij}= \frac{\displaystyle\sum_{k=1}^{n}(X_{ik}-\bar X_i)(X_{jk}-\bar X_j)} {\sqrt{\displaystyle\sum_{k=1}^{n}(X_{ik}-\bar X_i)^2}\ \sqrt{\displaystyle\sum_{k=1}^{n}(X_{jk}-\bar X_j)^2}} \in[-1,1] \]&lt;/div&gt; &lt;p&gt;The script maps each &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(r_{ij}\)&lt;/span&gt;\)&lt;/span&gt; onto a red colour scale in the range (0-1):&lt;br /&gt; 0 = white (weak correlation), 1 = dark red (strong correlation).&lt;/p&gt; &lt;p&gt;Take the correlation matrix map (urban_built_environment)as an example: &lt;img alt=&#34;corelation&#34; src=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/urban_built_environment-mental_health_and_well_being-01.png&#34; /&gt;&lt;/p&gt; &lt;h4 id=&#34;cross-correlation-matrix-heat-map&#34;&gt;Cross-correlation matrix heat map&lt;/h4&gt; &lt;p&gt;For each cross‑category correlation &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/csv&#34;&gt;CSV&lt;/a&gt;, the script reorders the matrix according to the specified relationships, recomputes the cosine similarity, maps the resulting values to a red gradient scale from 0 (white) to 1 (dark red), and produces a &lt;a href=&#34;Cross_relation_matrix&#34;&gt;cross‑correlation heat map&lt;/a&gt; that visualizes the strength of the relationships between different categories.&lt;/p&gt; &lt;p&gt;Take the cross correlationship heatmap of mental health-urban built environment with dendrogram_groups as an example: &lt;img alt=&#34;cross&#34; src=&#34;Cross_relation_matrix/Cross.jpg&#34; /&gt;&lt;/p&gt; &lt;h4 id=&#34;2d-relationprojection-clusters-and-distancethreshold-projection&#34;&gt;2D relation‑projection clusters and Distance‑threshold projection&lt;/h4&gt; &lt;p&gt;1.&lt;strong&gt;Distance thresold&lt;/strong&gt;:Write the 300‑dimensional word vectors to &lt;a href=&#34;Hierarchical_Agglomerative_Clustering_and_Corelation_Matrix/embedding_matrix.tsv&#34;&gt;embedding_matrix.tsv&lt;/a&gt;, classify them into our predefined categories to create &lt;a href=&#34;2d_projecton/labels.tsv&#34;&gt;labels.tsv&lt;/a&gt;, and use these two files—together with &lt;a href=&#34;Visualization_input_data/sorted_final_combined_dict.json&#34;&gt;bookmark.json&lt;/a&gt;—as the input data for generating the 2‑D distance‑threshold projection.Each word is assigned a fixed position, a colour that reflects its predefined category, and a node size to its graph degree. NetworkX then builds a fully connected graph on these nodes, and Matplotlib draws a distance‑threshold projection: colored nodes are plotted at their 2D positions, the four main vocabularies are labelled, and overlapping labels are automatically nudged apart. The resulting cluster map is exported as graph_embeddings_projection, providing a visual overview of how the classified word embeddings distribute across the reduced dimensional space.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;graph_embeddings_projection&#34; src=&#34;2d_projecton/graph_embeddings_projection_with_edges.svg&#34; /&gt;&lt;/p&gt; &lt;p&gt;2.&lt;strong&gt;Louvain Cluster&lt;/strong&gt;:The Louvain algorithm (community_louvain.best_partition) to network, iteratively maximizing the modularity Q and thus determining the number of communities k automatically. Each community is then assigned a distinct color, producing node_colors. Next,Fruchterman‑Reingold computes the final node coordinates, pulling nodes within the same community closer together. Only words from the four main relationships are labelled, and adjust text is used to prevent label overlap.&lt;/p&gt; &lt;p&gt;The Louvain algorithm iteratively maximises the modularity $ Q $:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ Q =\frac{1}{2m} \sum_{i,j} \Bigl(A_{ij} - \frac{k_i k_j}{2m}\Bigr)\ \delta(c_i, c_j) \]&lt;/div&gt; &lt;p&gt;where&lt;br /&gt; &lt;span class=&#34;arithmatex&#34;&gt;\(A_{ij}\)&lt;/span&gt; is the adjacency‑matrix element,&lt;br /&gt; &lt;span class=&#34;arithmatex&#34;&gt;\(k_i\)&lt;/span&gt; is the degree of node $ i $,&lt;br /&gt; &lt;span class=&#34;arithmatex&#34;&gt;\(m\)&lt;/span&gt; is the total number of edges, and&lt;br /&gt; &lt;span class=&#34;arithmatex&#34;&gt;\(\delta(c_i,c_j)\)&lt;/span&gt; is 1 if nodes &lt;span class=&#34;arithmatex&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;arithmatex&#34;&gt;\(j\)&lt;/span&gt; are in the same community and 0 otherwise.&lt;/p&gt; &lt;p&gt;Fruchterman–Reingold spring layout Iterative force model:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ F_{\text{rep}}(r)=\frac{k^{2}}{r} \qquad F_{\text{att}}(r)=\frac{r^{2}}{k} \qquad k = c\sqrt{\frac{A}{n}} \]&lt;/div&gt; &lt;p&gt;&#39;nx.spring_layout&#39; embeds the graph in 2‑D, iterating until the attractive force &lt;span class=&#34;arithmatex&#34;&gt;\(F_{\text{att}}\)&lt;/span&gt; balances the repulsive force &lt;span class=&#34;arithmatex&#34;&gt;\(F_{\text{rep}}\)&lt;/span&gt;, thereby keeping each community visually compact while forcing distinct communities apart.&lt;/p&gt; &lt;p&gt;&lt;img alt=&#34;graph_embeddings_projection&#34; src=&#34;2d_projecton/graph_embeddings_projection_with_communities.svg&#34; /&gt;&lt;/p&gt; &lt;h3 id=&#34;repository-structure&#34;&gt;Repository Structure&lt;/h3&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-7-1&#34;&gt;&lt;a id=&#34;__codelineno-7-1&#34; name=&#34;__codelineno-7-1&#34; href=&#34;#__codelineno-7-1&#34;&gt;&lt;/a&gt;📦 &amp;lt;repo‑root&amp;gt; &lt;/span&gt;&lt;span id=&#34;__span-7-2&#34;&gt;&lt;a id=&#34;__codelineno-7-2&#34; name=&#34;__codelineno-7-2&#34; href=&#34;#__codelineno-7-2&#34;&gt;&lt;/a&gt;├── paper_json_after_initial_cleaning/ # JSON dictionaries produced after the initial PDF cleaning &lt;/span&gt;&lt;span id=&#34;__span-7-3&#34;&gt;&lt;a id=&#34;__codelineno-7-3&#34; name=&#34;__codelineno-7-3&#34; href=&#34;#__codelineno-7-3&#34;&gt;&lt;/a&gt;│ └── *.json &lt;/span&gt;&lt;span id=&#34;__span-7-4&#34;&gt;&lt;a id=&#34;__codelineno-7-4&#34; name=&#34;__codelineno-7-4&#34; href=&#34;#__codelineno-7-4&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-5&#34;&gt;&lt;a id=&#34;__codelineno-7-5&#34; name=&#34;__codelineno-7-5&#34; href=&#34;#__codelineno-7-5&#34;&gt;&lt;/a&gt;├── Visualization_input_data/ # Visualization Input Data &lt;/span&gt;&lt;span id=&#34;__span-7-6&#34;&gt;&lt;a id=&#34;__codelineno-7-6&#34; name=&#34;__codelineno-7-6&#34; href=&#34;#__codelineno-7-6&#34;&gt;&lt;/a&gt;│ ├── sorted_final_combined_dict.emb # Transfer dictionary after cleaning to word‑embedding vectors &lt;/span&gt;&lt;span id=&#34;__span-7-7&#34;&gt;&lt;a id=&#34;__codelineno-7-7&#34; name=&#34;__codelineno-7-7&#34; href=&#34;#__codelineno-7-7&#34;&gt;&lt;/a&gt;│ ├── sorted_final_combined_dict.txt # dictionary after cleaning and sorting &lt;/span&gt;&lt;span id=&#34;__span-7-8&#34;&gt;&lt;a id=&#34;__codelineno-7-8&#34; name=&#34;__codelineno-7-8&#34; href=&#34;#__codelineno-7-8&#34;&gt;&lt;/a&gt;├ ├── final_combined_dict.txt # dictionary after cleaning but unsorting &lt;/span&gt;&lt;span id=&#34;__span-7-9&#34;&gt;&lt;a id=&#34;__codelineno-7-9&#34; name=&#34;__codelineno-7-9&#34; href=&#34;#__codelineno-7-9&#34;&gt;&lt;/a&gt;│ └── sorted_final_combined_dict.json # PCA/UMAP/t‑SNE low‑dimensional coordinates &lt;/span&gt;&lt;span id=&#34;__span-7-10&#34;&gt;&lt;a id=&#34;__codelineno-7-10&#34; name=&#34;__codelineno-7-10&#34; href=&#34;#__codelineno-7-10&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-11&#34;&gt;&lt;a id=&#34;__codelineno-7-11&#34; name=&#34;__codelineno-7-11&#34; href=&#34;#__codelineno-7-11&#34;&gt;&lt;/a&gt;├── N‑gram_similarity_matrix/ # Per‑topic similarity heat maps and raw tables &lt;/span&gt;&lt;span id=&#34;__span-7-12&#34;&gt;&lt;a id=&#34;__codelineno-7-12&#34; name=&#34;__codelineno-7-12&#34; href=&#34;#__codelineno-7-12&#34;&gt;&lt;/a&gt;│ ├── csv/ # Original similarity matrices &lt;/span&gt;&lt;span id=&#34;__span-7-13&#34;&gt;&lt;a id=&#34;__codelineno-7-13&#34; name=&#34;__codelineno-7-13&#34; href=&#34;#__codelineno-7-13&#34;&gt;&lt;/a&gt;│ │ └── &amp;lt;topic&amp;gt;.csv &lt;/span&gt;&lt;span id=&#34;__span-7-14&#34;&gt;&lt;a id=&#34;__codelineno-7-14&#34; name=&#34;__codelineno-7-14&#34; href=&#34;#__codelineno-7-14&#34;&gt;&lt;/a&gt;│ └── heatmap/ # Corresponding heat‑map plots &lt;/span&gt;&lt;span id=&#34;__span-7-15&#34;&gt;&lt;a id=&#34;__codelineno-7-15&#34; name=&#34;__codelineno-7-15&#34; href=&#34;#__codelineno-7-15&#34;&gt;&lt;/a&gt;│ └── &amp;lt;topic&amp;gt;_clusterd.svg &lt;/span&gt;&lt;span id=&#34;__span-7-16&#34;&gt;&lt;a id=&#34;__codelineno-7-16&#34; name=&#34;__codelineno-7-16&#34; href=&#34;#__codelineno-7-16&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-17&#34;&gt;&lt;a id=&#34;__codelineno-7-17&#34; name=&#34;__codelineno-7-17&#34; href=&#34;#__codelineno-7-17&#34;&gt;&lt;/a&gt;├── Hierarchical_Agglomerative_Clustering_and_Correlation_Matrix/ &lt;/span&gt;&lt;span id=&#34;__span-7-18&#34;&gt;&lt;a id=&#34;__codelineno-7-18&#34; name=&#34;__codelineno-7-18&#34; href=&#34;#__codelineno-7-18&#34;&gt;&lt;/a&gt;│ ├── dendrogram_groups/ # Word‑vector dendrograms with colour legends &lt;/span&gt;&lt;span id=&#34;__span-7-19&#34;&gt;&lt;a id=&#34;__codelineno-7-19&#34; name=&#34;__codelineno-7-19&#34; href=&#34;#__codelineno-7-19&#34;&gt;&lt;/a&gt;│ │ └── &amp;lt;topic&amp;gt;_clusterd_with_legend.svg &lt;/span&gt;&lt;span id=&#34;__span-7-20&#34;&gt;&lt;a id=&#34;__codelineno-7-20&#34; name=&#34;__codelineno-7-20&#34; href=&#34;#__codelineno-7-20&#34;&gt;&lt;/a&gt;│ ├── csv/ # Matrices reordered by cluster order &lt;/span&gt;&lt;span id=&#34;__span-7-21&#34;&gt;&lt;a id=&#34;__codelineno-7-21&#34; name=&#34;__codelineno-7-21&#34; href=&#34;#__codelineno-7-21&#34;&gt;&lt;/a&gt;│ │ └── &amp;lt;topic&amp;gt;.csv &lt;/span&gt;&lt;span id=&#34;__span-7-22&#34;&gt;&lt;a id=&#34;__codelineno-7-22&#34; name=&#34;__codelineno-7-22&#34; href=&#34;#__codelineno-7-22&#34;&gt;&lt;/a&gt;│ ├── embedding_matrix.tsv # 300‑dimensional word‑embedding matrix &lt;/span&gt;&lt;span id=&#34;__span-7-23&#34;&gt;&lt;a id=&#34;__codelineno-7-23&#34; name=&#34;__codelineno-7-23&#34; href=&#34;#__codelineno-7-23&#34;&gt;&lt;/a&gt;│ └── Corelation_heatmap/ # Pearson‑correlation heat maps &lt;/span&gt;&lt;span id=&#34;__span-7-24&#34;&gt;&lt;a id=&#34;__codelineno-7-24&#34; name=&#34;__codelineno-7-24&#34; href=&#34;#__codelineno-7-24&#34;&gt;&lt;/a&gt;│ └── &amp;lt;topic&amp;gt;.svg &lt;/span&gt;&lt;span id=&#34;__span-7-25&#34;&gt;&lt;a id=&#34;__codelineno-7-25&#34; name=&#34;__codelineno-7-25&#34; href=&#34;#__codelineno-7-25&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-26&#34;&gt;&lt;a id=&#34;__codelineno-7-26&#34; name=&#34;__codelineno-7-26&#34; href=&#34;#__codelineno-7-26&#34;&gt;&lt;/a&gt;├── Cross_relation_matrix/ # Cross‑category similarity heat map &lt;/span&gt;&lt;span id=&#34;__span-7-27&#34;&gt;&lt;a id=&#34;__codelineno-7-27&#34; name=&#34;__codelineno-7-27&#34; href=&#34;#__codelineno-7-27&#34;&gt;&lt;/a&gt;│ └── svg/ # Cross‑relation heat‑map plots &lt;/span&gt;&lt;span id=&#34;__span-7-28&#34;&gt;&lt;a id=&#34;__codelineno-7-28&#34; name=&#34;__codelineno-7-28&#34; href=&#34;#__codelineno-7-28&#34;&gt;&lt;/a&gt;│ └── &amp;lt;A‑B&amp;gt;_cross_rel.svg &lt;/span&gt;&lt;span id=&#34;__span-7-29&#34;&gt;&lt;a id=&#34;__codelineno-7-29&#34; name=&#34;__codelineno-7-29&#34; href=&#34;#__codelineno-7-29&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-30&#34;&gt;&lt;a id=&#34;__codelineno-7-30&#34; name=&#34;__codelineno-7-30&#34; href=&#34;#__codelineno-7-30&#34;&gt;&lt;/a&gt;├── 2d_projection/ # 2‑D projection and distance‑threshold graphs &lt;/span&gt;&lt;span id=&#34;__span-7-31&#34;&gt;&lt;a id=&#34;__codelineno-7-31&#34; name=&#34;__codelineno-7-31&#34; href=&#34;#__codelineno-7-31&#34;&gt;&lt;/a&gt;│ ├── graph_embeddings_projection-with_edges.svg &lt;/span&gt;&lt;span id=&#34;__span-7-32&#34;&gt;&lt;a id=&#34;__codelineno-7-32&#34; name=&#34;__codelineno-7-32&#34; href=&#34;#__codelineno-7-32&#34;&gt;&lt;/a&gt;│ ├── labels.tsv # Mapping from word to predefined category &lt;/span&gt;&lt;span id=&#34;__span-7-33&#34;&gt;&lt;a id=&#34;__codelineno-7-33&#34; name=&#34;__codelineno-7-33&#34; href=&#34;#__codelineno-7-33&#34;&gt;&lt;/a&gt;│ └── graph_embeddings_projection_with_communities.svg &lt;/span&gt;&lt;span id=&#34;__span-7-34&#34;&gt;&lt;a id=&#34;__codelineno-7-34&#34; name=&#34;__codelineno-7-34&#34; href=&#34;#__codelineno-7-34&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-35&#34;&gt;&lt;a id=&#34;__codelineno-7-35&#34; name=&#34;__codelineno-7-35&#34; href=&#34;#__codelineno-7-35&#34;&gt;&lt;/a&gt;├── Figure/ # Figures collected for readme &lt;/span&gt;&lt;span id=&#34;__span-7-36&#34;&gt;&lt;a id=&#34;__codelineno-7-36&#34; name=&#34;__codelineno-7-36&#34; href=&#34;#__codelineno-7-36&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-37&#34;&gt;&lt;a id=&#34;__codelineno-7-37&#34; name=&#34;__codelineno-7-37&#34; href=&#34;#__codelineno-7-37&#34;&gt;&lt;/a&gt;├── code/ # Main scripts &lt;/span&gt;&lt;span id=&#34;__span-7-38&#34;&gt;&lt;a id=&#34;__codelineno-7-38&#34; name=&#34;__codelineno-7-38&#34; href=&#34;#__codelineno-7-38&#34;&gt;&lt;/a&gt;│ ├── clean_pdf.py &lt;/span&gt;&lt;span id=&#34;__span-7-39&#34;&gt;&lt;a id=&#34;__codelineno-7-39&#34; name=&#34;__codelineno-7-39&#34; href=&#34;#__codelineno-7-39&#34;&gt;&lt;/a&gt;│ ├── build_ngram_matrix.py &lt;/span&gt;&lt;span id=&#34;__span-7-40&#34;&gt;&lt;a id=&#34;__codelineno-7-40&#34; name=&#34;__codelineno-7-40&#34; href=&#34;#__codelineno-7-40&#34;&gt;&lt;/a&gt;│ ├── cluster_and_heatmap.py &lt;/span&gt;&lt;span id=&#34;__span-7-41&#34;&gt;&lt;a id=&#34;__codelineno-7-41&#34; name=&#34;__codelineno-7-41&#34; href=&#34;#__codelineno-7-41&#34;&gt;&lt;/a&gt;│ └── projection_and_louvain.py &lt;/span&gt;&lt;span id=&#34;__span-7-42&#34;&gt;&lt;a id=&#34;__codelineno-7-42&#34; name=&#34;__codelineno-7-42&#34; href=&#34;#__codelineno-7-42&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-7-43&#34;&gt;&lt;a id=&#34;__codelineno-7-43&#34; name=&#34;__codelineno-7-43&#34; href=&#34;#__codelineno-7-43&#34;&gt;&lt;/a&gt;└── README.md # Project overview (method, formulas, sample plots) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;plan&#34;&gt;Plan&lt;/h2&gt; &lt;h3 id=&#34;paper-publish&#34;&gt;Paper Publish&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Compare the data extraction template from each member and summarize into one data extraction template .&lt;/li&gt; &lt;li&gt;Analyze the different categories in the data extraction and the literature summary, and conduct a review&lt;/li&gt; &lt;li&gt;Draft it into the “finding” part of the paper draft&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;text-mining&#34;&gt;Text Mining&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Continue to manually filter the words in each category to ensure that they are concise and accurate.&lt;/li&gt; &lt;li&gt;Analyze the visualization data and explore research questions&lt;/li&gt; &lt;li&gt;Paper draft&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Pwu-RV_udrI&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/Pwu-RV_udrI/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;Department&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Changda Ma&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/changdama&#34;&gt;changdama&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Catherine Wallis&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/cgwallis&#34;&gt;cgwallis&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sydney Dai&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/SydneyGT&#34;&gt;SydneyGT&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ze Yu Jiang&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/zeyujiang8800&#34;&gt;zeyujiang8800&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sam Edwards&lt;/td&gt; &lt;td&gt;RA&lt;/td&gt; &lt;td&gt;Medical Research&lt;/td&gt; &lt;td&gt;PSYCH&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sedwards42&#34;&gt;sedwards42&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Bailey Todtfeld&lt;/td&gt; &lt;td&gt;RA&lt;/td&gt; &lt;td&gt;Medical Research&lt;/td&gt; &lt;td&gt;PSYCH&lt;/td&gt; &lt;td&gt;N/A&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-neuroarchitecture/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-neuroarchitecture/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-neuroarchitecture/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-neuroarchitecture/README.png" type="image/png" length="None" /> </item> <item> <title>25-Sp-MPONC</title> <description>&lt;h1 id=&#34;modeling-processes-of-neighborhood-change-mponc&#34;&gt;Modeling Processes of Neighborhood Change (MPONC)&lt;/h1&gt; &lt;h2 id=&#34;reference-paper&#34;&gt;Reference paper&lt;/h2&gt; &lt;div class=&#34;language-bibtex highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nc&#34;&gt;@misc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;mori2024modelingprocessesneighborhoodchange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-2&#34;&gt;&lt;a id=&#34;__codelineno-0-2&#34; name=&#34;__codelineno-0-2&#34; href=&#34;#__codelineno-0-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{Modeling Processes of Neighborhood Change}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-3&#34;&gt;&lt;a id=&#34;__codelineno-0-3&#34; name=&#34;__codelineno-0-3&#34; href=&#34;#__codelineno-0-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{J. Carlos Martínez Mori and Zhanzhan Zhao}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-4&#34;&gt;&lt;a id=&#34;__codelineno-0-4&#34; name=&#34;__codelineno-0-4&#34; href=&#34;#__codelineno-0-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{2024}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-5&#34;&gt;&lt;a id=&#34;__codelineno-0-5&#34; name=&#34;__codelineno-0-5&#34; href=&#34;#__codelineno-0-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;eprint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{2401.03307}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-6&#34;&gt;&lt;a id=&#34;__codelineno-0-6&#34; name=&#34;__codelineno-0-6&#34; href=&#34;#__codelineno-0-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;archivePrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{arXiv}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-7&#34;&gt;&lt;a id=&#34;__codelineno-0-7&#34; name=&#34;__codelineno-0-7&#34; href=&#34;#__codelineno-0-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;primaryClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{cs.MA}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-8&#34;&gt;&lt;a id=&#34;__codelineno-0-8&#34; name=&#34;__codelineno-0-8&#34; href=&#34;#__codelineno-0-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{https://arxiv.org/abs/2401.03307}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-9&#34;&gt;&lt;a id=&#34;__codelineno-0-9&#34; name=&#34;__codelineno-0-9&#34; href=&#34;#__codelineno-0-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;25Sp-MPONC/modeling_processes_of_neighborhood_change_new &lt;/span&gt;&lt;span id=&#34;__span-1-2&#34;&gt;&lt;a id=&#34;__codelineno-1-2&#34; name=&#34;__codelineno-1-2&#34; href=&#34;#__codelineno-1-2&#34;&gt;&lt;/a&gt;conda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;create&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-n&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;mponc&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;.10.16 &lt;/span&gt;&lt;span id=&#34;__span-1-3&#34;&gt;&lt;a id=&#34;__codelineno-1-3&#34; name=&#34;__codelineno-1-3&#34; href=&#34;#__codelineno-1-3&#34;&gt;&lt;/a&gt;conda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;activate&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;mponc &lt;/span&gt;&lt;span id=&#34;__span-1-4&#34;&gt;&lt;a id=&#34;__codelineno-1-4&#34; name=&#34;__codelineno-1-4&#34; href=&#34;#__codelineno-1-4&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;span id=&#34;__span-1-5&#34;&gt;&lt;a id=&#34;__codelineno-1-5&#34; name=&#34;__codelineno-1-5&#34; href=&#34;#__codelineno-1-5&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;main.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt; &lt;blockquote&gt; &lt;p&gt;This research project simulates the impact of the Atlanta Beltline on the surrounding metropolitan area using game theory. The simulation models agent movement across census tracts within the Atlanta-Sandy Springs-Roswell metro region, with agents seeking to move optimally (seeking &#39;attractive&#39; census tracts) based on various factors.&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id=&#34;intro-and-description&#34;&gt;Intro and Description&lt;/h2&gt; &lt;p&gt;This project is based on the reference paper created by Dr. Martinez and Dr. Zhao, which aims to address the following: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;How does the layout of transportation infrastructure affect the demographics of nearby neighborhoods? &lt;/li&gt; &lt;li&gt;Does the creation of these infrastructure actually benefit everyone equally; is it fair? &lt;/li&gt; &lt;li&gt;Can we predict the effects on surrounding communities before these structures are actually built? &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These questions are primarily motivated by the issue of gentrification, an issue prevalent in many major cities. We utilized concepts in game theory, more specifically no-regret dynamics, in order to simulate the effects of the Atlanta Beltline on gentrification. To summarize our approach with no-regret dynamics:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;People, or &#39;agents&#39;, randomly move from region to region. Depending the region&#39;s attributes, a &lt;strong&gt;&#39;cost&#39;&lt;/strong&gt; value is assigned to each action. &lt;/li&gt; &lt;li&gt;&lt;em&gt;&#39;Cost&#39; is a function of region attractiveness, affordability, and community.&lt;/em&gt; &lt;/li&gt; &lt;li&gt;The higher the cost, the less likely an agent is to visit that census tract in the future. &lt;/li&gt; &lt;li&gt;This process is repeated until the probability distribution of visting census tracts converges - an equilibrium is reached, and further actions make no difference. &lt;/li&gt; &lt;li&gt;We compute the simulation convergance using the &lt;em&gt;total‑variation distance&lt;/em&gt; between two sliding windows of recent agent‑distributions: &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;\mathrm{TV}(p,q)\;=\;\tfrac12\sum_{c}\lvert\,p(c)-q(c)\rvert\,. &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; If TV ≤ &lt;code&gt;EPS_CONVERGENCE&lt;/code&gt; (default = 0.005) the system is deemed converged and the run halts automatically. All thresholds are configurable in &lt;code&gt;config.py&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Alternatively, we can use a hardcoded runtime.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h2&gt; &lt;p&gt;Every agent evaluates a tract with a cost defined as&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;cost = 1 – (affordability × attractiveness × community)&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Factor&lt;/th&gt; &lt;th&gt;Scale&lt;/th&gt; &lt;th&gt;Quick intuition&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Affordability&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0 or 1&lt;/td&gt; &lt;td&gt;1 if the tract still has room &lt;em&gt;or&lt;/em&gt; the agent is randomly selected to be an inhabitants (weight scales with relative wealth); 0 otherwise.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Attractiveness&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;How nice the tract is to live in (see sub‑components below).&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Community&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;How close the agent’s income is to the local average—closer ⇒ higher score.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3 id=&#34;attractiveness-upkeep-amenity_access-beltline_factor&#34;&gt;Attractiveness = upkeep × amenity_access × beltline_factor&lt;/h3&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Sub‑component&lt;/th&gt; &lt;th&gt;Range&lt;/th&gt; &lt;th&gt;What it captures&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Upkeep&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0 or 1&lt;/td&gt; &lt;td&gt;0 if the tract is abandoned (no residents); 1 otherwise.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Amenity access&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;Density of key POIs (restaurants, shops, transit stops, etc) weighted by distance.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;BeltLine factor β&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;≤ 1&lt;/td&gt; &lt;td&gt;Extra accessibility for tracts in the BeltLine zone: β = 1.00 at ≤ 800 m, tapering linearly to β = 0.917 (1.10/1.20) at 1.6 km, then β = 0.833 (1.0/1.20).&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;* Amenity list adapted from &lt;strong&gt;&lt;a href=&#34;https://vip-smur.github.io/24sp-mobility-seg/&#34;&gt;24Sp‑Mobility‑Seg&lt;/a&gt;&lt;/strong&gt;; we omit several tags such as “shed”, “guardhouse”, “ferry_terminal”, “garages”, and “bridge”.&lt;/p&gt; &lt;h4 id=&#34;implemented-amenities-weights-openstreetmap-labels&#34;&gt;Implemented Amenities &amp;amp; weights (OpenStreetMap labels):&lt;/h4&gt; &lt;p&gt;&lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;AMENITY_TAGS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-2&#34;&gt;&lt;a id=&#34;__codelineno-3-2&#34; name=&#34;__codelineno-3-2&#34; href=&#34;#__codelineno-3-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;amenity&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;bus_station|cafe|college|fast_food|food_court|fuel|library|restaurant|train_station|university|parking|school|hospital&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-3&#34;&gt;&lt;a id=&#34;__codelineno-3-3&#34; name=&#34;__codelineno-3-3&#34; href=&#34;#__codelineno-3-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;shop&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;supermarket|food|general|department_store|mall|wholesale&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-4&#34;&gt;&lt;a id=&#34;__codelineno-3-4&#34; name=&#34;__codelineno-3-4&#34; href=&#34;#__codelineno-3-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;landuse&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;residential|industrial|commercial|retail&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-5&#34;&gt;&lt;a id=&#34;__codelineno-3-5&#34; name=&#34;__codelineno-3-5&#34; href=&#34;#__codelineno-3-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; * We operationalize &lt;strong&gt;β&lt;/strong&gt; by giving tracts within &lt;strong&gt;800 m&lt;/strong&gt; of the BeltLine a &lt;strong&gt;+20 %&lt;/strong&gt; boost to their Attractiveness score (β = 1.20/1.20); the boost then tapers linearly to &lt;strong&gt;+10 %&lt;/strong&gt; at &lt;strong&gt;1.6 km&lt;/strong&gt;, and falls to β = 1.00/1.20 beyond that distance. These concrete percentages and distance bands approximate the BeltLine’s observed catchment zone and its predicted effect on nearby housing prices.&lt;/p&gt; &lt;h3 id=&#34;community-score-local-morans-i&#34;&gt;Community Score (Local Moran’s I)&lt;/h3&gt; &lt;p&gt;We quantify how well an agent’s income matches its neighbours using Local Moran’s I:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ I_c = \frac{(w_c - \bar w)}{S^2} \sum_{j \in N(c)} w_{cj}\,(w_j - \bar w), \quad S^2 = \frac{1}{n}\sum_{k=1}^n (w_k - \bar w)^2 \]&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;w_c&lt;/code&gt; = average income in tract c &lt;/li&gt; &lt;li&gt;&lt;code&gt;w̄&lt;/code&gt; = regional mean income &lt;/li&gt; &lt;li&gt;&lt;code&gt;w_{cj}&lt;/code&gt; = spatial weight (1 for adjacent tracts, 0 otherwise) &lt;/li&gt; &lt;li&gt;&lt;code&gt;N(c)&lt;/code&gt; = neighbouring tracts of c &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each agent i with income &lt;code&gt;w_i&lt;/code&gt; converts this statistic into a smooth score:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \mathrm{Community}_i(c) = \exp\bigl(-\alpha\,\lvert w_i - I_c\rvert\bigr) \]&lt;/div&gt; &lt;p&gt;where &lt;code&gt;α&lt;/code&gt; is set in &lt;code&gt;config.py&lt;/code&gt;.&lt;br /&gt; A closer match ⇒ value near 1 ⇒ lower cost.&lt;/p&gt; &lt;h3 id=&#34;weighting-amenity-access-vs-community&#34;&gt;Weighting amenity access vs community (λ)&lt;/h3&gt; &lt;p&gt;A tunable parameter &lt;strong&gt;λ ∈ [0, 1]&lt;/strong&gt; lets you emphasize either amenity access (high λ) or community match (low λ).&lt;br /&gt; Internally we rewrite&lt;br /&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;cost = 1 - [[Affordability] × [Upkeep x (λ × AmenityAccess)] × [(1-λ) × Community]] &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;h2 id=&#34;the-four-step-model&#34;&gt;The Four-Step Model&lt;/h2&gt; &lt;p&gt;Given that the agents move across various subregions in our simulation, one of the critical steps is determining the mode of transport of each agent. To do this in a way that accurately represents real-world distributions, we turned to the four-step model, a common trip generation algorithm: &lt;/p&gt; &lt;p&gt;&lt;img width=&#34;758&#34; alt=&#34;Screenshot 2024-12-03 at 2 19 28 PM&#34; src=&#34;./Figures/FourStepModel.png&#34;&gt;&lt;/p&gt; &lt;p&gt;The model has four components:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Trip Generation: This part of the model estimates the number of trips originating from or destined for a specific area. It focuses on understanding how many trips are generated rather than specific travel patterns. This process usually involves some type of data pertaining to the area at hand, such as demographics, income, or land usage.&lt;/li&gt; &lt;li&gt;Trip Distribution; This part of the model estimates the number of trips for routes that go from an area to another, as determined in the trip generation step. This process is typically done using the gravity model, which assumes that the number of trips are positively correlated with the attractiveness of an area and inversely correlated to distance.&lt;/li&gt; &lt;li&gt;Mode Choice: This part of the model determines the mode of transporation used to make the trips. This is typically done by considering demographic data (such as the percentage of people with cars) in an area.&lt;/li&gt; &lt;li&gt;Route Assignment: This part of the model determines the routes travelers take between origins and destinations. This is typically done by considering the route that takes the shorted possible time, and following that. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Our approach closely follows these four components. We first generate trips by considering the amenity density of areas. We sum up all amenity densities, and divide each area&#39;s density by this sum to generate a probability. We then utilize a Poisson Distribution to generate the number of trips by multipling a base number of trips by the probability. We then consider trip distribution through a modified gravity model. The equation for our model is the following, given that we aim to go from area/region i to j:&lt;/p&gt; &lt;p&gt;&lt;img width=&#34;686&#34; alt=&#34;Screenshot 2024-12-03 at 2 37 56 PM&#34; src=&#34;./Figures/GravityModel.png&#34;&gt;&lt;/p&gt; &lt;p&gt;We essentially multiply the total number of trips from area i to area j with the net amenity score for the destination j times transportation cost for that specific trip from area i to j, divided by the net amenity score for area j times the transportation cost from area i to j summed up over all destination j&#39;s. &lt;/p&gt; &lt;p&gt;For our modal split, we assume that the car ownership rate is 0.7, and that the transit rate is 0.3. Each region&#39;s trips are split based on this. We then assign these routes based on the shortest possible distance.&lt;/p&gt; &lt;p&gt;Through this process, we were able to have a methodical way of distributing the agents across Atlanta based on area factors such as amenity density.&lt;/p&gt; &lt;h3 id=&#34;tigerline-geodatabases-shapefiles&#34;&gt;TIGER/Line Geodatabases shapefiles:&lt;/h3&gt; &lt;p&gt;&lt;img alt=&#34;Alt text&#34; src=&#34;Figures/ZIP_URLs.png&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;project-status&#34;&gt;Project status&lt;/h2&gt; &lt;h3 id=&#34;outputs-configuration&#34;&gt;Outputs &amp;amp; configuration&lt;/h3&gt; &lt;p&gt;Our code outputs a GIF to visualize agent behavior over time. Each circle represents the centroid of a census tract - green signifying those in the Atlanta Beltline - and the encircled number is the agent population. Our code also outputs a CSV file containing all the simulated data at every individual timestep.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;Data contained in CSV&#39;s: Census tract name, agent population, raw average income, average income reported by census, normalized average incomes, and amenity density.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;Note: &#39;Timestep&#39; refers to a single instance agent action (relocation); 20,000 timesteps mean the agents relocate a total of 20,000 times during the simulation.&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;gif&#34;&gt;GIF&lt;/h4&gt; &lt;p&gt;This GIF shows the behavior of 1,000 agents up to 20,000 timesteps, frames being captured every 400 timesteps. Rho=1, alpha=0.25. &lt;img alt=&#34;Alt text&#34; src=&#34;Figures/SimulationGIF2025.gif&#34; /&gt;&lt;/p&gt; &lt;h3 id=&#34;runtimes&#34;&gt;Runtimes&lt;/h3&gt; &lt;blockquote&gt; &lt;p&gt;(1000 agents, 349 census tracts) - Simulation (x8): ~19.6 minutes - GIF creation (x8), 50 frames: ~13 min * Graph, amenities, and centroids are cached after first build&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id=&#34;census-based-approach&#34;&gt;Census-based approach&lt;/h2&gt; &lt;p&gt;Our project utilizes US Census data in that: - The geographical regions our agents inhabit correspond directly to US census tracts (can correspond to any other census-defined geographic unit, i.e. zip codes, housing districts, and school districts). - Each &#39;agent&#39; is assigned a &#39;wealth&#39; value in our simulation. We create this distribution of wealth using Census data (population &amp;amp; median incomes), to represent real-world demographics.&lt;/p&gt; &lt;h2 id=&#34;atlanta-beltline-in-our-simulation&#34;&gt;Atlanta Beltline in our Simulation&lt;/h2&gt; &lt;p&gt;We automate the process of labelling certain regions as &#39;in the Atlanta Beltline&#39; by using commuting paths from OpenStreetMap that correspond to the Atlanta Beltline - namely, a bike trail and a railway. To experiment with a different beltline, such as a beltline that spanned across Atlanta horizontally, or simply expanded north by x miles, we would acquire the OpenStreetMap ID&#39;s of existing paths (bike trails, walking paths, roads, etc.) corresponding to our desired Beltline, and paste these into &lt;strong&gt;config.py&lt;/strong&gt;. Alternatively, we can create a such path ourselves in OpenStreetMap. Then, any region containing segments of these trails would automatically be marked as &#34;In the Atlanta Beltline&#34;. &lt;/p&gt; &lt;p&gt;In &lt;strong&gt;config.py&lt;/strong&gt; - bike trail and railroad OpenStreetMap ID&#39;s for the beltline are as follows:&lt;/p&gt; &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;sd&#34;&gt;&amp;quot;&amp;quot;&amp;quot; Beltline &amp;#39;relation&amp;#39; IDs from Open Street Map &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-2&#34;&gt;&lt;a id=&#34;__codelineno-5-2&#34; name=&#34;__codelineno-5-2&#34; href=&#34;#__codelineno-5-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;RELATION_IDS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8408433&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;13048389&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th style=&#34;text-align: center;&#34;&gt;Bike Trail&lt;/th&gt; &lt;th style=&#34;text-align: center;&#34;&gt;Railroad&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td style=&#34;text-align: center;&#34;&gt;&lt;img src=&#34;./Figures/BeltlineBikeTrail.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &lt;td style=&#34;text-align: center;&#34;&gt;&lt;img src=&#34;./Figures/BeltlineRailroad.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Compare with Atlanta Beltline geography:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;./Figures/AtlantaBeltlineVisual.jpg&#34; width=&#34;250&#34;&gt;&lt;/p&gt; &lt;h2 id=&#34;adapting-the-model-to-other-cities&#34;&gt;Adapting the Model to Other Cities&lt;/h2&gt; &lt;p&gt;Although Atlanta serves as our case study, every pipeline stage—census shapefiles, OSM‑derived amenities, cost parameters, and even the BeltLine decision‑agent—can be swapped for a different region:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geometry &amp;amp; Demographics&lt;/strong&gt;&lt;br /&gt; • Replace the Fulton/DeKalb TIGER/Line shapefiles with those of your target city.&lt;br /&gt; • Point the &lt;code&gt;MEDIAN_INCOME_URL&lt;/code&gt; and &lt;code&gt;POP_URL&lt;/code&gt; in &lt;code&gt;config.py&lt;/code&gt; to that city’s American Community Survey &#34;ACS&#34; tables.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transit‑Ring Definition&lt;/strong&gt;&lt;br /&gt; • Identify (or sketch in OSM) the planned loop / BRT corridor / rail spur you want to study, then list its OSM relation IDs in &lt;code&gt;config.py&lt;/code&gt;.&lt;br /&gt; • The same β‑taper and DecisionAgent logic will assign accessibility boosts and density bonuses around the new corridor.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Policy Levers&lt;/strong&gt;&lt;br /&gt; • Tweak &lt;code&gt;RHO_SCALAR&lt;/code&gt; to explore how strong the up‑zoning response should be for the above transit ring.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Because the simulation is purely data‑driven, you can rapidly prototype “what‑if” BeltLine analogues for &lt;strong&gt;anywhere with open census and OSM data while measuring potential community shifts/gentrification before shovels hit the ground.&lt;/strong&gt; Example: &lt;img alt=&#34;Alt text&#34; src=&#34;Figures/OldZipURL.png&#34; /&gt; * By changing the above URL, we get the following:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;./Figures/AtlantaBeltlineCloseupGraph.png&#34; alt=&#34;Alt text&#34; width=&#34;250&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;policy-scenarios-vertical-vs-horizontal-scaling&#34;&gt;Policy Scenarios: Vertical vs Horizontal Scaling&lt;/h2&gt; &lt;p&gt;The simulation now supports two high-level policy experiments:&lt;/p&gt; &lt;h3 id=&#34;1-vertical-scaling-decision-making-agent-learns-m&#34;&gt;1. Vertical Scaling — Decision-Making Agent learns &lt;span class=&#34;arithmatex&#34;&gt;\(m\)&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;A dedicated &lt;code&gt;DecisionAgent&lt;/code&gt; treats “how aggressively should we up-zone?” as a learning problem:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Action space&lt;/strong&gt;:&lt;br&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ m \in \{0.00,\,0.01,\,\dots,\,1.00\} \]&lt;/div&gt; &lt;p&gt;sampled each timestep by multiplicative‑weights (no‑regret).&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Base capacity curve&lt;/strong&gt;:&lt;br&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;U_c = 1 + \frac{\texttt{beltline\_score}_c - \texttt{BL\_LOW}}{\texttt{BL\_HIGH} - \texttt{BL\_LOW}} \times \bigl(\texttt{RHO\_SCALAR}_{max} - 1\bigr) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h4 id=&#34;effective-multiplier&#34;&gt;Effective multiplier&lt;/h4&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \rho_c \;\leftarrow\; \rho_c \times \bigl[1 + m\,(U_c - 1)\bigr] \]&lt;/div&gt; &lt;p&gt;Two alternative utility metrics guide learning:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;code&gt;UTILITY_METRIC&lt;/code&gt;&lt;/th&gt; &lt;th&gt;Algorithm maximises&lt;/th&gt; &lt;th&gt;Real‑world analogy&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;0&lt;/code&gt; &lt;em&gt;(default)&lt;/em&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;average utility&lt;/strong&gt; (mean well‑being across all agents)&lt;/td&gt; &lt;td&gt;“Greatest good for the greatest number.”&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;minimum utility&lt;/strong&gt; (well‑being of the worst‑off agent)&lt;/td&gt; &lt;td&gt;Rawlsian / max‑min fairness.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The DecisionAgent reinforces actions that raise the chosen utility, gradually converging to an ideal &lt;em&gt;m&lt;/em&gt; for the current policy goal. &lt;/p&gt; &lt;p&gt;These “concrete zoning‑bonus percentages and distance bands” are the literal numbers (+20 %, +10 %, 800 m, 1600 m) encoded in &lt;code&gt;DecisionAgent.py&lt;/code&gt;. Feel free to edit them in &lt;code&gt;config.py&lt;/code&gt;.&lt;/p&gt; &lt;h3 id=&#34;2-horizontal-scaling-complete-beltline-from-day-0&#34;&gt;2. Horizontal Scaling (complete BeltLine from day 0)&lt;/h3&gt; &lt;p&gt;All census tracts whose centroids fall inside the 1.6 km BeltLine catchment zone begin with &lt;strong&gt;BeltLine factor β &amp;gt; 1&lt;/strong&gt; (default β = 1.20, editable in &lt;code&gt;config.py&lt;/code&gt;).&lt;br /&gt; Tracts outside that zone keep β = 1.00. This models an “all‑at‑once” completion of the transit loop.&lt;/p&gt; &lt;h2 id=&#34;sobol-sensitivity-analysis&#34;&gt;Sobol Sensitivity Analysis&lt;/h2&gt; &lt;p&gt;During calibration we ran a Sobol variance‑decomposition on six candidate features&lt;br /&gt; (Affordability, Attractiveness, Community, Location, BeltLine, Upkeep).&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Feature&lt;/th&gt; &lt;th&gt;1&lt;sup&gt;st&lt;/sup&gt;‑order index&lt;/th&gt; &lt;th&gt;Total‑order index&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Affordability&lt;/td&gt; &lt;td&gt;0.42&lt;/td&gt; &lt;td&gt;0.45&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Attractiveness&lt;/td&gt; &lt;td&gt;0.31&lt;/td&gt; &lt;td&gt;0.36&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Community&lt;/td&gt; &lt;td&gt;0.18&lt;/td&gt; &lt;td&gt;0.22&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;em&gt;Others&lt;/em&gt;&lt;/td&gt; &lt;td&gt;&amp;lt; 0.05&lt;/td&gt; &lt;td&gt;&amp;lt; 0.10&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Because the cumulative contribution of the remaining three factors was &amp;lt; 10 %, we compressed the cost function to the product &lt;strong&gt;Affordability × Attractiveness × Community&lt;/strong&gt;. The full Jupyter notebook lives in &lt;code&gt;notebooks/sensitivity_sobol.ipynb&lt;/code&gt;.&lt;/p&gt; &lt;h2 id=&#34;strengths-and-weaknesses&#34;&gt;Strengths and Weaknesses&lt;/h2&gt; &lt;h3 id=&#34;strengths&#34;&gt;Strengths&lt;/h3&gt; &lt;p&gt;Our approach is very modularized. For instance, our code can easily be ran on other regions, with customizable &#39;Beltlines&#39; and the definitio. It simply needs lists of agents, a NetworkX graph, and other generalized parameters to operate. Furthermore, Our approach is backed by established human behavior approaches (no-regret dynamics), utilizes a distribution system that is also established (four-step model). We are able to produce dynamic visuals (GIFs).&lt;/p&gt; &lt;h3 id=&#34;weaknesses&#34;&gt;Weaknesses&lt;/h3&gt; &lt;p&gt;Our simulation also assumes that there is no immigration/emigration in Atlanta, as we set a fixed number of agents. We also limit transportation choices to cars and public transportation, despite other modes of transport being popular (walking or biking) Additionally, our runtimes are relatively long due to the computationally expensive nature of the simulation. Ideally, our simulation would be ran in just a couple minutes or even seconds.&lt;/p&gt; &lt;h3 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h3&gt; &lt;p&gt;We hope to publish this research paper by this coming Fall semester. Most notably, we hope to improve the readability of our GIF&#39;s, improve the runtime of the simulation, validate our simulation&#39;s accuracy, and include additional visualizations of our results to better communicate our analysis during discussion. &lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0sxJBZpCphA&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/0sxJBZpCphA/maxresdefault.jpg&#34; width=&#34;480&#34; alt=&#34;Final Presentation --- 25Sp --- Modeling Processes of Neighborhood Change (MPONC)&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Matthew Lim&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mlim70&#34;&gt;mlim70&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Justin Xu&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/JXU037&#34;&gt;JXU037&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Devam Mondal&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Dodesimo&#34;&gt;Dodesimo&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nithish Sabapathy&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nithish101&#34;&gt;nithish101&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25sp-mponc/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25sp-mponc/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25sp-mponc/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25sp-mponc/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-Mobility</title> <description>&lt;h1 id=&#34;pedestrian-environment-index-pei-documentation-fall-2025&#34;&gt;Pedestrian Environment Index (PEI) Documentation - Fall 2025&lt;/h1&gt; &lt;p&gt;This project implements the Pedestrian Environment Index (PEI) methodology as developed at the University of Illinois Chicago (see the research paper: &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0966692314001343&#34;&gt;https://www.sciencedirect.com/science/article/pii/S0966692314001343&lt;/a&gt;). The PEI provides a composite measure of the walkability of an environment, incorporating the following subindices:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Population Density Index (PDI)&lt;/li&gt; &lt;li&gt;Commercial Density Index (CDI)&lt;/li&gt; &lt;li&gt;Intersection Density Index (IDI)&lt;/li&gt; &lt;li&gt;Land-use Diversity Index (LDI)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;1-motivation-and-introduction&#34;&gt;1. Motivation and Introduction&lt;/h2&gt; &lt;p&gt;The &lt;strong&gt;Pedestrian Environment Index (PEI)&lt;/strong&gt; is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments. This implementation of the PEI is useful for researchers aiming to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Assess the current walkability of neighborhoods or regions.&lt;/li&gt; &lt;li&gt;Compare walkability across different areas.&lt;/li&gt; &lt;li&gt;Identify areas with potential for improvement.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;2-getting-started&#34;&gt;2. Getting Started&lt;/h2&gt; &lt;h3 id=&#34;prerequisites&#34;&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Python 3.x&lt;/strong&gt;:&lt;br /&gt; Ensure Python is installed and available in your system path. Check using: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--version &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Required Libraries&lt;/strong&gt;:&lt;br /&gt; Install the following Python libraries:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;osmnx&lt;/li&gt; &lt;li&gt;pandas&lt;/li&gt; &lt;li&gt;numpy&lt;/li&gt; &lt;li&gt;matplotlib.pyplot&lt;/li&gt; &lt;li&gt;csv&lt;/li&gt; &lt;li&gt; &lt;p&gt;census&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Census API Key&lt;/strong&gt;:&lt;br /&gt; Obtain a Census API key from &lt;a href=&#34;https://api.census.gov/data/key_signup.html&#34;&gt;Census API Key Signup&lt;/a&gt;.&lt;br /&gt; Save the key in a text file named &lt;code&gt;census_api_key.txt&lt;/code&gt; in the same directory as &lt;code&gt;PDI_generator.ipynb&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;installation&#34;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Install the required libraries using pip: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;osmnx&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pandas&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;numpy&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;matplotlib&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;csv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;census &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;3-core-subindices&#34;&gt;3. Core Subindices&lt;/h2&gt; &lt;h3 id=&#34;population-density-index-pdi&#34;&gt;&lt;strong&gt;Population Density Index (PDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Measures residential population density within defined areas.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Population and area data are downloaded from the Missouri Census Data Center.&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Calculation&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\text{Population Density} = \frac{\text{Total Population}}{\text{Total Area (Square Miles)}}\)&lt;/span&gt;&lt;br /&gt; - &lt;strong&gt;PDI&lt;/strong&gt;: Percentile rank of Population Density across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;commercial-density-index-cdi&#34;&gt;&lt;strong&gt;Commercial Density Index (CDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Evaluates the density of commercial establishments per block group.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Data is sourced using the Overpass API.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Tags used include shops, restaurants, cafes, banks, schools, cinemas, parks, sports centers, and stadiums.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Area is derived from census tracts in the US Census GeoJSON files.&lt;/p&gt; &lt;p&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\text{Commercial Density} = \frac{\text{Count of Commercial POIs}}{\text{Total Land Area (Square Miles)}}\)&lt;/span&gt;&lt;br /&gt; - &lt;strong&gt;CDI&lt;/strong&gt;: Percentile rank of Commercial Density across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;intersection-density-index-idi&#34;&gt;&lt;strong&gt;Intersection Density Index (IDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Quantifies the density of intersections in a given area.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Retrieved using the Overpass API.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: &lt;span class=&#34;arithmatex&#34;&gt;\(\text{Intersection Density} = \frac{\text{Number of Nodes Part of More than One Way (Intersections)}}{\text{Area (Square Miles)}}\)&lt;/span&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;IDI&lt;/strong&gt;: Percentile rank of Intersection Densities across all years and cities.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;land-use-diversity-index-ldi&#34;&gt;&lt;strong&gt;Land-use Diversity Index (LDI)&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Analyzes the diversity of land-use types within an area.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Land-use data is retrieved from OpenStreetMap using the Overpass API with the &#34;landuse&#34; tag.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: &lt;span class=&#34;arithmatex&#34;&gt;\(\text{Entropy} = \sum \left( \frac{\text{Area of Land Use Type}}{\text{Total Area}} \cdot \ln \left( \frac{\text{Area of Land Use Type}}{\text{Total Area}} \right) \right)\)&lt;/span&gt; (for all land-use types with non-zero area). &lt;ul&gt; &lt;li&gt;Normalized by: &lt;span class=&#34;arithmatex&#34;&gt;\(\frac{\text{Entropy}}{\ln(\text{Number of Land Use Types with Non-Zero Area})}\)&lt;/span&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;LDI&lt;/strong&gt;: Percentile rank of Entropies across all years and cities.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;4-pei-formula&#34;&gt;4. PEI Formula&lt;/h2&gt; &lt;p&gt;The PEI is calculated using the following formula:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ PEI = \frac{{(1 + PDI) \cdot (1 + IDI) \cdot (1 + LDI) \cdot (1 + CDI)}}{16} \]&lt;/div&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-implementation-workflow&#34;&gt;5. Implementation Workflow&lt;/h2&gt; &lt;h3 id=&#34;step-1-files&#34;&gt;Step 1: Files&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Download population data files from the Missouri Census Data Center (MCDC) for each required year.&lt;/li&gt; &lt;li&gt;Download block group and census tract files from the US Census Bureau website.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-2-subindex-calculation&#34;&gt;Step 2: Subindex Calculation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Run individual generator scripts (e.g., &lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.ipynb&lt;/code&gt;) for each subindex.&lt;/li&gt; &lt;li&gt;Outputs include CSV and GeoJSON files with fields for block group, year, and the &#34;raw subindex&#34; values:&lt;/li&gt; &lt;li&gt;Population Density&lt;/li&gt; &lt;li&gt;Commercial Density&lt;/li&gt; &lt;li&gt;Intersection Density&lt;/li&gt; &lt;li&gt;Entropy&lt;/li&gt; &lt;li&gt;Append all results to master files (&lt;code&gt;all_PDI&lt;/code&gt;, &lt;code&gt;all_CDI&lt;/code&gt;, &lt;code&gt;all_IDI&lt;/code&gt;, &lt;code&gt;all_LDI&lt;/code&gt;) for comprehensive cross-year/city comparison.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-3-normalization&#34;&gt;Step 3: Normalization&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Normalize raw subindex data - between 1 and 0:&lt;/li&gt; &lt;li&gt;This normalization is done by taking each block group/tract&#39;s percentile rank for each &#34;raw subindex&#34; versus every other city and every other year:&lt;/li&gt; &lt;li&gt;Because we normalize across all cities and years, our subindex values can be compared seamlessly against any other block group regardless of time/location.&lt;/li&gt; &lt;li&gt;We are able to normalize across all cities and years thanks to these aforementioned 4 files - &lt;code&gt;all_PDI.csv&lt;/code&gt;, &lt;code&gt;all_CDI.csv&lt;/code&gt;, &lt;code&gt;all_IDI.csv&lt;/code&gt;, &lt;code&gt;all_LDI.csv&lt;/code&gt; - which contain raw data for all years/cities.&lt;/li&gt; &lt;li&gt;Once we normalize the raw subindex we can now call it an actual subindex - e.g. the normalized &lt;code&gt;Commercial Density&lt;/code&gt; becomes &lt;code&gt;CDI&lt;/code&gt;, normalized &lt;code&gt;Entropy&lt;/code&gt; becomes &lt;code&gt;LDI&lt;/code&gt;, etc.&lt;/li&gt; &lt;li&gt; &lt;p&gt;The file also updates the CSV &amp;amp; GeoJSON files for each subindex and city with a new field - one of &lt;code&gt;CDI&lt;/code&gt;, &lt;code&gt;LDI&lt;/code&gt;, &lt;code&gt;PDI&lt;/code&gt;, &lt;code&gt;IDI&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Now we finally have finalized CSV and GeoJSON files for the 4 subindexes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-4-pei-calculation&#34;&gt;Step 4: PEI Calculation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Combine normalized subindices using the PEI formula for each block group/tract.&lt;/li&gt; &lt;li&gt;Generate CSV and GeoJSON files (&lt;code&gt;PEI_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;).&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-5-web-app-integration&#34;&gt;Step 5: Web App Integration&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Upload finalized GeoJSON files to AWS S3 buckets.&lt;/li&gt; &lt;li&gt;Implement and visualize data on the web app.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;6-usage&#34;&gt;6. Usage&lt;/h2&gt; &lt;h3 id=&#34;inside-the-fall24-folder-you-will-find-3-folders&#34;&gt;Inside the Fall24 folder you will find 3 folders:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Tract_Files - we mainly used this folder for testing:&lt;/li&gt; &lt;li&gt;This contains the relevant &lt;code&gt;ipynb&lt;/code&gt; files for creating the subindexes.&lt;/li&gt; &lt;li&gt; &lt;p&gt;It also contains &lt;code&gt;tracts.geojson&lt;/code&gt; which has the first 10 rows of tracts in the US - useful for testing. - Please download full tract files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;BlockGroup_Files:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;This contains the relevant &lt;code&gt;ipynb&lt;/code&gt; files for creating the subindexes. (In the PDI file, only run code blocks after the &lt;code&gt;#NEW&lt;/code&gt; comment).&lt;/li&gt; &lt;li&gt;It also contains &lt;code&gt;block_groups.geojson&lt;/code&gt; which has the first 10 rows of blockgroups in Atlanta - useful for testing. - Please create the full files using the &lt;code&gt;./Spring24/Blockgroup GeoJSON Generator&lt;/code&gt; folder (you need to rename the output of this to &lt;code&gt;block_groups.geojson&lt;/code&gt;), downlaod the full files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;step-1-data-download&#34;&gt;Step 1: Data Download&lt;/h3&gt; &lt;p&gt;Download the required data files from the following sources: - &lt;strong&gt;Population Data&lt;/strong&gt;: Obtain CSV files from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt;. - &lt;strong&gt;Census Block Groups/Tract GeoJSON&lt;/strong&gt;: Retrieve the required GeoJSON files from the US Census Bureau or relevant sources: - As described above, download files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.&lt;/p&gt; &lt;h3 id=&#34;step-2-update-generator-scripts&#34;&gt;Step 2: Update Generator Scripts&lt;/h3&gt; &lt;p&gt;Modify the generator scripts (&lt;code&gt;PDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;CDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;LDI_Generator.ipynb&lt;/code&gt;, &lt;code&gt;IDI_Generator.ipynb&lt;/code&gt;) to include your specific file paths and input parameters. For all the subindex files, they will have a portion like the code shown below. This is the only part you must update as required:&lt;/p&gt; &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-2&#34;&gt;&lt;a id=&#34;__codelineno-2-2&#34; name=&#34;__codelineno-2-2&#34; href=&#34;#__codelineno-2-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-3&#34;&gt;&lt;a id=&#34;__codelineno-2-3&#34; name=&#34;__codelineno-2-3&#34; href=&#34;#__codelineno-2-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-4&#34;&gt;&lt;a id=&#34;__codelineno-2-4&#34; name=&#34;__codelineno-2-4&#34; href=&#34;#__codelineno-2-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2013&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-5&#34;&gt;&lt;a id=&#34;__codelineno-2-5&#34; name=&#34;__codelineno-2-5&#34; href=&#34;#__codelineno-2-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-6&#34;&gt;&lt;a id=&#34;__codelineno-2-6&#34; name=&#34;__codelineno-2-6&#34; href=&#34;#__codelineno-2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-7&#34;&gt;&lt;a id=&#34;__codelineno-2-7&#34; name=&#34;__codelineno-2-7&#34; href=&#34;#__codelineno-2-7&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-8&#34;&gt;&lt;a id=&#34;__codelineno-2-8&#34; name=&#34;__codelineno-2-8&#34; href=&#34;#__codelineno-2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-9&#34;&gt;&lt;a id=&#34;__codelineno-2-9&#34; name=&#34;__codelineno-2-9&#34; href=&#34;#__codelineno-2-9&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-10&#34;&gt;&lt;a id=&#34;__codelineno-2-10&#34; name=&#34;__codelineno-2-10&#34; href=&#34;#__codelineno-2-10&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-11&#34;&gt;&lt;a id=&#34;__codelineno-2-11&#34; name=&#34;__codelineno-2-11&#34; href=&#34;#__codelineno-2-11&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2017&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-12&#34;&gt;&lt;a id=&#34;__codelineno-2-12&#34; name=&#34;__codelineno-2-12&#34; href=&#34;#__codelineno-2-12&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-13&#34;&gt;&lt;a id=&#34;__codelineno-2-13&#34; name=&#34;__codelineno-2-13&#34; href=&#34;#__codelineno-2-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-14&#34;&gt;&lt;a id=&#34;__codelineno-2-14&#34; name=&#34;__codelineno-2-14&#34; href=&#34;#__codelineno-2-14&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-15&#34;&gt;&lt;a id=&#34;__codelineno-2-15&#34; name=&#34;__codelineno-2-15&#34; href=&#34;#__codelineno-2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;calculate_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subindex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-16&#34;&gt;&lt;a id=&#34;__codelineno-2-16&#34; name=&#34;__codelineno-2-16&#34; href=&#34;#__codelineno-2-16&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;input_geojson&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;path_to_your_geojson_file.geojson&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Replace with your census tract or blockgroup GeoJSON file&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-17&#34;&gt;&lt;a id=&#34;__codelineno-2-17&#34; name=&#34;__codelineno-2-17&#34; href=&#34;#__codelineno-2-17&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;output_prefix&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;tracts&amp;gt; or &amp;lt;block_groups&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# tracts or bg based on if we are analyzing tracts or blockgroups&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-18&#34;&gt;&lt;a id=&#34;__codelineno-2-18&#34; name=&#34;__codelineno-2-18&#34; href=&#34;#__codelineno-2-18&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2022&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-19&#34;&gt;&lt;a id=&#34;__codelineno-2-19&#34; name=&#34;__codelineno-2-19&#34; href=&#34;#__codelineno-2-19&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;aggregate_file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&amp;lt;subindex&amp;gt;_&amp;lt;tract/bg&amp;gt;_all.csv&amp;quot;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# update the &amp;lt;subindex&amp;gt; and choose tracts or bg&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-20&#34;&gt;&lt;a id=&#34;__codelineno-2-20&#34; name=&#34;__codelineno-2-20&#34; href=&#34;#__codelineno-2-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;step-3-run-scripts-in-the-following-order&#34;&gt;Step 3: Run Scripts in the Following Order&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Run the Subindex Generators&lt;/strong&gt;:&lt;br /&gt; Execute the following scripts to calculate raw subindices:&lt;/li&gt; &lt;li&gt;&lt;code&gt;CDI_Generator.ipynb&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;LDI_Generator.ipynb&lt;/code&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;IDI_Generator.ipynb&lt;/code&gt;&lt;br /&gt; These can be run in any order.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run PDI&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;For small input files (not many tracts or geojsons), run our current &lt;code&gt;PDI_Generator.ipynb&lt;/code&gt;.&lt;/li&gt; &lt;li&gt; &lt;p&gt;For larger files, a custom approach using CSV files from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt; is requied: - For this, please contact cnguyen369@gatech.edu&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Normalize Subindices&lt;/strong&gt;:&lt;br /&gt; Run &lt;code&gt;Normalizer.ipynb&lt;/code&gt; to normalize the raw subindices across all years and cities.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generate PEI&lt;/strong&gt;:&lt;br /&gt; Finally, run &lt;code&gt;PEI_Generator.ipynb&lt;/code&gt; to calculate the Pedestrian Environment Index.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;step-4-output&#34;&gt;Step 4: Output&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;This process will output normalized subindex files and the final PEI results as CSV and GeoJSON files.&lt;/li&gt; &lt;li&gt;The file format will be:&lt;ul&gt; &lt;li&gt;&lt;code&gt;&amp;lt;subindex&amp;gt;_&amp;lt;city&amp;gt;_&amp;lt;year&amp;gt;.csv/geojson&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Utilize the &lt;code&gt;Subindex_Visualizer.ipynb&lt;/code&gt; file to visualize your geojson file output!&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;7-challenges&#34;&gt;7. Challenges&lt;/h2&gt; &lt;h3 id=&#34;the-biggest-challege-in-our-statistic-generators-was-developing-the-pdi-generator&#34;&gt;The biggest challege in our statistic generators was developing the PDI Generator.&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;While most of our subindexes - &lt;code&gt;CDI&lt;/code&gt;, &lt;code&gt;LDI&lt;/code&gt;, &lt;code&gt;IDI&lt;/code&gt; - use the &lt;code&gt;Overpass API (OSM data)&lt;/code&gt; to gather data, this is not possible for the &lt;code&gt;PDI&lt;/code&gt; as population data is not provided by OSM.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Because of this, we were forced to utilize the &lt;code&gt;Census API&lt;/code&gt;, which had 2 main issues:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It often returned simply the latest data i.e. 2024 data - even when we requested historical population data.&lt;/li&gt; &lt;li&gt;On large geoJSONs, where we have to make hundreds and thousands of API calls, the Census API frequently errored due to API call limits.&lt;ul&gt; &lt;li&gt;This became a considerable problem when running our files using &lt;code&gt;PACE&lt;/code&gt; to generate Census Tract data for Dr Ku. Our code would run for 10 or so hours and then fail - as we would run out of API tokens.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;We got over this challenge by downloading population data by tract/block group directly - from &lt;a href=&#34;https://mcdc.missouri.edu/cgi-bin/uexplore?/data&#34;&gt;Missouri Census Data Center (MCDC)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;We could then easily calculate &lt;code&gt;Population Density&lt;/code&gt; and hence &lt;code&gt;PDI&lt;/code&gt; by block_group/tract by merging this data with our block_groups/tracts geoJSON files - which contain an area column.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;fall-2025-additions-summary&#34;&gt;&lt;strong&gt;Fall 2025 Additions Summary&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;We had 3 main goals this semester: - Adding new subindexes to the overall PEI, to flesh out the statistic and ensure it is as comprehensive as possible. - Update the web app with a few new features: namely allowing for &#34;sliders&#34;, so that users can customize subindex weights (as well as potentially figuring out how to display our 100mb+ nationwide data onto the web app). - Continuing to work alongside Dr Ku with both data generation and tool creation for his research linking mental health issues to walkability.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;8-fall-2025-additions-bike-infrastructure-index-bii&#34;&gt;8. Fall 2025 Additions - Bike Infrastructure Index (BII)&lt;/h2&gt; &lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt; &lt;p&gt;The Bike Infrastructure index scores an area based on the quantity and quality of bike infrastructure.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt; Research has shown how closely related bike-ability and walkability are to a well designed urban environment. Our current approach to PEI ignored biking as a factor, so we wanted to develop a new index that incorporates biking. &lt;/p&gt; &lt;h3 id=&#34;central-idea&#34;&gt;Central Idea&lt;/h3&gt; &lt;p&gt;Map out all bikeable roads in a given area. Then categorize these roads by how beneficial they are as biking infrastructure. Finally find the distance that the infrastructure covers relative to area.&lt;/p&gt; &lt;h3 id=&#34;methodology&#34;&gt;Methodology&lt;/h3&gt; &lt;h4 id=&#34;1-weight-each-major-category-of-bike-infrastructure-from-osm-data&#34;&gt;1) Weight each major category of bike infrastructure from OSM data.&lt;/h4&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{Separate/Protected/Path/Cycle Streets} = \text{0.5} $$ $$ \text{Painted Lanes} = \text{0.25} $$ $$ \text{Shared Roads} = \text{0.15} $$ $$ \text{Local Roads} = \text{0.1} \]&lt;/div&gt; &lt;h4 id=&#34;2-score-each-piece-of-infrastructure-based-on-length-and-weight&#34;&gt;2) Score each piece of infrastructure based on length and weight&lt;/h4&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{Infrastructure Score} = \text{Category weight} * \text{Infrastructure distance} \]&lt;/div&gt; &lt;h4 id=&#34;3-sum-score-for-a-given-area&#34;&gt;3) Sum score for a given area&lt;/h4&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{AreaScore} = \sum_{i=1}^{n} \text{Infrastructure Score}_i \]&lt;/div&gt; &lt;h4 id=&#34;4-normalize-by-area-size&#34;&gt;4) Normalize by area size&lt;/h4&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{BII} = \frac{\text{AreaScore}}{\text{AreaSize}} \]&lt;/div&gt; &lt;h3 id=&#34;data-collection&#34;&gt;Data Collection&lt;/h3&gt; &lt;p&gt;We used &lt;strong&gt;OpenStreetMap (OSM)&lt;/strong&gt; to identify and extract bike infrastructure through relevant polygon-based tags, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&#34;bicycle&#34;: True, &#34;bicycle:conditional&#34;: True, &#34;bicycle_road&#34;: True, &#34;cyclestreet&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;cycleway&#34;: True, &#34;cycleway:segregated&#34;: True, &#34;cycleway:both&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;cycleway:both:segregated&#34;: True, &#34;cycleway:left&#34;: True, &#34;cycleway:left:oneway&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;cycleway:left:segregated&#34;: True, &#34;cycleway:right&#34;: True, &#34;cycleway:right:oneway&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;cycleway:right:segregated&#34;: True, &#34;oneway&#34;: True, &#34;oneway:bicycle&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;direction&#34;: True, &#34;ramp:bicycle&#34;: True, &#34;segregated&#34;: True, &#34;highway&#34;: True, &#34;access&#34;: True,&lt;/li&gt; &lt;li&gt;&#34;access:conditional&#34;: True, &#34;foot&#34;: True, &#34;route&#34;: True, &#34;network&#34;: True, &#34;ref&#34;: True&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;After collecting this data we had to do a lot of filtering to make sure roads were only counted once, to make sure only roads that had the bike tag were included, and to make sure no roads for only cars were included.&lt;/p&gt; &lt;h3 id=&#34;results-visualization&#34;&gt;Results &amp;amp; Visualization&lt;/h3&gt; &lt;p&gt;We were able to generate BII across 2013, 2017, and 2022 for Atlanta. The percent change of BII across all three years is shown below. &lt;/p&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;BikeInfrastructureIndex/BII_percentchange.png&#34; width=&#34;500&#34; alt=&#34;Atlanta BII&#34;&gt; &lt;/p&gt; &lt;p&gt;The image suggests that Atlanta has become more bikeable over time. This analysis perfects algins with the continued investment into bike infrastructure projects by the city of Atlanta.&lt;/p&gt; &lt;p&gt;The next steps of BII is to generate data across the US so that it can properly be integrated into the website and PEI database.&lt;/p&gt; &lt;h2 id=&#34;9-fall-2025-additions-road-safety-index-rsi&#34;&gt;9. Fall 2025 Additions - Road Safety index (RSI)&lt;/h2&gt; &lt;h3 id=&#34;overview_1&#34;&gt;Overview&lt;/h3&gt; &lt;p&gt;The Road Safety Index quantifies how safe (and therefore how walkable) an area is &lt;strong&gt;based on the speed limits of its roads&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt; Research consistently shows a strong relationship between &lt;strong&gt;road speed&lt;/strong&gt; and &lt;strong&gt;pedestrian injury severity and pedestrian safety&lt;/strong&gt;. Thus, we wanted to develop an index that accounts for how road speeds in neighborhoods can affect pedestrian safety, and consequently that area&#39;s walkability.&lt;/p&gt; &lt;h3 id=&#34;central-idea_1&#34;&gt;Central Idea&lt;/h3&gt; &lt;p&gt;We treated &lt;strong&gt;higher road speeds as higher risk&lt;/strong&gt; for pedestrians. RSI computes a &lt;strong&gt;risk score per road segment&lt;/strong&gt;, then aggregates to an &lt;strong&gt;area-level score&lt;/strong&gt; (e.g., census block group / tract) to visualize relative safety/walkability.&lt;/p&gt; &lt;h3 id=&#34;methodology_1&#34;&gt;Methodology&lt;/h3&gt; &lt;h4 id=&#34;1-risk-from-speed-nilssons-power-model&#34;&gt;1) Risk from speed: Nilsson’s Power Model&lt;/h4&gt; &lt;p&gt;We used &lt;strong&gt;Nilsson’s Power Model&lt;/strong&gt; to translate traffic speed into expected changes in crash outcomes.&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ R_{\text{road}} = \left(\frac{v}{v_0}\right)^{\beta} \]&lt;/div&gt; &lt;h4 id=&#34;2-road-level-safety-score-baseline-20-mph&#34;&gt;2) Road-level safety score (baseline = 20 mph)&lt;/h4&gt; &lt;p&gt;Using a baseline speed of &lt;strong&gt;20 mph&lt;/strong&gt;, we compute a risk score per road segment:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{RiskScore} = \left(\frac{\text{RoadSpeed}}{20}\right)^{1.5} \]&lt;/div&gt; &lt;h4 id=&#34;3-weight-by-road-segment-length&#34;&gt;3) Weight by road segment length&lt;/h4&gt; &lt;p&gt;Longer roads should contribute more to an area’s overall safety score, so we weight each segment by its length:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{SegmentRisk} = \text{SegmentLength} \cdot \text{RiskScore} \]&lt;/div&gt; &lt;h4 id=&#34;4-aggregate-to-area-block-group-tract&#34;&gt;4) Aggregate to area (block group / tract)&lt;/h4&gt; &lt;p&gt;We aggregate all segment contributions inside each area:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{AreaScore} = \sum_{i=1}^{n} \text{SegmentRisk}_i \]&lt;/div&gt; &lt;h4 id=&#34;5-optional-normalization-by-area-size&#34;&gt;5) Optional normalization by area size&lt;/h4&gt; &lt;p&gt;To compare areas of different sizes, we optionally normalize by geographic area:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{FinalRSI} = \frac{\text{AreaScore}}{\text{AreaSize}} \]&lt;/div&gt; &lt;h3 id=&#34;data-collection_1&#34;&gt;Data Collection&lt;/h3&gt; &lt;h4 id=&#34;challenge-missing-speed-limits-in-openstreetmap&#34;&gt;Challenge: Missing speed limits in OpenStreetMap&lt;/h4&gt; &lt;p&gt;OpenStreetMap (OSM) does &lt;strong&gt;not&lt;/strong&gt; have comprehensive &lt;code&gt;maxspeed&lt;/code&gt; data across all roads. To address this, we used a &lt;strong&gt;policy-driven approach&lt;/strong&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Research &lt;strong&gt;state legal documentation&lt;/strong&gt; for default speed limits by road type &lt;/li&gt; &lt;li&gt;Match default limits to roads using &lt;strong&gt;OSM highway tags&lt;/strong&gt; &lt;/li&gt; &lt;li&gt;Assign inferred speeds where &lt;code&gt;maxspeed&lt;/code&gt; is missing&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We focused on OSM highway tags that are most likely to affect pedestrian environments: - &lt;code&gt;tertiary&lt;/code&gt; - &lt;code&gt;residential&lt;/code&gt; - &lt;code&gt;unclassified&lt;/code&gt;&lt;/p&gt; &lt;h3 id=&#34;results-visualization_1&#34;&gt;Results &amp;amp; Visualization&lt;/h3&gt; &lt;p&gt;This semester, we focused on producing RSI data for the Atlanta area. Below, you will find a graph visualizing how walkable Atlanta is based on our RSI calculations. Note: Lower RSI scores means an area is more walkable.&lt;/p&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;RoadSafetyIndex/atlanta_rsi_map.png&#34; width=&#34;500&#34; alt=&#34;Atlanta Road Safety Index Map&#34;&gt; &lt;/p&gt; &lt;p&gt;Several of the highest-safety block groups identified by RSI correspond to: - Smaller/local streets&lt;br /&gt; - Greener residential environments&lt;br /&gt; - Lower-speed road networks&lt;/p&gt; &lt;p&gt;There are still improvements that we are interested in making to RSI such as taking into account roads with other highway tags on OSM into our calculations and looking into decreasing the risk score for road segements that have an attached sidewalk.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;10-fall-2025-additions-social-greenspace-index-sgi&#34;&gt;10. Fall 2025 Additions – Social Greenspace Index (SGI)&lt;/h2&gt; &lt;h3 id=&#34;overview_2&#34;&gt;Overview&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Social Greenspace Index (SGI)&lt;/strong&gt; introduces a new dimension of walkability to the Pedestrian Environment Index (PEI) by quantifying &lt;strong&gt;access to outdoor social greenspaces&lt;/strong&gt; within a given area.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt; While greenspace is often measured through environmental indicators such as tree canopy coverage, air quality, or climate conditions, this subindex focuses specifically on &lt;strong&gt;man-made, social outdoor spaces&lt;/strong&gt;—places where people actively gather, recreate, and spend time outdoors. We hypothesize that &lt;strong&gt;areas with more accessible social greenspaces are inherently more walkable&lt;/strong&gt;, as these spaces both encourage and require pedestrian activity.&lt;/p&gt; &lt;h3 id=&#34;central-idea_2&#34;&gt;Central Idea&lt;/h3&gt; &lt;p&gt;SGI treats &lt;strong&gt;social greenspace area as a proxy for pedestrian-oriented urban design&lt;/strong&gt;. Rather than counting the number of greenspace features, the index measures the &lt;strong&gt;total area of social greenspaces&lt;/strong&gt; within a census tract relative to the tract’s total land area.&lt;/p&gt; &lt;p&gt;This approach prioritizes: - Parks and playgrounds&lt;br /&gt; - Dog parks and recreational fields&lt;br /&gt; - Stadiums and other outdoor gathering spaces &lt;/p&gt; &lt;p&gt;The underlying assumption is that &lt;strong&gt;the more space a neighborhood devotes to outdoor social activity, the more conducive it is to walking&lt;/strong&gt;.&lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;methodology_2&#34;&gt;Methodology&lt;/h3&gt; &lt;h4 id=&#34;1-defining-social-greenspace&#34;&gt;1) Defining Social Greenspace&lt;/h4&gt; &lt;p&gt;SGI began as a broader &lt;strong&gt;Environmental Index&lt;/strong&gt;, initially exploring factors such as: - Tree canopy coverage&lt;br /&gt; - Climate variation&lt;br /&gt; - Air quality (e.g., CDC air quality datasets)&lt;/p&gt; &lt;p&gt;However, the scope was narrowed to focus on &lt;strong&gt;social greenspace&lt;/strong&gt;, as this more directly reflects pedestrian use and walkability rather than environmental conditions alone.&lt;/p&gt; &lt;h4 id=&#34;2-data-source-openstreetmap-osm&#34;&gt;2) Data source: OpenStreetMap (OSM)&lt;/h4&gt; &lt;p&gt;We used &lt;strong&gt;OpenStreetMap (OSM)&lt;/strong&gt; to identify and extract social greenspaces through relevant polygon-based tags, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;leisure&lt;/code&gt;: &lt;code&gt;park&lt;/code&gt;, &lt;code&gt;playground&lt;/code&gt;, &lt;code&gt;dog_park&lt;/code&gt;, &lt;code&gt;stadium&lt;/code&gt;, &lt;code&gt;common&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;natural&lt;/code&gt;: &lt;code&gt;grassland&lt;/code&gt;, &lt;code&gt;wood&lt;/code&gt;, &lt;code&gt;fell&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;landuse&lt;/code&gt;: &lt;code&gt;meadow&lt;/code&gt;, &lt;code&gt;vineyard&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Unlike count-based indices, SGI relies on &lt;strong&gt;area-based polygons&lt;/strong&gt;, allowing us to capture the actual spatial footprint of greenspaces.&lt;/p&gt; &lt;h4 id=&#34;3-area-based-scoring&#34;&gt;3) Area-based scoring&lt;/h4&gt; &lt;p&gt;For each census tract, the Social Greenspace Index is computed as:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{SGI} = \frac{\text{Total Social Greenspace Area}}{\text{Total Tract Area}} \]&lt;/div&gt; &lt;p&gt;This produces a &lt;strong&gt;normalized score between 0 and 1&lt;/strong&gt;, enabling comparison across tracts of different sizes.&lt;/p&gt; &lt;h4 id=&#34;4-integration-with-existing-pei-structure&#34;&gt;4) Integration with existing PEI structure&lt;/h4&gt; &lt;p&gt;SGI was designed to align with the existing PEI framework and methodology, adapting concepts from prior density-based subindices (e.g., CDI) while shifting from &lt;strong&gt;point counts to polygonal area aggregation&lt;/strong&gt;.&lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;results-visualization_2&#34;&gt;Results &amp;amp; Visualization&lt;/h3&gt; &lt;p&gt;This semester, SGI was implemented and visualized for the &lt;strong&gt;Atlanta metropolitan area&lt;/strong&gt;, with results shown for census tracts across multiple years (2013, 2017, and 2022). This is the visualization for 2022:&lt;/p&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;SocialGreenspaceIndex/greenspace_fraction_2022map.png&#34; width=&#34;500&#34; alt=&#34;Atlanta Social Greenspace Index Maps (2013–2022)&#34;&gt; &lt;/p&gt; &lt;p&gt;Across the three time periods, the visualizations suggest that &lt;strong&gt;Atlanta has become more walkable over time when evaluated through the lens of social greenspace availability&lt;/strong&gt;. Several tracts show noticeable increases in greenspace fraction, particularly in areas surrounding large parks and recreational corridors.&lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;limitations-future-work&#34;&gt;Limitations &amp;amp; Future Work&lt;/h3&gt; &lt;p&gt;While SGI provides a meaningful new perspective on walkability, several limitations remain and will be addressed in future work:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Polygon overlay verification&lt;/strong&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A full validation of the spatial overlay process is needed to ensure all greenspace polygons are correctly intersected with census tract boundaries.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Computational efficiency&lt;/strong&gt; &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Area-based polygon processing is computationally intensive. Future iterations will focus on optimizing spatial operations to support &lt;strong&gt;nationwide implementation&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comparison with original Environmental Index concept&lt;/strong&gt; &lt;/p&gt; &lt;/li&gt; &lt;li&gt;A formal comparison between the initial Environmental Index (tree canopy, air quality, climate) and SGI will be conducted to evaluate their relative explanatory power for walkability outcomes.&lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;11-fall-2025-additions-dr-ku-research-updates&#34;&gt;11. Fall 2025 Additions — Dr. Ku Research Updates&lt;/h2&gt; &lt;h3 id=&#34;pei-analysis-updates&#34;&gt;PEI Analysis Updates&lt;/h3&gt; &lt;p&gt;This semester included several important research updates from Dr. Ku’s group. As shown below, the analysis found a &lt;strong&gt;strong association between census tract–level Pedestrian Environment Index (PEI) and distressing Psychotic-Like Experiences (PLEs)&lt;/strong&gt;. Notably, this relationship remained significant after adjusting for a comprehensive set of individual- and neighborhood-level covariates, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Age &lt;/li&gt; &lt;li&gt;Sex &lt;/li&gt; &lt;li&gt;Race/ethnicity &lt;/li&gt; &lt;li&gt;Parental education &lt;/li&gt; &lt;li&gt;Family history of psychosis &lt;/li&gt; &lt;li&gt;Financial adversity &lt;/li&gt; &lt;li&gt;Neighborhood crime &lt;/li&gt; &lt;li&gt;Neighborhood population density &lt;/li&gt; &lt;/ul&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;NeighborhoodMatcher/PEI_Association.png&#34; width=&#34;500&#34; alt=&#34;PEI association results&#34;&gt; &lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;neighborhood-matching-tool-paper-code&#34;&gt;Neighborhood Matching Tool — Paper &amp;amp; Code&lt;/h3&gt; &lt;p&gt;In parallel with this analysis, we completed a paper this semester describing the design and implementation of our &lt;strong&gt;Neighborhood Matching tool&lt;/strong&gt;, which enables privacy-preserving linkage between participant-level data and census tract–level neighborhood measures.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Code repository:&lt;/strong&gt;&lt;br /&gt; 🔗 https://github.com/SustainableUrbanSystemsLab/NeighborhoodMatcher&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Paper:&lt;/strong&gt;&lt;br /&gt; Click the preview below to view the full, scrollable PDF.&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;NeighborhoodMatcher/NeighborhoodMatcher_Paper.pdf&#34;&gt;&lt;img src=&#34;./NeighborhoodMatcher/NeighborhoodMatcher_Preview-1.png&#34; alt=&#34;Neighborhood Matcher paper preview&#34; max-width=&#34;600&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;12-overall-future-work&#34;&gt;12. Overall Future Work&lt;/h2&gt; &lt;p&gt;To improve the comprehensiveness of the Public Infrastructure Environment (PIE) framework, a major future goal is to expand the number of subindices beyond the current set.&lt;br /&gt; If we were to do this, we also want to make sure that they are properly integrated into PEI.&lt;/p&gt; &lt;p&gt;Planned improvements include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;More New Subindices&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The more the merrier! Because we have shifted to a &#34;slider&#34; approach, where users customize their subindex weights towards overall PEI based on their personal needs. Adding new subindices will only further improve on not only the comprehensiveness of PEI, but also on the customizability of our product. &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Integrate the Subindices fully with our current PEI&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;As mentioned above we now have data for Atlanta for 4 new subindices, but we now must re-run our PEI generation pipeline to fully integrate these 4 into our nationwide datasets. Additionally, we will work towards adding the 4 new subindices to our web app.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Web App Expansion&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;While we have nationwide datasets, our web app still only displays Atlanta data. We will work on adding new cities and potentially even adding nationwide data. We also want &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Official Publication&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Publish our research officially and publicly to help advance urban sustainability.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ground-Truthing&lt;/strong&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Conduct surveys and other research to validate PEI accuracy and compare with other walkability models.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;13-contributing&#34;&gt;13. Contributing&lt;/h2&gt; &lt;p&gt;We welcome contributions to this project. &lt;/p&gt; &lt;h3 id=&#34;steps-to-contribute&#34;&gt;Steps to Contribute:&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Fork the repository.&lt;/li&gt; &lt;li&gt;Create a feature branch: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;checkout&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-b&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;feature/new-feature &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Push your changes and submit a pull request.&lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;14-license&#34;&gt;14. License&lt;/h2&gt; &lt;p&gt;This project is shared for research and educational purposes. Please do not redistribute for commercial use.&lt;/p&gt; &lt;hr /&gt; &lt;h1 id=&#34;web-app-documentation&#34;&gt;Web App Documentation&lt;/h1&gt; &lt;p&gt;The web app is currently deployed at this link: https://vip-pei-app-2.onrender.com/ 😊&lt;/p&gt; &lt;p&gt;This deployment is dynamic and so any updates to our codebase (https://github.com/AtharvaBeesen/vip-pei-app-2) will automatically be displayed.&lt;/p&gt; &lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;App Name&lt;/strong&gt;: VIP SMUR PEI Proof of Concept&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Visualize the work we have done in creating the aforementioned subindexes. We also wanted to allow the data we generate to be available online in a visually appealing, paletable, and easy-to-download way.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;key-features&#34;&gt;Key Features:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Interactive map with GeoJSON visualization for the subindexes - PDI, IDI, CDI, LDI, PEI - across different cities and years.&lt;/li&gt; &lt;li&gt;Dynamic city, statistic, and year selection.&lt;/li&gt; &lt;li&gt;Ability to download CSV and GeoJSON files for selected data.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;technology-stack&#34;&gt;Technology Stack:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React, JavaScript, HTML, CSS&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: All functionality contained within JavaScript&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mapping Library&lt;/strong&gt;: Leaflet&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: Amazon S3 Buckets&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;2-getting-started_1&#34;&gt;2. Getting Started&lt;/h2&gt; &lt;h3 id=&#34;prerequisites_1&#34;&gt;Prerequisites&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Node.js and npm/yarn&lt;/strong&gt;:&lt;br /&gt; Ensure Node.js and npm (or yarn) are installed on your system. You can check this by running: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;node&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-v &lt;/span&gt;&lt;span id=&#34;__span-4-2&#34;&gt;&lt;a id=&#34;__codelineno-4-2&#34; name=&#34;__codelineno-4-2&#34; href=&#34;#__codelineno-4-2&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-v &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; If not installed, download them from &lt;a href=&#34;https://nodejs.org/&#34;&gt;Node.js official site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code Editor (Optional)&lt;/strong&gt;:&lt;br /&gt; Install a code editor like &lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;Visual Studio Code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Browser&lt;/strong&gt;:&lt;br /&gt; A modern browser like Chrome, Firefox, or Edge to test your app.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Git&lt;/strong&gt;:&lt;br /&gt; Install Git for cloning the repository. Check installation by running: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--version &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leaflet Library Dependencies&lt;/strong&gt;:&lt;br /&gt; The app uses Leaflet for maps, which requires:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;A valid internet connection to download Leaflet assets via npm or yarn.&lt;/li&gt; &lt;li&gt;Ensure the browser supports Leaflet.&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;installation_1&#34;&gt;Installation&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Clone the repository: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;clone&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;https://github.com/AtharvaBeesen/vip-pei-app-2.git &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Install dependencies: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-7-1&#34;&gt;&lt;a id=&#34;__codelineno-7-1&#34; name=&#34;__codelineno-7-1&#34; href=&#34;#__codelineno-7-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Ensure Leaflet is installed: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-8-1&#34;&gt;&lt;a id=&#34;__codelineno-8-1&#34; name=&#34;__codelineno-8-1&#34; href=&#34;#__codelineno-8-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;leaflet &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Run the application: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-9-1&#34;&gt;&lt;a id=&#34;__codelineno-9-1&#34; name=&#34;__codelineno-9-1&#34; href=&#34;#__codelineno-9-1&#34;&gt;&lt;/a&gt;npm&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;start &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Access the app at &lt;code&gt;http://localhost:3000&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;deployment&#34;&gt;Deployment&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Already deployed! We deployed using &lt;code&gt;Render&lt;/code&gt;:&lt;br /&gt; &lt;a href=&#34;https://vip-pei-app-2.onrender.com/&#34;&gt;https://vip-pei-app-2.onrender.com/&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;3-features&#34;&gt;3. Features&lt;/h2&gt; &lt;h3 id=&#34;31-interactive-map&#34;&gt;3.1 Interactive Map&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Displays GeoJSON data visualized on a Leaflet map.&lt;/li&gt; &lt;li&gt;Map dynamically updates based on city, statistic, and year selections.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;32-city-statistic-and-year-selection&#34;&gt;3.2 City, Statistic, and Year Selection&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Dropdown menus for users to select:&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Cities&lt;/strong&gt;: Atlanta, New York, Los Angeles.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Statistics&lt;/strong&gt;: IDI, PDI, CDI, LDI, PEI.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Years&lt;/strong&gt;: 2022, 2013.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;33-file-downloads&#34;&gt;3.3 File Downloads&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;CSV and GeoJSON files for the selected data can be downloaded with a single click.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;4-components&#34;&gt;4. Components&lt;/h2&gt; &lt;h3 id=&#34;41-appjs&#34;&gt;4.1 App.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;The main entry point for the application.&lt;/li&gt; &lt;li&gt;Manages state for selected city, statistic, and year.&lt;/li&gt; &lt;li&gt;Renders &lt;code&gt;CitySelector&lt;/code&gt;, &lt;code&gt;DownloadButton&lt;/code&gt;, and &lt;code&gt;MapComponent&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;42-cityselectorjs&#34;&gt;4.2 CitySelector.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Dropdown menus for selecting city, statistic, and year.&lt;/li&gt; &lt;li&gt;Capitalizes city names and statistics for user-friendly display.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;43-mapcomponentjs&#34;&gt;4.3 MapComponent.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Displays the Leaflet map and GeoJSON data.&lt;/li&gt; &lt;li&gt;Dynamically fetches data from S3 Buckets based on user selections (more on this below).&lt;/li&gt; &lt;li&gt;Highlights GeoJSON features with a color-coded scheme based on statistic values.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;44-downloadbuttonjs&#34;&gt;4.4 DownloadButton.js&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Provides buttons to download CSV and GeoJSON files from S3.&lt;/li&gt; &lt;li&gt;Dynamically constructs download URLs based on user selections.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-api-integration&#34;&gt;5. API Integration&lt;/h2&gt; &lt;p&gt;The app dynamically fetches GeoJSON data from an Amazon S3 bucket: - URL format:&lt;br /&gt; &lt;code&gt;https://vip-censusdata.s3.us-east-2.amazonaws.com/{city}_blockgroup_{statistic}_{year}.geojson&lt;/code&gt;&lt;/p&gt; &lt;h3 id=&#34;example&#34;&gt;Example:&lt;/h3&gt; &lt;p&gt;For Atlanta, IDI, and 2022:&lt;br /&gt; &lt;code&gt;https://vip-censusdata.s3.us-east-2.amazonaws.com/atlanta_blockgroup_IDI_2022.geojson&lt;/code&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;5-city-comparison-tool-spring-2025&#34;&gt;5. City Comparison Tool (Spring 2025)&lt;/h2&gt; &lt;h3 id=&#34;1-overview&#34;&gt;&lt;strong&gt;1. Overview&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;We created a City Comparison Tool MVP to allow users to dynamically compare changes in walkability-related subindices (IDI, PDI, CDI, LDI, PEI) between two different years for a selected city.&lt;/p&gt; &lt;p&gt;This tool calculates and visualizes the &lt;strong&gt;percentage change&lt;/strong&gt; in the selected statistic for each census block group, helping to identify areas that have improved or declined over time.&lt;/p&gt; &lt;h3 id=&#34;2-key-features&#34;&gt;&lt;strong&gt;2. Key Features&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;City Selection&lt;/strong&gt;:&lt;br /&gt; Compare changes for Atlanta, New York, or Los Angeles.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Statistic Selection&lt;/strong&gt;:&lt;br /&gt; Choose one of the following subindices to analyze:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Intersection Density Index (IDI)&lt;/li&gt; &lt;li&gt;Population Density Index (PDI)&lt;/li&gt; &lt;li&gt;Commercial Density Index (CDI)&lt;/li&gt; &lt;li&gt;Land-use Diversity Index (LDI)&lt;/li&gt; &lt;li&gt; &lt;p&gt;Pedestrian Environment Index (PEI)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Year Selection&lt;/strong&gt;:&lt;br /&gt; Select two different years to calculate the percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic GeoJSON Visualization&lt;/strong&gt;:&lt;br /&gt; The map displays block groups color-coded by the percentage change in the selected statistic.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive Tooltips&lt;/strong&gt;:&lt;br /&gt; Hovering over a block group shows its GEOID and computed percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Custom Color Scale&lt;/strong&gt;:&lt;br /&gt; The visualization uses a diverging color scheme to easily distinguish between positive and negative changes.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;3-technical-workflow&#34;&gt;&lt;strong&gt;3. Technical Workflow&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Fetching&lt;/strong&gt;:&lt;br /&gt; The tool fetches the respective city&#39;s GeoJSON files for both selected years from the Amazon S3 bucket.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Difference Calculation&lt;/strong&gt;: &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;For most subindices (IDI, PDI, CDI, PEI), block groups are matched by &lt;strong&gt;GEOID&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Percent Change Computation&lt;/strong&gt;:&lt;br /&gt; The percent change for each block group is calculated as:&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{Percent Change} = \frac{(\text{After Value} - \text{Before Value})}{\text{Before Value}} \times 100 \]&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Visualization&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Block groups are shaded according to the magnitude of their percent change.&lt;/li&gt; &lt;li&gt; &lt;p&gt;Tooltips display the block group ID and the exact percent change.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Robust Edge Case Handling&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;If both before and after values are zero, the percent change is set to 0.&lt;/li&gt; &lt;li&gt;If a before value is zero and after is nonzero, the block group is highlighted accordingly without division errors.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;4-known-limitations&#34;&gt;&lt;strong&gt;4. Known Limitations&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Only a few cities and years are currently available.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;5-future-work&#34;&gt;&lt;strong&gt;5. Future Work&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Add more cities and historical years to expand the tool’s coverage.&lt;/li&gt; &lt;li&gt;Improve LDI data quality by assigning proper GEOIDs.&lt;/li&gt; &lt;li&gt;Integrate this comparison tool directly into the main PEI web app navigation.&lt;/li&gt; &lt;li&gt;Add multi-year trend graphs and regional aggregation for deeper urban insights.&lt;/li&gt; &lt;li&gt;Allow users to select multiple subindices at once for richer comparisons.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;6-metric-weighting-composite-score-tool-spring-2025&#34;&gt;6. Metric Weighting &amp;amp; Composite Score Tool (Spring 2025)&lt;/h2&gt; &lt;h3 id=&#34;1-overview_1&#34;&gt;&lt;strong&gt;1. Overview&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;We built a Metric Weighting and Composite Score tool that lets users control how different walkability subindices contribute to an overall score at the census block group level.&lt;/p&gt; &lt;p&gt;Instead of showing a single fixed index, this feature allows users to adjust the importance of each subindex using sliders and immediately see how those choices change the map. This makes it easier to explore how different definitions of “walkability” affect walkability patterns across a city.&lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;2-key-features_1&#34;&gt;&lt;strong&gt;2. Key Features&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Interactive Metric Sliders&lt;/strong&gt;&lt;br /&gt; Users can adjust the relative weight (0–100%) of each subindex:&lt;/li&gt; &lt;li&gt;Intersection Density Index (IDI)&lt;/li&gt; &lt;li&gt;Land-use Diversity Index (LDI)&lt;/li&gt; &lt;li&gt;Population Density Index (PDI)&lt;/li&gt; &lt;li&gt; &lt;p&gt;Commercial Density Index (CDI)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Live Map Updates&lt;/strong&gt;&lt;br /&gt; Any change to a slider instantly recalculates scores and updates the map.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Weighted Composite Scores&lt;/strong&gt;&lt;br /&gt; Each block group receives a composite score based on the selected weights.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Color-Coded Visualization&lt;/strong&gt;&lt;br /&gt; Block groups are shaded using a green–yellow–red scale, where higher values indicate more favorable pedestrian environments.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Informative Tooltips&lt;/strong&gt;&lt;br /&gt; Hovering over a block group displays:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;GEOID&lt;/li&gt; &lt;li&gt;Composite score&lt;/li&gt; &lt;li&gt;Individual subindex values used in the calculation&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;3-technical-workflow_1&#34;&gt;&lt;strong&gt;3. Technical Workflow&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Data Loading&lt;/strong&gt;&lt;br /&gt; For the selected city and year, the app fetches four separate GeoJSON files (one per subindex) from an Amazon S3 bucket:&lt;/li&gt; &lt;li&gt;&lt;code&gt;{city}_blockgroup_IDI_{year}.geojson&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;{city}_blockgroup_LDI_{year}.geojson&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;{city}_blockgroup_PDI_{year}.geojson&lt;/code&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;{city}_blockgroup_CDI_{year}.geojson&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;GEOID Matching&lt;/strong&gt;&lt;br /&gt; Subindex values are aligned across datasets using the block group GEOID to ensure consistency.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Composite Score Calculation&lt;/strong&gt;&lt;br /&gt; For each block group, the composite score is calculated as a weighted average:&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \text{Composite Score} = \frac{\sum_{m} w_m \cdot v_m}{\sum_{m} w_m} \]&lt;/div&gt; &lt;p&gt;where: - &lt;span class=&#34;arithmatex&#34;&gt;\(v_m\)&lt;/span&gt; is the block group’s value for metric &lt;span class=&#34;arithmatex&#34;&gt;\(m\)&lt;/span&gt; - &lt;span class=&#34;arithmatex&#34;&gt;\(w_m\)&lt;/span&gt; is the user-defined weight for metric &lt;span class=&#34;arithmatex&#34;&gt;\(m\)&lt;/span&gt;&lt;/p&gt; &lt;p&gt;If all weights are set to zero, no composite score is shown to avoid misleading results.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Map Rendering&lt;/strong&gt; &lt;/li&gt; &lt;li&gt;Recalculating scores triggers a map re-render.&lt;/li&gt; &lt;li&gt;A custom color scale maps composite values to shades of green, yellow, and red.&lt;/li&gt; &lt;li&gt;Tooltips are updated to reflect the new composite and individual metric values.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;4-design-rationale&#34;&gt;&lt;strong&gt;4. Design Rationale&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;This feature is designed to make the index construction process transparent. By letting users control metric weights, the tool shows how assumptions about what matters for walkability can change the results. This is particularly useful for researchers who may be targeting specific elements of walkability more than others (for example, researchers more interested in the effects of higher land use variation may adjust so that LDI is higher weighted).&lt;/p&gt; &lt;p&gt;Rather than presenting a single “correct” score, the interface encourages exploration and comparison of different weighting choices.&lt;/p&gt; &lt;hr /&gt; &lt;h3 id=&#34;5-known-limitations&#34;&gt;&lt;strong&gt;5. Known Limitations&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Composite scores depend on how the underlying subindices are scaled.&lt;/li&gt; &lt;li&gt;Only Atlanta data is currently available.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&#34;6-future-work&#34;&gt;&lt;strong&gt;6. Future Work&lt;/strong&gt;&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Include new subindices we have created recently to be sider options (such as our transit, biking, road safety, and greenspace subindexes).&lt;/li&gt; &lt;li&gt;Allow users to save and share custom weighting presets.&lt;/li&gt; &lt;li&gt;Support side-by-side comparison of different weighting schemes.&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;7-future-work&#34;&gt;7. Future Work&lt;/h2&gt; &lt;h3 id=&#34;there-are-3-key-goals-we-hope-to-achieve&#34;&gt;There are 3 key goals we hope to achieve:&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Increase the number of cities and years supported&lt;/strong&gt;:&lt;br /&gt; This would simply require us to continue running our subindex generators over the course of the next semester(s) in order to continue to grow the size of our database.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Seek Collaboration/Monetization Opportunities&lt;/strong&gt;:&lt;br /&gt; As we grow the site and our footprint in the space, we could seek to replicate WalkScore&#39;s monetization and collaboration business model:&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Collaborate with products/sites&lt;/strong&gt;:&lt;br /&gt; Work with products or sites that require walkability statistics (e.g., Zillow and City Planning Companies) to create customized statistics at a cost.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Direct collaboration with local government&lt;/strong&gt;:&lt;br /&gt; Assist local governments in achieving their goals of improving walkability in urban areas.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Developing a for-cost API&lt;/strong&gt;:&lt;br /&gt; Create an API that allows third-party researchers to use our data. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;For Example: Collaborating with researchers like Dr. Ku, who uses our data to enhance his psychology research.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ol&gt; &lt;hr /&gt; &lt;h2 id=&#34;8-contributing&#34;&gt;8. Contributing&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Please contact abeesen3@gatech.edu before doing so.&lt;/li&gt; &lt;li&gt;Example of how to contribute:&lt;/li&gt; &lt;li&gt;Fork the repository (https://github.com/AtharvaBeesen/vip-pei-app-2)&lt;/li&gt; &lt;li&gt;Create a feature branch: &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-10-1&#34;&gt;&lt;a id=&#34;__codelineno-10-1&#34; name=&#34;__codelineno-10-1&#34; href=&#34;#__codelineno-10-1&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;checkout&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-b&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;feature/new-feature &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Push your changes and submit a pull request.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;9-license&#34;&gt;9. License&lt;/h2&gt; &lt;p&gt;This project is shared for research and educational purposes. Please do not redistribute for commercial use.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=II8eYLK199c&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/II8eYLK199c/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Atharva Beesen&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AtharvaBeesen&#34;&gt;AtharvaBeesen&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mason Dewitt&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Masonrd&#34;&gt;Masonrd&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Katherine Davis&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/katherine-el-davis&#34;&gt;katherine-el-davis&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Lucy Chai&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/lucymchai&#34;&gt;lucymchai&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-mobility/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-mobility/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-mobility/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-mobility/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-Microclimate-Outdoor+</title> <description>&lt;h1 id=&#34;25fa-microclimate-umcf&#34;&gt;25Fa-Microclimate-UMCF&lt;/h1&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;figures/umcf.gif&#34; width=&#34;1000&#34; alt=&#34;UMCF / Outdoor+ workflow overview&#34;&gt; &lt;/p&gt; &lt;h3 id=&#34;umcf&#34;&gt;UMCF&lt;/h3&gt; &lt;p&gt;A collection of components to use the&lt;br /&gt; &lt;strong&gt;urbanMicroclimateFoam&lt;/strong&gt; solver.&lt;/p&gt; &lt;h2 id=&#34;a-grasshopper-plugin-for-microclimate-simulations&#34;&gt;A Grasshopper plugin for microclimate simulations&lt;/h2&gt; &lt;p&gt;&lt;img alt=&#34;language&#34; src=&#34;https://img.shields.io/badge/language-C%23-555&#34; /&gt; &lt;img alt=&#34;status&#34; src=&#34;https://img.shields.io/badge/status-beta-2ea44f&#34; /&gt;&lt;/p&gt; &lt;p&gt;The plugin is based on the &lt;strong&gt;urbanMicroclimateFoam&lt;/strong&gt; open-source solver based on &lt;strong&gt;OpenFOAM&lt;/strong&gt;,&lt;br /&gt; developed by the &lt;strong&gt;Chair of Building Physics at ETH Zürich&lt;/strong&gt;.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;GitHub repository:&lt;/strong&gt; https://github.com/OpenFOAM-BuildingPhysics/urbanMicroclimateFoam &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;urbanMicroclimateFoam (uMFoam)&lt;/strong&gt; is an open-source solver built on &lt;strong&gt;OpenFOAM&lt;/strong&gt; for modeling urban microclimates.&lt;br /&gt; It simulates multiple coupled physical processes, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Turbulent airflow &lt;/li&gt; &lt;li&gt;Heat and moisture transport in air &lt;/li&gt; &lt;li&gt;Radiative heat exchange (shortwave and longwave) &lt;/li&gt; &lt;li&gt;Heat and moisture storage in building materials (&lt;strong&gt;HAM model&lt;/strong&gt;) &lt;/li&gt; &lt;li&gt;Urban vegetation heat balance &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Learn more at the official repository:&lt;br /&gt; 🔗 &lt;strong&gt;&lt;a href=&#34;https://github.com/OpenFOAM-BuildingPhysics/urbanMicroclimateFoam&#34;&gt;urbanMicroclimateFoam GitHub&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt; &lt;h3 id=&#34;cfd-computational-fluid-dynamics-model&#34;&gt;🌊 CFD — Computational Fluid Dynamics Model&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Solves turbulent, convective airflow &lt;/li&gt; &lt;li&gt;Handles heat and moisture transport in the air subdomain &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;ham-heat-and-moisture-transport-model&#34;&gt;🏗️ HAM — Heat and Moisture Transport Model&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Manages absorption and transport &lt;/li&gt; &lt;li&gt;Controls storage of heat and moisture in porous building materials &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;rad-radiation-model&#34;&gt;☀️ RAD — Radiation Model&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Calculates net longwave and shortwave radiative heat fluxes &lt;/li&gt; &lt;li&gt;Uses view factor approach &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;veg-vegetation-model&#34;&gt;🌳 VEG — Vegetation Model&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Solves heat balance for urban trees &lt;/li&gt; &lt;li&gt;Handles green surfaces &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt; &lt;h3 id=&#34;1-install-openfoam-windows&#34;&gt;1. Install OpenFOAM (Windows)&lt;/h3&gt; &lt;p&gt;Install &lt;strong&gt;blueCFD-Core 2020&lt;/strong&gt;, which includes &lt;strong&gt;OpenFOAM 8&lt;/strong&gt;.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Download: &lt;code&gt;blueCFD-Core-2020-1-win64-setup.exe&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;2-install-umcf-plugin-for-grasshopper-rhino&#34;&gt;2. Install UMCF Plugin for Grasshopper (Rhino)&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Open &lt;strong&gt;Rhinoceros&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Run the &lt;code&gt;PackageManager&lt;/code&gt; command&lt;/li&gt; &lt;li&gt;Search for &lt;strong&gt;UMCF&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Enable &lt;strong&gt;“Include pre-releases”&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Install&lt;/strong&gt; and restart Rhino&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;fall-2025-additions-urban-morphology-microclimate-tokyo-case-study&#34;&gt;Fall 2025 Additions – Urban Morphology &amp;amp; Microclimate (Tokyo Case Study)&lt;/h2&gt; &lt;h3 id=&#34;overview_1&#34;&gt;Overview&lt;/h3&gt; &lt;p&gt;This case study evaluates how &lt;strong&gt;urban morphology&lt;/strong&gt; influences &lt;strong&gt;temperature and wind-related variables&lt;/strong&gt; within the urban microclimate. Using &lt;strong&gt;Tokyo, Japan&lt;/strong&gt; as a case study, we investigate the relationship between dense urban form, geometric complexity, and microclimate behavior through CFD simulations.&lt;/p&gt; &lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt; &lt;p&gt;Urban morphology—such as building density, height variation, and street canyon geometry—plays a critical role in shaping microclimate conditions. Tokyo’s dense and heterogeneous urban fabric, characterized by narrow streets and sharp transitions between open and enclosed spaces, presents a challenging yet valuable context for examining these effects.&lt;/p&gt; &lt;p&gt;This study aims to understand how urban form affects microclimate performance, while also identifying technical limitations related to geometry handling and mesh generation in high-density environments.&lt;/p&gt; &lt;h3 id=&#34;central-idea&#34;&gt;Central Idea&lt;/h3&gt; &lt;p&gt;We treat urban morphology as a primary driver of microclimate variation.&lt;br /&gt; By constructing a detailed 3D urban model of Tokyo and running iterative simulations, we assess how temperature and wind patterns respond to spatial configuration, mesh resolution, and model setup.&lt;/p&gt; &lt;h3 id=&#34;methodology&#34;&gt;Methodology&lt;/h3&gt; &lt;h4 id=&#34;1-urban-morphology-modeling&#34;&gt;1) Urban Morphology Modeling&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Construct a detailed 3D urban model of selected Tokyo areas&lt;/li&gt; &lt;li&gt;Capture key morphological characteristics, including:&lt;/li&gt; &lt;li&gt;Narrow street canyons&lt;/li&gt; &lt;li&gt;High building density&lt;/li&gt; &lt;li&gt;Sharp transitions between open and enclosed spaces&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;2-simulation-and-iterative-refinement&#34;&gt;2) Simulation and Iterative Refinement&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Run simulations using &lt;strong&gt;urbanMicroclimateFoam (UMCF)&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Analyze temperature and wind-related outputs&lt;/li&gt; &lt;li&gt;Iteratively refine the computational mesh and model configuration based on simulation behavior and numerical stability&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;data-collection&#34;&gt;Data Collection&lt;/h3&gt; &lt;h4 id=&#34;urban-geometry-and-morphology&#34;&gt;Urban Geometry and Morphology&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Building footprints and heights were collected from &lt;strong&gt;PLATEAU (MLIT, Japan)&lt;/strong&gt;&lt;br /&gt; https://www.mlit.go.jp/plateau/en/&lt;/li&gt; &lt;li&gt;PLATEAU CityGML data were converted into a Rhinoceros-compatible format using a custom &lt;strong&gt;Grasshopper (GML reader) workflow&lt;/strong&gt;, enabling geometry preprocessing and inspection within Rhino.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt; &lt;h4 id=&#34;mesh-generation-and-computational-cost&#34;&gt;Mesh Generation and Computational Cost&lt;/h4&gt; &lt;p&gt;The large number of objects and high geometric complexity made mesh generation a critical and persistent challenge.&lt;/p&gt; &lt;p&gt;High-density urban geometry requires fine meshes to accurately resolve wind flow and temperature gradients. However, finer meshes significantly increase computational cost, necessitating trade-offs between accuracy, numerical stability, and feasibility.&lt;/p&gt; &lt;p&gt;Mesh-related errors occurred repeatedly and were not fully resolved within the project timeframe.&lt;/p&gt; &lt;p&gt;Several basic geometric conditions were identified as necessary for stable simulations: - All buildings must touch the same &lt;strong&gt;XY ground plane&lt;/strong&gt; (no floating geometries) - Vegetation objects must be sufficiently &lt;strong&gt;distanced from buildings&lt;/strong&gt; - The bottom face of all buildings must be removed - The mesh must exhibit a well-formed topology, with small, uniform, and evenly distributed triangular faces&lt;/p&gt; &lt;h3 id=&#34;future-improvements&#34;&gt;Future Improvements&lt;/h3&gt; &lt;p&gt;Potential future directions include: - Developing more robust mesh-cleaning and validation workflows - Simplifying urban geometry while preserving key morphological characteristics - Establishing quantitative metrics to compare simulation stability across mesh resolutions - Expanding analysis to multiple Tokyo districts with contrasting urban forms&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AnX9a9fqACU&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/AnX9a9fqACU/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Marcelo Álvarez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (DC)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/alvarezdmarch&#34;&gt;alvarezdmarch&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mallika Champaneria&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mallikachampaneria&#34;&gt;mallikachampaneria&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Shaiba Bano&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Urban Design&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sshaiba3&#34;&gt;sshaiba3&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nitiksha Mota&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Urban Design&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nmota6&#34;&gt;nmota6&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Aiko Hayashi&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AnneTotoro&#34;&gt;AnneTotoro&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sina Rahimi&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architectural Science&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sinarhm&#34;&gt;sinarahimi&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-microclimate-outdoorplus/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-microclimate-outdoorplus/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-microclimate-outdoorplus/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-microclimate-outdoorplus/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-Microclimate-ML</title> <description>&lt;h1 id=&#34;microclimate-weather-prediction-with-deep-learning&#34;&gt;Microclimate Weather Prediction with Deep Learning&lt;/h1&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;Georgia Tech VIP-SMUR Project&lt;/strong&gt; | Fall 2025&lt;br /&gt; High-resolution microclimate weather prediction combining FusionLSTM deep learning architecture, Regression Kriging, and spatial analysis&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.8+-blue.svg&#34; alt=&#34;Python 3.8+&#34; max-width=&#34;600&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://pytorch.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-2.0+-red.svg&#34; alt=&#34;PyTorch&#34; max-width=&#34;600&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-green.svg&#34; alt=&#34;License&#34; max-width=&#34;600&#34; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;This project combines multiple advanced techniques to predict microclimate weather patterns at Georgia Tech campus with high spatial and temporal resolution. The pipeline integrates &lt;strong&gt;FusionLSTM&lt;/strong&gt; (a TFT-inspired architecture featuring multi-scale LSTM branches with attention) for time series prediction with &lt;strong&gt;Regression Kriging&lt;/strong&gt; to generate campus-wide maps. The model predicts &lt;strong&gt;Temperature&lt;/strong&gt; and &lt;strong&gt;Relative Humidity&lt;/strong&gt; at &lt;strong&gt;100,283 grid points&lt;/strong&gt; using multi-variate time series and geospatial features.&lt;/p&gt; &lt;p&gt;The model successfully captures extreme weather conditions across Georgia Tech campus. Below are comparison maps showing model predictions vs. actual station observations for four representative scenarios:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Scenario&lt;/th&gt; &lt;th&gt;Conditions&lt;/th&gt; &lt;th&gt;Visualization&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;🔥 Hottest&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;37.30°C avg, 34.56% RH&lt;br&gt;2016-06-25 16:10&lt;/td&gt; &lt;td&gt;&lt;img src=&#34;./4_Inference_and_Visualization/figures/HOTTEST_comparison_map.png&#34; alt=&#34;Hottest&#34; max-width=&#34;600&#34; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;❄️ Coldest&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;8.45°C avg, 89.61% RH&lt;br&gt;2017-05-06 06:30&lt;/td&gt; &lt;td&gt;&lt;img src=&#34;./4_Inference_and_Visualization/figures/COLDEST_comparison_map.png&#34; alt=&#34;Coldest&#34; max-width=&#34;600&#34; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;🏜️ Driest&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;18.13°C avg, 17.95% RH&lt;br&gt;2015-04-04 18:30&lt;/td&gt; &lt;td&gt;&lt;img src=&#34;./4_Inference_and_Visualization/figures/DRIEST_comparison_map.png&#34; alt=&#34;Driest&#34; max-width=&#34;600&#34; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;💧 Most Humid&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;16.73°C avg, 99.50% RH&lt;br&gt;2015-04-18 04:40&lt;/td&gt; &lt;td&gt;&lt;img src=&#34;./4_Inference_and_Visualization/figures/MOST_HUMID_comparison_map.png&#34; alt=&#34;Most Humid&#34; max-width=&#34;600&#34; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;&lt;em&gt;Each comparison map shows side-by-side temperature (left) and relative humidity (right) predictions with station observations overlaid as square markers.&lt;/em&gt;&lt;/p&gt; &lt;h3 id=&#34;why-fusionlstm&#34;&gt;Why FusionLSTM?&lt;/h3&gt; &lt;p&gt;We adapted core TFT components (Gated Residual Networks, Variable Selection, Multi-Head Attention) with three key modifications optimized for microclimate forecasting:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Single-step point prediction&lt;/strong&gt; - Better Kriging integration, avoids compounding uncertainty&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Parallel multi-scale LSTM branches&lt;/strong&gt; - Explicitly captures both rapid fluctuations and diurnal cycles &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Physics-aware features only&lt;/strong&gt; - No station IDs, enabling generalization to unseen locations&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;See &lt;a href=&#34;docs/PROJECT_PLAN.md&#34;&gt;&lt;code&gt;docs/PROJECT_PLAN.md&lt;/code&gt;&lt;/a&gt; for detailed design rationale.&lt;/p&gt; &lt;h3 id=&#34;key-features&#34;&gt;Key Features&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;FusionLSTM Model&lt;/strong&gt; - Multi-scale LSTM with attention for single-step iterative forecasting (+10 minutes ahead)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;16-Station Warm-Season Training&lt;/strong&gt; - April–September data with station holdout validation&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Physics-Aware Features&lt;/strong&gt; - Solar angles and time encodings (no station IDs for generalization)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;High-Resolution Spatial Mapping&lt;/strong&gt; - 100,283 grid points across campus (~3.5 km²)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Regression Kriging&lt;/strong&gt; - PyKrige spatial interpolation with 16-station stability&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Baseline Comparisons&lt;/strong&gt; - Persistence, Linear Regression, Vanilla LSTM&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Publication-Ready Visualizations&lt;/strong&gt; - 300 DPI high-resolution maps&lt;/li&gt; &lt;li&gt;&lt;strong&gt;HPC Integration&lt;/strong&gt; - SLURM scripts for Phoenix cluster (GPU/CPU)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt; &lt;h3 id=&#34;local-machine&#34;&gt;Local Machine&lt;/h3&gt; &lt;h4 id=&#34;step-1-installation&#34;&gt;Step 1: Installation&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Option A: Using UV (Recommended)&lt;/strong&gt;&lt;/p&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Clone the repository (requires GitHub SSH key for private repo)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-2&#34;&gt;&lt;a id=&#34;__codelineno-0-2&#34; name=&#34;__codelineno-0-2&#34; href=&#34;#__codelineno-0-2&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;clone&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;git@github.com:VIP-SMUR/25Fa-Microclimate-ML.git &lt;/span&gt;&lt;span id=&#34;__span-0-3&#34;&gt;&lt;a id=&#34;__codelineno-0-3&#34; name=&#34;__codelineno-0-3&#34; href=&#34;#__codelineno-0-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;25Fa-Microclimate-ML &lt;/span&gt;&lt;span id=&#34;__span-0-4&#34;&gt;&lt;a id=&#34;__codelineno-0-4&#34; name=&#34;__codelineno-0-4&#34; href=&#34;#__codelineno-0-4&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-5&#34;&gt;&lt;a id=&#34;__codelineno-0-5&#34; name=&#34;__codelineno-0-5&#34; href=&#34;#__codelineno-0-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Install UV&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-6&#34;&gt;&lt;a id=&#34;__codelineno-0-6&#34; name=&#34;__codelineno-0-6&#34; href=&#34;#__codelineno-0-6&#34;&gt;&lt;/a&gt;curl&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-LsSf&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;https://astral.sh/uv/install.sh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;sh &lt;/span&gt;&lt;span id=&#34;__span-0-7&#34;&gt;&lt;a id=&#34;__codelineno-0-7&#34; name=&#34;__codelineno-0-7&#34; href=&#34;#__codelineno-0-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/.local/bin:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-8&#34;&gt;&lt;a id=&#34;__codelineno-0-8&#34; name=&#34;__codelineno-0-8&#34; href=&#34;#__codelineno-0-8&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-9&#34;&gt;&lt;a id=&#34;__codelineno-0-9&#34; name=&#34;__codelineno-0-9&#34; href=&#34;#__codelineno-0-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Create environment and install dependencies&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-10&#34;&gt;&lt;a id=&#34;__codelineno-0-10&#34; name=&#34;__codelineno-0-10&#34; href=&#34;#__codelineno-0-10&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;venv &lt;/span&gt;&lt;span id=&#34;__span-0-11&#34;&gt;&lt;a id=&#34;__codelineno-0-11&#34; name=&#34;__codelineno-0-11&#34; href=&#34;#__codelineno-0-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;.venv/bin/activate &lt;/span&gt;&lt;span id=&#34;__span-0-12&#34;&gt;&lt;a id=&#34;__codelineno-0-12&#34; name=&#34;__codelineno-0-12&#34; href=&#34;#__codelineno-0-12&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Option B: Using pip&lt;/strong&gt;&lt;/p&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Clone the repository (requires GitHub SSH key for private repo)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-2&#34;&gt;&lt;a id=&#34;__codelineno-1-2&#34; name=&#34;__codelineno-1-2&#34; href=&#34;#__codelineno-1-2&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;clone&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;git@github.com:VIP-SMUR/25Fa-Microclimate-ML.git &lt;/span&gt;&lt;span id=&#34;__span-1-3&#34;&gt;&lt;a id=&#34;__codelineno-1-3&#34; name=&#34;__codelineno-1-3&#34; href=&#34;#__codelineno-1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;25Fa-Microclimate-ML &lt;/span&gt;&lt;span id=&#34;__span-1-4&#34;&gt;&lt;a id=&#34;__codelineno-1-4&#34; name=&#34;__codelineno-1-4&#34; href=&#34;#__codelineno-1-4&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-5&#34;&gt;&lt;a id=&#34;__codelineno-1-5&#34; name=&#34;__codelineno-1-5&#34; href=&#34;#__codelineno-1-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Create virtual environment&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-6&#34;&gt;&lt;a id=&#34;__codelineno-1-6&#34; name=&#34;__codelineno-1-6&#34; href=&#34;#__codelineno-1-6&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-m&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;venv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;.venv &lt;/span&gt;&lt;span id=&#34;__span-1-7&#34;&gt;&lt;a id=&#34;__codelineno-1-7&#34; name=&#34;__codelineno-1-7&#34; href=&#34;#__codelineno-1-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;.venv/bin/activate&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# On Windows: .venv\Scripts\activate&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-8&#34;&gt;&lt;a id=&#34;__codelineno-1-8&#34; name=&#34;__codelineno-1-8&#34; href=&#34;#__codelineno-1-8&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-9&#34;&gt;&lt;a id=&#34;__codelineno-1-9&#34; name=&#34;__codelineno-1-9&#34; href=&#34;#__codelineno-1-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Install dependencies&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-1-10&#34;&gt;&lt;a id=&#34;__codelineno-1-10&#34; name=&#34;__codelineno-1-10&#34; href=&#34;#__codelineno-1-10&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h4 id=&#34;step-2-download-required-data&#34;&gt;Step 2: Download Required Data&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;A. Weather Data (Required for Training)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Download the 16-station weather data with solar angles:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/datasets/yupengtang/gatech_10_min_long_format_sun_angles&#34;&gt;Download from Hugging Face&lt;/a&gt;&lt;/strong&gt; (~112 MB)&lt;/p&gt; &lt;p&gt;Place in: &lt;code&gt;2_Data/gatech_16_stations_10_min_long_format_sun_angles.csv&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;B. Pre-trained Model (Required for Inference)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Download the trained model weights from Hugging Face:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/yupengtang/TFT_weather_model/resolve/main/TFT_weather_model.pth&#34;&gt;Download Model (TFT_weather_model.pth)&lt;/a&gt;&lt;/strong&gt; (1.4 MB)&lt;/p&gt; &lt;p&gt;Or visit: https://huggingface.co/yupengtang/TFT_weather_model&lt;/p&gt; &lt;p&gt;Place in: &lt;code&gt;3_Training_Model/weights/&lt;/code&gt; or &lt;code&gt;3_Training_Model/weights_4heads/&lt;/code&gt;&lt;/p&gt; &lt;h4 id=&#34;step-3-run-inference&#34;&gt;Step 3: Run Inference&lt;/h4&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-2-2&#34;&gt;&lt;a id=&#34;__codelineno-2-2&#34; name=&#34;__codelineno-2-2&#34; href=&#34;#__codelineno-2-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-3&#34;&gt;&lt;a id=&#34;__codelineno-2-3&#34; name=&#34;__codelineno-2-3&#34; href=&#34;#__codelineno-2-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Run inference&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-4&#34;&gt;&lt;a id=&#34;__codelineno-2-4&#34; name=&#34;__codelineno-2-4&#34; href=&#34;#__codelineno-2-4&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_fusionlstm_inference_kriging.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--target_time&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2017-06-25 14:00:00&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-5&#34;&gt;&lt;a id=&#34;__codelineno-2-5&#34; name=&#34;__codelineno-2-5&#34; href=&#34;#__codelineno-2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → Generates: outputs/FusionLSTM_kriging_predictions_20170625_140000.csv&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-6&#34;&gt;&lt;a id=&#34;__codelineno-2-6&#34; name=&#34;__codelineno-2-6&#34; href=&#34;#__codelineno-2-6&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-7&#34;&gt;&lt;a id=&#34;__codelineno-2-7&#34; name=&#34;__codelineno-2-7&#34; href=&#34;#__codelineno-2-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Create visualization maps&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-8&#34;&gt;&lt;a id=&#34;__codelineno-2-8&#34; name=&#34;__codelineno-2-8&#34; href=&#34;#__codelineno-2-8&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_mapping_visualization.py &lt;/span&gt;&lt;span id=&#34;__span-2-9&#34;&gt;&lt;a id=&#34;__codelineno-2-9&#34; name=&#34;__codelineno-2-9&#34; href=&#34;#__codelineno-2-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → Generates: figures/temperature_map_*.png, humidity_map_*.png, comparison_map_*.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-10&#34;&gt;&lt;a id=&#34;__codelineno-2-10&#34; name=&#34;__codelineno-2-10&#34; href=&#34;#__codelineno-2-10&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-11&#34;&gt;&lt;a id=&#34;__codelineno-2-11&#34; name=&#34;__codelineno-2-11&#34; href=&#34;#__codelineno-2-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Analyze LULC feature importance (optional)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-12&#34;&gt;&lt;a id=&#34;__codelineno-2-12&#34; name=&#34;__codelineno-2-12&#34; href=&#34;#__codelineno-2-12&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_3_lulc_analysis.py &lt;/span&gt;&lt;span id=&#34;__span-2-13&#34;&gt;&lt;a id=&#34;__codelineno-2-13&#34; name=&#34;__codelineno-2-13&#34; href=&#34;#__codelineno-2-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → Generates: figures/FusionLSTM_kriging_predictions_*_lulc_importance.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-14&#34;&gt;&lt;a id=&#34;__codelineno-2-14&#34; name=&#34;__codelineno-2-14&#34; href=&#34;#__codelineno-2-14&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-15&#34;&gt;&lt;a id=&#34;__codelineno-2-15&#34; name=&#34;__codelineno-2-15&#34; href=&#34;#__codelineno-2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Generate extreme scenario maps (automatic scenario detection)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-16&#34;&gt;&lt;a id=&#34;__codelineno-2-16&#34; name=&#34;__codelineno-2-16&#34; href=&#34;#__codelineno-2-16&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_4_generate_representative_scenarios.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dpi&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-17&#34;&gt;&lt;a id=&#34;__codelineno-2-17&#34; name=&#34;__codelineno-2-17&#34; href=&#34;#__codelineno-2-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → Generates: figures/HOTTEST_*.png, COLDEST_*.png, DRIEST_*.png, MOST_HUMID_*.png&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;on-phoenix-hpc-recommended-for-large-scale&#34;&gt;On Phoenix HPC (Recommended for Large-Scale)&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;New to HPC?&lt;/strong&gt; See &lt;a href=&#34;PACE_PHOENIX_TUTORIAL.md&#34;&gt;PACE_PHOENIX_TUTORIAL.md&lt;/a&gt; for complete beginner&#39;s guide including VPN setup and SSH connection.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This is a private repository. &lt;a href=&#34;#github-ssh-key-setup-for-private-repo&#34;&gt;Configure GitHub SSH key&lt;/a&gt; first if you haven&#39;t already.&lt;/p&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Connect to Phoenix&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-2&#34;&gt;&lt;a id=&#34;__codelineno-3-2&#34; name=&#34;__codelineno-3-2&#34; href=&#34;#__codelineno-3-2&#34;&gt;&lt;/a&gt;ssh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&amp;lt;your_gt_username&amp;gt;@login-phoenix.pace.gatech.edu &lt;/span&gt;&lt;span id=&#34;__span-3-3&#34;&gt;&lt;a id=&#34;__codelineno-3-3&#34; name=&#34;__codelineno-3-3&#34; href=&#34;#__codelineno-3-3&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-4&#34;&gt;&lt;a id=&#34;__codelineno-3-4&#34; name=&#34;__codelineno-3-4&#34; href=&#34;#__codelineno-3-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Navigate to your home directory (recommended for code)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-5&#34;&gt;&lt;a id=&#34;__codelineno-3-5&#34; name=&#34;__codelineno-3-5&#34; href=&#34;#__codelineno-3-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-6&#34;&gt;&lt;a id=&#34;__codelineno-3-6&#34; name=&#34;__codelineno-3-6&#34; href=&#34;#__codelineno-3-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Alternative: Use scratch for large temporary files&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-7&#34;&gt;&lt;a id=&#34;__codelineno-3-7&#34; name=&#34;__codelineno-3-7&#34; href=&#34;#__codelineno-3-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# cd /storage/scratch1/&amp;lt;your_gt_username&amp;gt;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-8&#34;&gt;&lt;a id=&#34;__codelineno-3-8&#34; name=&#34;__codelineno-3-8&#34; href=&#34;#__codelineno-3-8&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-9&#34;&gt;&lt;a id=&#34;__codelineno-3-9&#34; name=&#34;__codelineno-3-9&#34; href=&#34;#__codelineno-3-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Clone repository (requires GitHub access)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-10&#34;&gt;&lt;a id=&#34;__codelineno-3-10&#34; name=&#34;__codelineno-3-10&#34; href=&#34;#__codelineno-3-10&#34;&gt;&lt;/a&gt;git&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;clone&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;git@github.com:VIP-SMUR/25Fa-Microclimate-ML.git &lt;/span&gt;&lt;span id=&#34;__span-3-11&#34;&gt;&lt;a id=&#34;__codelineno-3-11&#34; name=&#34;__codelineno-3-11&#34; href=&#34;#__codelineno-3-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;25Fa-Microclimate-ML &lt;/span&gt;&lt;span id=&#34;__span-3-12&#34;&gt;&lt;a id=&#34;__codelineno-3-12&#34; name=&#34;__codelineno-3-12&#34; href=&#34;#__codelineno-3-12&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-13&#34;&gt;&lt;a id=&#34;__codelineno-3-13&#34; name=&#34;__codelineno-3-13&#34; href=&#34;#__codelineno-3-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# ===== TRAINING =====&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-14&#34;&gt;&lt;a id=&#34;__codelineno-3-14&#34; name=&#34;__codelineno-3-14&#34; href=&#34;#__codelineno-3-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;3_Training_Model &lt;/span&gt;&lt;span id=&#34;__span-3-15&#34;&gt;&lt;a id=&#34;__codelineno-3-15&#34; name=&#34;__codelineno-3-15&#34; href=&#34;#__codelineno-3-15&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;phoenix_gpu_train.sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# GPU: A100, 4 attention heads, ~2-4 hours&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-16&#34;&gt;&lt;a id=&#34;__codelineno-3-16&#34; name=&#34;__codelineno-3-16&#34; href=&#34;#__codelineno-3-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# OR&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-17&#34;&gt;&lt;a id=&#34;__codelineno-3-17&#34; name=&#34;__codelineno-3-17&#34; href=&#34;#__codelineno-3-17&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;phoenix_cpu_train.sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# CPU: 8 cores, 2 attention heads, ~24-48 hours&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-18&#34;&gt;&lt;a id=&#34;__codelineno-3-18&#34; name=&#34;__codelineno-3-18&#34; href=&#34;#__codelineno-3-18&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-19&#34;&gt;&lt;a id=&#34;__codelineno-3-19&#34; name=&#34;__codelineno-3-19&#34; href=&#34;#__codelineno-3-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# ===== INFERENCE &amp;amp; VISUALIZATION =====&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-20&#34;&gt;&lt;a id=&#34;__codelineno-3-20&#34; name=&#34;__codelineno-3-20&#34; href=&#34;#__codelineno-3-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-3-21&#34;&gt;&lt;a id=&#34;__codelineno-3-21&#34; name=&#34;__codelineno-3-21&#34; href=&#34;#__codelineno-3-21&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-22&#34;&gt;&lt;a id=&#34;__codelineno-3-22&#34; name=&#34;__codelineno-3-22&#34; href=&#34;#__codelineno-3-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 1: Inference (~2 min 10 sec)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-23&#34;&gt;&lt;a id=&#34;__codelineno-3-23&#34; name=&#34;__codelineno-3-23&#34; href=&#34;#__codelineno-3-23&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_inference.sbatch &lt;/span&gt;&lt;span id=&#34;__span-3-24&#34;&gt;&lt;a id=&#34;__codelineno-3-24&#34; name=&#34;__codelineno-3-24&#34; href=&#34;#__codelineno-3-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → outputs/FusionLSTM_kriging_predictions_*.csv (31 MB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-25&#34;&gt;&lt;a id=&#34;__codelineno-3-25&#34; name=&#34;__codelineno-3-25&#34; href=&#34;#__codelineno-3-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → outputs/FusionLSTM_kriging_predictions_*_models.pkl (169 KB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-26&#34;&gt;&lt;a id=&#34;__codelineno-3-26&#34; name=&#34;__codelineno-3-26&#34; href=&#34;#__codelineno-3-26&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-27&#34;&gt;&lt;a id=&#34;__codelineno-3-27&#34; name=&#34;__codelineno-3-27&#34; href=&#34;#__codelineno-3-27&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 2: Visualization (~1 min 31 sec)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-28&#34;&gt;&lt;a id=&#34;__codelineno-3-28&#34; name=&#34;__codelineno-3-28&#34; href=&#34;#__codelineno-3-28&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_visualization.sbatch &lt;/span&gt;&lt;span id=&#34;__span-3-29&#34;&gt;&lt;a id=&#34;__codelineno-3-29&#34; name=&#34;__codelineno-3-29&#34; href=&#34;#__codelineno-3-29&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → figures/temperature_map_*.png (1.7 MB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-30&#34;&gt;&lt;a id=&#34;__codelineno-3-30&#34; name=&#34;__codelineno-3-30&#34; href=&#34;#__codelineno-3-30&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → figures/humidity_map_*.png (1.6 MB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-31&#34;&gt;&lt;a id=&#34;__codelineno-3-31&#34; name=&#34;__codelineno-3-31&#34; href=&#34;#__codelineno-3-31&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → figures/comparison_map_*.png (2.1 MB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-32&#34;&gt;&lt;a id=&#34;__codelineno-3-32&#34; name=&#34;__codelineno-3-32&#34; href=&#34;#__codelineno-3-32&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-33&#34;&gt;&lt;a id=&#34;__codelineno-3-33&#34; name=&#34;__codelineno-3-33&#34; href=&#34;#__codelineno-3-33&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 3: LULC Analysis (~34 sec, optional)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-34&#34;&gt;&lt;a id=&#34;__codelineno-3-34&#34; name=&#34;__codelineno-3-34&#34; href=&#34;#__codelineno-3-34&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_3_lulc.sbatch &lt;/span&gt;&lt;span id=&#34;__span-3-35&#34;&gt;&lt;a id=&#34;__codelineno-3-35&#34; name=&#34;__codelineno-3-35&#34; href=&#34;#__codelineno-3-35&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → figures/FusionLSTM_kriging_predictions_*_lulc_importance.png (237 KB)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-36&#34;&gt;&lt;a id=&#34;__codelineno-3-36&#34; name=&#34;__codelineno-3-36&#34; href=&#34;#__codelineno-3-36&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-37&#34;&gt;&lt;a id=&#34;__codelineno-3-37&#34; name=&#34;__codelineno-3-37&#34; href=&#34;#__codelineno-3-37&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 4: Generate representative scenario maps (~3 min, recommended for publication)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-38&#34;&gt;&lt;a id=&#34;__codelineno-3-38&#34; name=&#34;__codelineno-3-38&#34; href=&#34;#__codelineno-3-38&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_4_representative_scenarios.sbatch &lt;/span&gt;&lt;span id=&#34;__span-3-39&#34;&gt;&lt;a id=&#34;__codelineno-3-39&#34; name=&#34;__codelineno-3-39&#34; href=&#34;#__codelineno-3-39&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# → figures/HOTTEST_*.png, COLDEST_*.png, DRIEST_*.png, MOST_HUMID_*.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-40&#34;&gt;&lt;a id=&#34;__codelineno-3-40&#34; name=&#34;__codelineno-3-40&#34; href=&#34;#__codelineno-3-40&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-41&#34;&gt;&lt;a id=&#34;__codelineno-3-41&#34; name=&#34;__codelineno-3-41&#34; href=&#34;#__codelineno-3-41&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Monitor jobs&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-42&#34;&gt;&lt;a id=&#34;__codelineno-3-42&#34; name=&#34;__codelineno-3-42&#34; href=&#34;#__codelineno-3-42&#34;&gt;&lt;/a&gt;squeue&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-u&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-3-43&#34;&gt;&lt;a id=&#34;__codelineno-3-43&#34; name=&#34;__codelineno-3-43&#34; href=&#34;#__codelineno-3-43&#34;&gt;&lt;/a&gt;tail&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-f&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;logs/inference_*.out &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;complete-workflow&#34;&gt;Complete Workflow&lt;/h2&gt; &lt;h3 id=&#34;option-a-use-pre-trained-model-recommended&#34;&gt;Option A: Use Pre-trained Model (Recommended)&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-4-2&#34;&gt;&lt;a id=&#34;__codelineno-4-2&#34; name=&#34;__codelineno-4-2&#34; href=&#34;#__codelineno-4-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-3&#34;&gt;&lt;a id=&#34;__codelineno-4-3&#34; name=&#34;__codelineno-4-3&#34; href=&#34;#__codelineno-4-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 1. Run inference with trained model&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-4&#34;&gt;&lt;a id=&#34;__codelineno-4-4&#34; name=&#34;__codelineno-4-4&#34; href=&#34;#__codelineno-4-4&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_fusionlstm_inference_kriging.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--target_time&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2017-06-25 14:00:00&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-5&#34;&gt;&lt;a id=&#34;__codelineno-4-5&#34; name=&#34;__codelineno-4-5&#34; href=&#34;#__codelineno-4-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Output: outputs/FusionLSTM_kriging_predictions_20170625_140000.csv (100,283 points)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-6&#34;&gt;&lt;a id=&#34;__codelineno-4-6&#34; name=&#34;__codelineno-4-6&#34; href=&#34;#__codelineno-4-6&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-7&#34;&gt;&lt;a id=&#34;__codelineno-4-7&#34; name=&#34;__codelineno-4-7&#34; href=&#34;#__codelineno-4-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 2. Create high-resolution visualization maps&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-8&#34;&gt;&lt;a id=&#34;__codelineno-4-8&#34; name=&#34;__codelineno-4-8&#34; href=&#34;#__codelineno-4-8&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_mapping_visualization.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dpi&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-9&#34;&gt;&lt;a id=&#34;__codelineno-4-9&#34; name=&#34;__codelineno-4-9&#34; href=&#34;#__codelineno-4-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Output: &lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-10&#34;&gt;&lt;a id=&#34;__codelineno-4-10&#34; name=&#34;__codelineno-4-10&#34; href=&#34;#__codelineno-4-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# - figures/temperature_map_20170625_140000.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-11&#34;&gt;&lt;a id=&#34;__codelineno-4-11&#34; name=&#34;__codelineno-4-11&#34; href=&#34;#__codelineno-4-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# - figures/humidity_map_20170625_140000.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-12&#34;&gt;&lt;a id=&#34;__codelineno-4-12&#34; name=&#34;__codelineno-4-12&#34; href=&#34;#__codelineno-4-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# - figures/comparison_map_20170625_140000.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-13&#34;&gt;&lt;a id=&#34;__codelineno-4-13&#34; name=&#34;__codelineno-4-13&#34; href=&#34;#__codelineno-4-13&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-14&#34;&gt;&lt;a id=&#34;__codelineno-4-14&#34; name=&#34;__codelineno-4-14&#34; href=&#34;#__codelineno-4-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 3. Analyze spatial feature importance (optional)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-15&#34;&gt;&lt;a id=&#34;__codelineno-4-15&#34; name=&#34;__codelineno-4-15&#34; href=&#34;#__codelineno-4-15&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_3_lulc_analysis.py &lt;/span&gt;&lt;span id=&#34;__span-4-16&#34;&gt;&lt;a id=&#34;__codelineno-4-16&#34; name=&#34;__codelineno-4-16&#34; href=&#34;#__codelineno-4-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Output: figures/FusionLSTM_kriging_predictions_20170625_140000_lulc_importance.png&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-17&#34;&gt;&lt;a id=&#34;__codelineno-4-17&#34; name=&#34;__codelineno-4-17&#34; href=&#34;#__codelineno-4-17&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-18&#34;&gt;&lt;a id=&#34;__codelineno-4-18&#34; name=&#34;__codelineno-4-18&#34; href=&#34;#__codelineno-4-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 4. Generate extreme scenario maps (automatic scenario detection)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-19&#34;&gt;&lt;a id=&#34;__codelineno-4-19&#34; name=&#34;__codelineno-4-19&#34; href=&#34;#__codelineno-4-19&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_4_generate_representative_scenarios.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dpi&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-20&#34;&gt;&lt;a id=&#34;__codelineno-4-20&#34; name=&#34;__codelineno-4-20&#34; href=&#34;#__codelineno-4-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Output: figures/HOTTEST_*.png, COLDEST_*.png, DRIEST_*.png, MOST_HUMID_*.png&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;option-b-train-your-own-model&#34;&gt;Option B: Train Your Own Model&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 1: Train the model&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-2&#34;&gt;&lt;a id=&#34;__codelineno-5-2&#34; name=&#34;__codelineno-5-2&#34; href=&#34;#__codelineno-5-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;3_Training_Model &lt;/span&gt;&lt;span id=&#34;__span-5-3&#34;&gt;&lt;a id=&#34;__codelineno-5-3&#34; name=&#34;__codelineno-5-3&#34; href=&#34;#__codelineno-5-3&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-4&#34;&gt;&lt;a id=&#34;__codelineno-5-4&#34; name=&#34;__codelineno-5-4&#34; href=&#34;#__codelineno-5-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# GPU training (recommended)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-5&#34;&gt;&lt;a id=&#34;__codelineno-5-5&#34; name=&#34;__codelineno-5-5&#34; href=&#34;#__codelineno-5-5&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_5_main.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-6&#34;&gt;&lt;a id=&#34;__codelineno-5-6&#34; name=&#34;__codelineno-5-6&#34; href=&#34;#__codelineno-5-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--data_path&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../2_Data/gatech_16_stations_10_min_long_format_sun_angles.csv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-7&#34;&gt;&lt;a id=&#34;__codelineno-5-7&#34; name=&#34;__codelineno-5-7&#34; href=&#34;#__codelineno-5-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-8&#34;&gt;&lt;a id=&#34;__codelineno-5-8&#34; name=&#34;__codelineno-5-8&#34; href=&#34;#__codelineno-5-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--attention_heads&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-9&#34;&gt;&lt;a id=&#34;__codelineno-5-9&#34; name=&#34;__codelineno-5-9&#34; href=&#34;#__codelineno-5-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--save_dir&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;./weights_4heads &lt;/span&gt;&lt;span id=&#34;__span-5-10&#34;&gt;&lt;a id=&#34;__codelineno-5-10&#34; name=&#34;__codelineno-5-10&#34; href=&#34;#__codelineno-5-10&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-11&#34;&gt;&lt;a id=&#34;__codelineno-5-11&#34; name=&#34;__codelineno-5-11&#34; href=&#34;#__codelineno-5-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# OR CPU training&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-12&#34;&gt;&lt;a id=&#34;__codelineno-5-12&#34; name=&#34;__codelineno-5-12&#34; href=&#34;#__codelineno-5-12&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_5_main.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-13&#34;&gt;&lt;a id=&#34;__codelineno-5-13&#34; name=&#34;__codelineno-5-13&#34; href=&#34;#__codelineno-5-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--data_path&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../2_Data/gatech_16_stations_10_min_long_format_sun_angles.csv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-14&#34;&gt;&lt;a id=&#34;__codelineno-5-14&#34; name=&#34;__codelineno-5-14&#34; href=&#34;#__codelineno-5-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cpu&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-15&#34;&gt;&lt;a id=&#34;__codelineno-5-15&#34; name=&#34;__codelineno-5-15&#34; href=&#34;#__codelineno-5-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--attention_heads&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-16&#34;&gt;&lt;a id=&#34;__codelineno-5-16&#34; name=&#34;__codelineno-5-16&#34; href=&#34;#__codelineno-5-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--save_dir&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;./weights &lt;/span&gt;&lt;span id=&#34;__span-5-17&#34;&gt;&lt;a id=&#34;__codelineno-5-17&#34; name=&#34;__codelineno-5-17&#34; href=&#34;#__codelineno-5-17&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-18&#34;&gt;&lt;a id=&#34;__codelineno-5-18&#34; name=&#34;__codelineno-5-18&#34; href=&#34;#__codelineno-5-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 2: Run inference with your model&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-19&#34;&gt;&lt;a id=&#34;__codelineno-5-19&#34; name=&#34;__codelineno-5-19&#34; href=&#34;#__codelineno-5-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-5-20&#34;&gt;&lt;a id=&#34;__codelineno-5-20&#34; name=&#34;__codelineno-5-20&#34; href=&#34;#__codelineno-5-20&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_fusionlstm_inference_kriging.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-21&#34;&gt;&lt;a id=&#34;__codelineno-5-21&#34; name=&#34;__codelineno-5-21&#34; href=&#34;#__codelineno-5-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--model_path&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../3_Training_Model/weights_4heads/TFT_weather_model.pth&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-22&#34;&gt;&lt;a id=&#34;__codelineno-5-22&#34; name=&#34;__codelineno-5-22&#34; href=&#34;#__codelineno-5-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--target_time&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2017-06-25 14:00:00&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-23&#34;&gt;&lt;a id=&#34;__codelineno-5-23&#34; name=&#34;__codelineno-5-23&#34; href=&#34;#__codelineno-5-23&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-24&#34;&gt;&lt;a id=&#34;__codelineno-5-24&#34; name=&#34;__codelineno-5-24&#34; href=&#34;#__codelineno-5-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Step 3: Create visualizations&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-5-25&#34;&gt;&lt;a id=&#34;__codelineno-5-25&#34; name=&#34;__codelineno-5-25&#34; href=&#34;#__codelineno-5-25&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_mapping_visualization.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;project-structure&#34;&gt;Project Structure&lt;/h2&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;25Fa-Microclimate-ML/ &lt;/span&gt;&lt;span id=&#34;__span-6-2&#34;&gt;&lt;a id=&#34;__codelineno-6-2&#34; name=&#34;__codelineno-6-2&#34; href=&#34;#__codelineno-6-2&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-3&#34;&gt;&lt;a id=&#34;__codelineno-6-3&#34; name=&#34;__codelineno-6-3&#34; href=&#34;#__codelineno-6-3&#34;&gt;&lt;/a&gt;├── 1_Urban_Features/ # Geospatial feature extraction &lt;/span&gt;&lt;span id=&#34;__span-6-4&#34;&gt;&lt;a id=&#34;__codelineno-6-4&#34; name=&#34;__codelineno-6-4&#34; href=&#34;#__codelineno-6-4&#34;&gt;&lt;/a&gt;│ ├── grid_generator.py # Generate prediction grid &lt;/span&gt;&lt;span id=&#34;__span-6-5&#34;&gt;&lt;a id=&#34;__codelineno-6-5&#34; name=&#34;__codelineno-6-5&#34; href=&#34;#__codelineno-6-5&#34;&gt;&lt;/a&gt;│ ├── get_osm_utils.py # OpenStreetMap data processing &lt;/span&gt;&lt;span id=&#34;__span-6-6&#34;&gt;&lt;a id=&#34;__codelineno-6-6&#34; name=&#34;__codelineno-6-6&#34; href=&#34;#__codelineno-6-6&#34;&gt;&lt;/a&gt;│ └── ... &lt;/span&gt;&lt;span id=&#34;__span-6-7&#34;&gt;&lt;a id=&#34;__codelineno-6-7&#34; name=&#34;__codelineno-6-7&#34; href=&#34;#__codelineno-6-7&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-8&#34;&gt;&lt;a id=&#34;__codelineno-6-8&#34; name=&#34;__codelineno-6-8&#34; href=&#34;#__codelineno-6-8&#34;&gt;&lt;/a&gt;├── 2_Data/ # Weather data and features &lt;/span&gt;&lt;span id=&#34;__span-6-9&#34;&gt;&lt;a id=&#34;__codelineno-6-9&#34; name=&#34;__codelineno-6-9&#34; href=&#34;#__codelineno-6-9&#34;&gt;&lt;/a&gt;│ ├── gatech_16_stations_10_min_long_format_sun_angles.csv # Main dataset (~947K rows, 16 stations) &lt;/span&gt;&lt;span id=&#34;__span-6-10&#34;&gt;&lt;a id=&#34;__codelineno-6-10&#34; name=&#34;__codelineno-6-10&#34; href=&#34;#__codelineno-6-10&#34;&gt;&lt;/a&gt;│ ├── gatech_gridpoint.csv # Grid data (100,283 points) &lt;/span&gt;&lt;span id=&#34;__span-6-11&#34;&gt;&lt;a id=&#34;__codelineno-6-11&#34; name=&#34;__codelineno-6-11&#34; href=&#34;#__codelineno-6-11&#34;&gt;&lt;/a&gt;│ └── ... &lt;/span&gt;&lt;span id=&#34;__span-6-12&#34;&gt;&lt;a id=&#34;__codelineno-6-12&#34; name=&#34;__codelineno-6-12&#34; href=&#34;#__codelineno-6-12&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-13&#34;&gt;&lt;a id=&#34;__codelineno-6-13&#34; name=&#34;__codelineno-6-13&#34; href=&#34;#__codelineno-6-13&#34;&gt;&lt;/a&gt;├── 3_Training_Model/ # Model training pipeline &lt;/span&gt;&lt;span id=&#34;__span-6-14&#34;&gt;&lt;a id=&#34;__codelineno-6-14&#34; name=&#34;__codelineno-6-14&#34; href=&#34;#__codelineno-6-14&#34;&gt;&lt;/a&gt;│ ├── _1_model_architecture.py # Single-step TFT implementation &lt;/span&gt;&lt;span id=&#34;__span-6-15&#34;&gt;&lt;a id=&#34;__codelineno-6-15&#34; name=&#34;__codelineno-6-15&#34; href=&#34;#__codelineno-6-15&#34;&gt;&lt;/a&gt;│ ├── _2_data_preprocessing.py # Data cleaning &amp;amp; sequences &lt;/span&gt;&lt;span id=&#34;__span-6-16&#34;&gt;&lt;a id=&#34;__codelineno-6-16&#34; name=&#34;__codelineno-6-16&#34; href=&#34;#__codelineno-6-16&#34;&gt;&lt;/a&gt;│ ├── _3_model_training.py # Training pipeline &lt;/span&gt;&lt;span id=&#34;__span-6-17&#34;&gt;&lt;a id=&#34;__codelineno-6-17&#34; name=&#34;__codelineno-6-17&#34; href=&#34;#__codelineno-6-17&#34;&gt;&lt;/a&gt;│ ├── _4_model_evaluation.py # Metrics &amp;amp; visualization &lt;/span&gt;&lt;span id=&#34;__span-6-18&#34;&gt;&lt;a id=&#34;__codelineno-6-18&#34; name=&#34;__codelineno-6-18&#34; href=&#34;#__codelineno-6-18&#34;&gt;&lt;/a&gt;│ ├── _5_main.py # Main training script (CLI) &lt;/span&gt;&lt;span id=&#34;__span-6-19&#34;&gt;&lt;a id=&#34;__codelineno-6-19&#34; name=&#34;__codelineno-6-19&#34; href=&#34;#__codelineno-6-19&#34;&gt;&lt;/a&gt;│ ├── _6_example_usage.py # Usage examples &lt;/span&gt;&lt;span id=&#34;__span-6-20&#34;&gt;&lt;a id=&#34;__codelineno-6-20&#34; name=&#34;__codelineno-6-20&#34; href=&#34;#__codelineno-6-20&#34;&gt;&lt;/a&gt;│ ├── phoenix_gpu_train.sbatch # SLURM: GPU training (A100) &lt;/span&gt;&lt;span id=&#34;__span-6-21&#34;&gt;&lt;a id=&#34;__codelineno-6-21&#34; name=&#34;__codelineno-6-21&#34; href=&#34;#__codelineno-6-21&#34;&gt;&lt;/a&gt;│ ├── phoenix_cpu_train.sbatch # SLURM: CPU training &lt;/span&gt;&lt;span id=&#34;__span-6-22&#34;&gt;&lt;a id=&#34;__codelineno-6-22&#34; name=&#34;__codelineno-6-22&#34; href=&#34;#__codelineno-6-22&#34;&gt;&lt;/a&gt;│ ├── weights/ # CPU trained models &lt;/span&gt;&lt;span id=&#34;__span-6-23&#34;&gt;&lt;a id=&#34;__codelineno-6-23&#34; name=&#34;__codelineno-6-23&#34; href=&#34;#__codelineno-6-23&#34;&gt;&lt;/a&gt;│ ├── weights_4heads/ # GPU trained models &lt;/span&gt;&lt;span id=&#34;__span-6-24&#34;&gt;&lt;a id=&#34;__codelineno-6-24&#34; name=&#34;__codelineno-6-24&#34; href=&#34;#__codelineno-6-24&#34;&gt;&lt;/a&gt;│ ├── training_plots/ # Loss curves, LR schedule &lt;/span&gt;&lt;span id=&#34;__span-6-25&#34;&gt;&lt;a id=&#34;__codelineno-6-25&#34; name=&#34;__codelineno-6-25&#34; href=&#34;#__codelineno-6-25&#34;&gt;&lt;/a&gt;│ ├── evaluation_plots/ # Predictions, residuals &lt;/span&gt;&lt;span id=&#34;__span-6-26&#34;&gt;&lt;a id=&#34;__codelineno-6-26&#34; name=&#34;__codelineno-6-26&#34; href=&#34;#__codelineno-6-26&#34;&gt;&lt;/a&gt;│ ├── logs/ # SLURM job logs &lt;/span&gt;&lt;span id=&#34;__span-6-27&#34;&gt;&lt;a id=&#34;__codelineno-6-27&#34; name=&#34;__codelineno-6-27&#34; href=&#34;#__codelineno-6-27&#34;&gt;&lt;/a&gt;│ └── README.md # Training documentation &lt;/span&gt;&lt;span id=&#34;__span-6-28&#34;&gt;&lt;a id=&#34;__codelineno-6-28&#34; name=&#34;__codelineno-6-28&#34; href=&#34;#__codelineno-6-28&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-29&#34;&gt;&lt;a id=&#34;__codelineno-6-29&#34; name=&#34;__codelineno-6-29&#34; href=&#34;#__codelineno-6-29&#34;&gt;&lt;/a&gt;├── 4_Inference_and_Visualization/ # Inference &amp;amp; visualization &lt;/span&gt;&lt;span id=&#34;__span-6-30&#34;&gt;&lt;a id=&#34;__codelineno-6-30&#34; name=&#34;__codelineno-6-30&#34; href=&#34;#__codelineno-6-30&#34;&gt;&lt;/a&gt;│ ├── _1_fusionlstm_inference_kriging.py # FusionLSTM inference + Kriging &lt;/span&gt;&lt;span id=&#34;__span-6-31&#34;&gt;&lt;a id=&#34;__codelineno-6-31&#34; name=&#34;__codelineno-6-31&#34; href=&#34;#__codelineno-6-31&#34;&gt;&lt;/a&gt;│ ├── _2_mapping_visualization.py # Create spatial maps &lt;/span&gt;&lt;span id=&#34;__span-6-32&#34;&gt;&lt;a id=&#34;__codelineno-6-32&#34; name=&#34;__codelineno-6-32&#34; href=&#34;#__codelineno-6-32&#34;&gt;&lt;/a&gt;│ ├── _3_lulc_analysis.py # LULC feature importance &lt;/span&gt;&lt;span id=&#34;__span-6-33&#34;&gt;&lt;a id=&#34;__codelineno-6-33&#34; name=&#34;__codelineno-6-33&#34; href=&#34;#__codelineno-6-33&#34;&gt;&lt;/a&gt;│ ├── _4_generate_representative_scenarios.py # Auto-generate extreme scenarios &lt;/span&gt;&lt;span id=&#34;__span-6-34&#34;&gt;&lt;a id=&#34;__codelineno-6-34&#34; name=&#34;__codelineno-6-34&#34; href=&#34;#__codelineno-6-34&#34;&gt;&lt;/a&gt;│ ├── _1_inference.sbatch # SLURM: Inference (A100 GPU) &lt;/span&gt;&lt;span id=&#34;__span-6-35&#34;&gt;&lt;a id=&#34;__codelineno-6-35&#34; name=&#34;__codelineno-6-35&#34; href=&#34;#__codelineno-6-35&#34;&gt;&lt;/a&gt;│ ├── _2_visualization.sbatch # SLURM: Visualization (CPU) &lt;/span&gt;&lt;span id=&#34;__span-6-36&#34;&gt;&lt;a id=&#34;__codelineno-6-36&#34; name=&#34;__codelineno-6-36&#34; href=&#34;#__codelineno-6-36&#34;&gt;&lt;/a&gt;│ ├── _3_lulc.sbatch # SLURM: LULC analysis (CPU) &lt;/span&gt;&lt;span id=&#34;__span-6-37&#34;&gt;&lt;a id=&#34;__codelineno-6-37&#34; name=&#34;__codelineno-6-37&#34; href=&#34;#__codelineno-6-37&#34;&gt;&lt;/a&gt;│ ├── _4_representative_scenarios.sbatch # SLURM: Generate all scenarios (GPU) &lt;/span&gt;&lt;span id=&#34;__span-6-38&#34;&gt;&lt;a id=&#34;__codelineno-6-38&#34; name=&#34;__codelineno-6-38&#34; href=&#34;#__codelineno-6-38&#34;&gt;&lt;/a&gt;│ ├── outputs/ # Prediction CSV + PKL files &lt;/span&gt;&lt;span id=&#34;__span-6-39&#34;&gt;&lt;a id=&#34;__codelineno-6-39&#34; name=&#34;__codelineno-6-39&#34; href=&#34;#__codelineno-6-39&#34;&gt;&lt;/a&gt;│ ├── figures/ # Generated maps (PNG) &lt;/span&gt;&lt;span id=&#34;__span-6-40&#34;&gt;&lt;a id=&#34;__codelineno-6-40&#34; name=&#34;__codelineno-6-40&#34; href=&#34;#__codelineno-6-40&#34;&gt;&lt;/a&gt;│ ├── logs/ # SLURM job logs &lt;/span&gt;&lt;span id=&#34;__span-6-41&#34;&gt;&lt;a id=&#34;__codelineno-6-41&#34; name=&#34;__codelineno-6-41&#34; href=&#34;#__codelineno-6-41&#34;&gt;&lt;/a&gt;│ └── README.md # Inference documentation &lt;/span&gt;&lt;span id=&#34;__span-6-42&#34;&gt;&lt;a id=&#34;__codelineno-6-42&#34; name=&#34;__codelineno-6-42&#34; href=&#34;#__codelineno-6-42&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-43&#34;&gt;&lt;a id=&#34;__codelineno-6-43&#34; name=&#34;__codelineno-6-43&#34; href=&#34;#__codelineno-6-43&#34;&gt;&lt;/a&gt;├── 5_Optional_Frontend/ # Interactive dashboard (optional) &lt;/span&gt;&lt;span id=&#34;__span-6-44&#34;&gt;&lt;a id=&#34;__codelineno-6-44&#34; name=&#34;__codelineno-6-44&#34; href=&#34;#__codelineno-6-44&#34;&gt;&lt;/a&gt;│ ├── streamlit_dashboard.py # Main dashboard app &lt;/span&gt;&lt;span id=&#34;__span-6-45&#34;&gt;&lt;a id=&#34;__codelineno-6-45&#34; name=&#34;__codelineno-6-45&#34; href=&#34;#__codelineno-6-45&#34;&gt;&lt;/a&gt;│ └── README.md # Dashboard documentation &lt;/span&gt;&lt;span id=&#34;__span-6-46&#34;&gt;&lt;a id=&#34;__codelineno-6-46&#34; name=&#34;__codelineno-6-46&#34; href=&#34;#__codelineno-6-46&#34;&gt;&lt;/a&gt;│ &lt;/span&gt;&lt;span id=&#34;__span-6-47&#34;&gt;&lt;a id=&#34;__codelineno-6-47&#34; name=&#34;__codelineno-6-47&#34; href=&#34;#__codelineno-6-47&#34;&gt;&lt;/a&gt;├── requirements.txt # Python dependencies &lt;/span&gt;&lt;span id=&#34;__span-6-48&#34;&gt;&lt;a id=&#34;__codelineno-6-48&#34; name=&#34;__codelineno-6-48&#34; href=&#34;#__codelineno-6-48&#34;&gt;&lt;/a&gt;└── README.md # This file &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;model-architecture&#34;&gt;Model Architecture&lt;/h2&gt; &lt;h3 id=&#34;fusionlstm-multi-scale-lstm-with-attention&#34;&gt;FusionLSTM: Multi-Scale LSTM with Attention&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Core Components&lt;/strong&gt;: - &lt;strong&gt;Variable Selection Networks&lt;/strong&gt; → Adaptive feature importance learning - &lt;strong&gt;Multi-scale LSTM&lt;/strong&gt; → Parallel short-term (1 layer) + long-term (2 layers) branches - &lt;strong&gt;Multi-head Attention&lt;/strong&gt; → Temporal dependency modeling (2 heads, optimized for efficiency) - &lt;strong&gt;Gated Residual Networks&lt;/strong&gt; → Complex feature interactions with stable gradients - &lt;strong&gt;Position Encoding&lt;/strong&gt; → Learnable temporal embeddings&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Input Features (12 dimensions)&lt;/strong&gt;: 1. &lt;strong&gt;Weather Observations&lt;/strong&gt; (2): Temperature (°C), Relative Humidity (%) 2. &lt;strong&gt;Solar Geometry&lt;/strong&gt; (4): Altitude/azimuth angles (sin/cos encoding) - Physics-aware features 3. &lt;strong&gt;Temporal Features&lt;/strong&gt; (6): - Hour of day (sin/cos, 24-hour cycle) - Day of year (sin/cos, 365-day cycle) - Minute (sin/cos, 10-minute resolution)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Output Targets (2 dimensions)&lt;/strong&gt;: - Temperature (°C) - Relative Humidity (%)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Sequence Configuration&lt;/strong&gt;: - Historical window: 144 timesteps (24 hours @ 10-minute resolution) - Prediction: Next timestep (+10 minutes) - Training: Warm season only (April–September) for focused heat stress modeling&lt;/p&gt; &lt;h3 id=&#34;spatial-interpolation-regression-kriging-with-16-stations&#34;&gt;Spatial Interpolation: Regression Kriging with 16 Stations&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Method: Regression Kriging&lt;/strong&gt; (PyKrige) - &lt;strong&gt;Station Coverage&lt;/strong&gt;: 16 stations provide robust spatial coverage and stable variogram estimation - &lt;strong&gt;Variogram&lt;/strong&gt;: Spherical model with empirical fitting (sill, range, nugget) - &lt;strong&gt;Spatial Covariates&lt;/strong&gt;: Elevation, building density/height, distances to features, shadow ratios - &lt;strong&gt;Stability&lt;/strong&gt;: 16 stations eliminate the need for IDW fallback (previously required with only 3 stations)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt;: 1. FusionLSTM generates predictions at all 16 weather station locations 2. Regression Kriging interpolates to 100,283 grid points using spatial covariates 3. Campus boundary overlay from OpenStreetMap (via OSMnx) 4. Adaptive map boundaries fitted to campus extent&lt;/p&gt; &lt;h2 id=&#34;dataset-coverage&#34;&gt;Dataset &amp;amp; Coverage&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Weather Stations&lt;/strong&gt;: 16 stations - &lt;strong&gt;Time Range&lt;/strong&gt;: 2015-2019 (warm season: April–September) - &lt;strong&gt;Resolution&lt;/strong&gt;: 10-minute intervals - &lt;strong&gt;Total Records&lt;/strong&gt;: ~947,000 warm-season observations - &lt;strong&gt;File Size&lt;/strong&gt;: ~112 MB - &lt;strong&gt;Variables&lt;/strong&gt;: Temperature, Relative Humidity, Dew Point, Solar Angles - &lt;strong&gt;Download&lt;/strong&gt;: &lt;a href=&#34;https://huggingface.co/datasets/yupengtang/gatech_10_min_long_format_sun_angles&#34;&gt;Hugging Face Dataset&lt;/a&gt; (see &lt;code&gt;2_Data/README.md&lt;/code&gt;)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Spatial Grid&lt;/strong&gt;: 100,283 points - &lt;strong&gt;Area&lt;/strong&gt;: Georgia Tech campus (~3.5 km²) - &lt;strong&gt;Average Spacing&lt;/strong&gt;: ~5.9 meters - &lt;strong&gt;Spatial Features&lt;/strong&gt;: 24 features including distances, elevation, building metrics, shadow ratios&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Station Holdout Protocol&lt;/strong&gt;: Station 10635579 (61,556 records) held out for testing; remaining 15 stations used for training/validation with 90/10 time-based split&lt;/p&gt; &lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt; &lt;h3 id=&#34;model-performance-fusionlstm-architecture&#34;&gt;Model Performance (FusionLSTM Architecture)&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Validation Model&lt;/strong&gt; (15 stations training + 1 held-out for testing):&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Variable&lt;/th&gt; &lt;th&gt;RMSE&lt;/th&gt; &lt;th&gt;MAE&lt;/th&gt; &lt;th&gt;MAPE&lt;/th&gt; &lt;th&gt;R²&lt;/th&gt; &lt;th&gt;Max Error&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Temperature&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.43°C&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.29°C&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.15%&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.9928&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;6.98°C&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Relative Humidity&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.28%&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.90%&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.51%&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.9952&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;22.23%&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;&lt;strong&gt;Generalization Analysis&lt;/strong&gt; (Test/Train Ratio): - Temperature: 1.057 (excellent - minimal overfitting) - Relative Humidity: 1.074 (excellent - minimal overfitting) - &lt;strong&gt;Average&lt;/strong&gt;: 1.065 (healthy generalization)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Training Summary&lt;/strong&gt;: - Best Validation Loss: 0.000161 - Total Parameters: 337,742 - Training Time: ~23 minutes (A100 GPU) - Status: Excellent fit with healthy generalization&lt;/p&gt; &lt;h3 id=&#34;feature-importance-analysis&#34;&gt;Feature Importance Analysis&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Top Contributing Features&lt;/strong&gt; (by RMSE impact when removed):&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Rank&lt;/th&gt; &lt;th&gt;Feature&lt;/th&gt; &lt;th&gt;RMSE Change&lt;/th&gt; &lt;th&gt;Category&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;RH (Relative Humidity)&lt;/td&gt; &lt;td&gt;+2789.47%&lt;/td&gt; &lt;td&gt;Weather Observations&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;Temp (Temperature)&lt;/td&gt; &lt;td&gt;+371.97%&lt;/td&gt; &lt;td&gt;Weather Observations&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;hour_sin&lt;/td&gt; &lt;td&gt;+6.98%&lt;/td&gt; &lt;td&gt;Temporal (Diurnal Cycle)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;altitude_sin&lt;/td&gt; &lt;td&gt;+6.46%&lt;/td&gt; &lt;td&gt;Solar Geometry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5&lt;/td&gt; &lt;td&gt;hour_cos&lt;/td&gt; &lt;td&gt;+2.44%&lt;/td&gt; &lt;td&gt;Temporal (Diurnal Cycle)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;6&lt;/td&gt; &lt;td&gt;azimuth_sin&lt;/td&gt; &lt;td&gt;+2.02%&lt;/td&gt; &lt;td&gt;Solar Geometry&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;&lt;strong&gt;Key Insights&lt;/strong&gt;: - &lt;strong&gt;Weather observations&lt;/strong&gt; dominate predictions (expected for autoregressive model) - &lt;strong&gt;Solar angles&lt;/strong&gt; contribute significantly (+2.38% avg) - validates physics-aware design - &lt;strong&gt;Temporal features&lt;/strong&gt; (hour encoding) capture diurnal patterns (+4.71% combined) - &lt;strong&gt;Day-of-year encoding&lt;/strong&gt; captures seasonal variations effectively&lt;/p&gt; &lt;h3 id=&#34;computational-requirements&#34;&gt;Computational Requirements&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt; (Phoenix cluster, A100 GPU): - &lt;strong&gt;Validation Model&lt;/strong&gt; (15 stations): ~23 minutes, 32.7 GB RAM - &lt;strong&gt;Deployment Model&lt;/strong&gt; (16 stations): ~26 minutes, 34.0 GB RAM - CPU alternative (8 cores): ~24-48 hours, 64 GB RAM&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt; (single timestamp, 100,283 points): - GPU: ~2 min 10 sec (measured on A100) - CPU: ~10-15 minutes (estimated)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Visualization&lt;/strong&gt; (100k+ points, DPI 300): - ~1 min 31 sec for 3 maps (measured)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;LULC Analysis&lt;/strong&gt; (permutation importance): - ~34 seconds (measured)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Extreme Scenarios&lt;/strong&gt; (all 4 scenarios): - ~3 min 4 sec total (measured on A100)&lt;/p&gt; &lt;h2 id=&#34;usage-examples&#34;&gt;Usage Examples&lt;/h2&gt; &lt;h3 id=&#34;example-1-complete-pipeline-local&#34;&gt;Example 1: Complete Pipeline (Local)&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-7-1&#34;&gt;&lt;a id=&#34;__codelineno-7-1&#34; name=&#34;__codelineno-7-1&#34; href=&#34;#__codelineno-7-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-7-2&#34;&gt;&lt;a id=&#34;__codelineno-7-2&#34; name=&#34;__codelineno-7-2&#34; href=&#34;#__codelineno-7-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-3&#34;&gt;&lt;a id=&#34;__codelineno-7-3&#34; name=&#34;__codelineno-7-3&#34; href=&#34;#__codelineno-7-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Run inference&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-4&#34;&gt;&lt;a id=&#34;__codelineno-7-4&#34; name=&#34;__codelineno-7-4&#34; href=&#34;#__codelineno-7-4&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_fusionlstm_inference_kriging.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--target_time&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2017-06-25 14:00:00&amp;quot;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda &lt;/span&gt;&lt;span id=&#34;__span-7-5&#34;&gt;&lt;a id=&#34;__codelineno-7-5&#34; name=&#34;__codelineno-7-5&#34; href=&#34;#__codelineno-7-5&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-6&#34;&gt;&lt;a id=&#34;__codelineno-7-6&#34; name=&#34;__codelineno-7-6&#34; href=&#34;#__codelineno-7-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Create maps with custom settings&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-7&#34;&gt;&lt;a id=&#34;__codelineno-7-7&#34; name=&#34;__codelineno-7-7&#34; href=&#34;#__codelineno-7-7&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_mapping_visualization.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-8&#34;&gt;&lt;a id=&#34;__codelineno-7-8&#34; name=&#34;__codelineno-7-8&#34; href=&#34;#__codelineno-7-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dpi&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-9&#34;&gt;&lt;a id=&#34;__codelineno-7-9&#34; name=&#34;__codelineno-7-9&#34; href=&#34;#__codelineno-7-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--marker-size&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-10&#34;&gt;&lt;a id=&#34;__codelineno-7-10&#34; name=&#34;__codelineno-7-10&#34; href=&#34;#__codelineno-7-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--marker-alpha&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;.7 &lt;/span&gt;&lt;span id=&#34;__span-7-11&#34;&gt;&lt;a id=&#34;__codelineno-7-11&#34; name=&#34;__codelineno-7-11&#34; href=&#34;#__codelineno-7-11&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-12&#34;&gt;&lt;a id=&#34;__codelineno-7-12&#34; name=&#34;__codelineno-7-12&#34; href=&#34;#__codelineno-7-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Analyze LULC feature importance&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-13&#34;&gt;&lt;a id=&#34;__codelineno-7-13&#34; name=&#34;__codelineno-7-13&#34; href=&#34;#__codelineno-7-13&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_3_lulc_analysis.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;example-2-hpc-workflow-phoenix&#34;&gt;Example 2: HPC Workflow (Phoenix)&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-8-1&#34;&gt;&lt;a id=&#34;__codelineno-8-1&#34; name=&#34;__codelineno-8-1&#34; href=&#34;#__codelineno-8-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Navigate to project directory&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-2&#34;&gt;&lt;a id=&#34;__codelineno-8-2&#34; name=&#34;__codelineno-8-2&#34; href=&#34;#__codelineno-8-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/25Fa-Microclimate-ML/4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-8-3&#34;&gt;&lt;a id=&#34;__codelineno-8-3&#34; name=&#34;__codelineno-8-3&#34; href=&#34;#__codelineno-8-3&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-4&#34;&gt;&lt;a id=&#34;__codelineno-8-4&#34; name=&#34;__codelineno-8-4&#34; href=&#34;#__codelineno-8-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Submit all jobs sequentially&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-5&#34;&gt;&lt;a id=&#34;__codelineno-8-5&#34; name=&#34;__codelineno-8-5&#34; href=&#34;#__codelineno-8-5&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_inference.sbatch &lt;/span&gt;&lt;span id=&#34;__span-8-6&#34;&gt;&lt;a id=&#34;__codelineno-8-6&#34; name=&#34;__codelineno-8-6&#34; href=&#34;#__codelineno-8-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Wait ~2 min 10 sec for inference to complete&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-7&#34;&gt;&lt;a id=&#34;__codelineno-8-7&#34; name=&#34;__codelineno-8-7&#34; href=&#34;#__codelineno-8-7&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-8&#34;&gt;&lt;a id=&#34;__codelineno-8-8&#34; name=&#34;__codelineno-8-8&#34; href=&#34;#__codelineno-8-8&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_visualization.sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# ~1 min 31 sec&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-9&#34;&gt;&lt;a id=&#34;__codelineno-8-9&#34; name=&#34;__codelineno-8-9&#34; href=&#34;#__codelineno-8-9&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_3_lulc.sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# ~34 sec&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-10&#34;&gt;&lt;a id=&#34;__codelineno-8-10&#34; name=&#34;__codelineno-8-10&#34; href=&#34;#__codelineno-8-10&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-11&#34;&gt;&lt;a id=&#34;__codelineno-8-11&#34; name=&#34;__codelineno-8-11&#34; href=&#34;#__codelineno-8-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Optional: Generate extreme scenarios&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-12&#34;&gt;&lt;a id=&#34;__codelineno-8-12&#34; name=&#34;__codelineno-8-12&#34; href=&#34;#__codelineno-8-12&#34;&gt;&lt;/a&gt;sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_4_representative_scenarios.sbatch&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# ~3 min 4 sec&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-13&#34;&gt;&lt;a id=&#34;__codelineno-8-13&#34; name=&#34;__codelineno-8-13&#34; href=&#34;#__codelineno-8-13&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-14&#34;&gt;&lt;a id=&#34;__codelineno-8-14&#34; name=&#34;__codelineno-8-14&#34; href=&#34;#__codelineno-8-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Check status&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-15&#34;&gt;&lt;a id=&#34;__codelineno-8-15&#34; name=&#34;__codelineno-8-15&#34; href=&#34;#__codelineno-8-15&#34;&gt;&lt;/a&gt;squeue&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-u&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-16&#34;&gt;&lt;a id=&#34;__codelineno-8-16&#34; name=&#34;__codelineno-8-16&#34; href=&#34;#__codelineno-8-16&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-17&#34;&gt;&lt;a id=&#34;__codelineno-8-17&#34; name=&#34;__codelineno-8-17&#34; href=&#34;#__codelineno-8-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# View results&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-18&#34;&gt;&lt;a id=&#34;__codelineno-8-18&#34; name=&#34;__codelineno-8-18&#34; href=&#34;#__codelineno-8-18&#34;&gt;&lt;/a&gt;ls&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-lh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;outputs/ &lt;/span&gt;&lt;span id=&#34;__span-8-19&#34;&gt;&lt;a id=&#34;__codelineno-8-19&#34; name=&#34;__codelineno-8-19&#34; href=&#34;#__codelineno-8-19&#34;&gt;&lt;/a&gt;ls&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-lh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;figures/ &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;example-3-custom-training&#34;&gt;Example 3: Custom Training&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-9-1&#34;&gt;&lt;a id=&#34;__codelineno-9-1&#34; name=&#34;__codelineno-9-1&#34; href=&#34;#__codelineno-9-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;3_Training_Model &lt;/span&gt;&lt;span id=&#34;__span-9-2&#34;&gt;&lt;a id=&#34;__codelineno-9-2&#34; name=&#34;__codelineno-9-2&#34; href=&#34;#__codelineno-9-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-3&#34;&gt;&lt;a id=&#34;__codelineno-9-3&#34; name=&#34;__codelineno-9-3&#34; href=&#34;#__codelineno-9-3&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_5_main.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-4&#34;&gt;&lt;a id=&#34;__codelineno-9-4&#34; name=&#34;__codelineno-9-4&#34; href=&#34;#__codelineno-9-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--data_path&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;../2_Data/gatech_16_stations_10_min_long_format_sun_angles.csv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-5&#34;&gt;&lt;a id=&#34;__codelineno-9-5&#34; name=&#34;__codelineno-9-5&#34; href=&#34;#__codelineno-9-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--sequence_length&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;144&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-6&#34;&gt;&lt;a id=&#34;__codelineno-9-6&#34; name=&#34;__codelineno-9-6&#34; href=&#34;#__codelineno-9-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--epochs&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-7&#34;&gt;&lt;a id=&#34;__codelineno-9-7&#34; name=&#34;__codelineno-9-7&#34; href=&#34;#__codelineno-9-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--patience&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-8&#34;&gt;&lt;a id=&#34;__codelineno-9-8&#34; name=&#34;__codelineno-9-8&#34; href=&#34;#__codelineno-9-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--hidden_dim&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-9&#34;&gt;&lt;a id=&#34;__codelineno-9-9&#34; name=&#34;__codelineno-9-9&#34; href=&#34;#__codelineno-9-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--num_layers&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-10&#34;&gt;&lt;a id=&#34;__codelineno-9-10&#34; name=&#34;__codelineno-9-10&#34; href=&#34;#__codelineno-9-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dropout&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;.3&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-11&#34;&gt;&lt;a id=&#34;__codelineno-9-11&#34; name=&#34;__codelineno-9-11&#34; href=&#34;#__codelineno-9-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--attention_heads&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-12&#34;&gt;&lt;a id=&#34;__codelineno-9-12&#34; name=&#34;__codelineno-9-12&#34; href=&#34;#__codelineno-9-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--weight_decay&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;1e-3&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-13&#34;&gt;&lt;a id=&#34;__codelineno-9-13&#34; name=&#34;__codelineno-9-13&#34; href=&#34;#__codelineno-9-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--learning_rate&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;.001&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-14&#34;&gt;&lt;a id=&#34;__codelineno-9-14&#34; name=&#34;__codelineno-9-14&#34; href=&#34;#__codelineno-9-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-15&#34;&gt;&lt;a id=&#34;__codelineno-9-15&#34; name=&#34;__codelineno-9-15&#34; href=&#34;#__codelineno-9-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--save_dir&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;./weights_4heads &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;example-4-batch-processing-multiple-times&#34;&gt;Example 4: Batch Processing Multiple Times&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-10-1&#34;&gt;&lt;a id=&#34;__codelineno-10-1&#34; name=&#34;__codelineno-10-1&#34; href=&#34;#__codelineno-10-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;4_Inference_and_Visualization &lt;/span&gt;&lt;span id=&#34;__span-10-2&#34;&gt;&lt;a id=&#34;__codelineno-10-2&#34; name=&#34;__codelineno-10-2&#34; href=&#34;#__codelineno-10-2&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-10-3&#34;&gt;&lt;a id=&#34;__codelineno-10-3&#34; name=&#34;__codelineno-10-3&#34; href=&#34;#__codelineno-10-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Loop through multiple timestamps&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-10-4&#34;&gt;&lt;a id=&#34;__codelineno-10-4&#34; name=&#34;__codelineno-10-4&#34; href=&#34;#__codelineno-10-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2017-06-25 14:00:00&amp;quot;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2016-06-25 16:10:00&amp;quot;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;2015-04-04 18:30:00&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-10-5&#34;&gt;&lt;a id=&#34;__codelineno-10-5&#34; name=&#34;__codelineno-10-5&#34; href=&#34;#__codelineno-10-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_1_fusionlstm_inference_kriging.py&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--target_time&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$time&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--device&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;cuda &lt;/span&gt;&lt;span id=&#34;__span-10-6&#34;&gt;&lt;a id=&#34;__codelineno-10-6&#34; name=&#34;__codelineno-10-6&#34; href=&#34;#__codelineno-10-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;_2_mapping_visualization.py &lt;/span&gt;&lt;span id=&#34;__span-10-7&#34;&gt;&lt;a id=&#34;__codelineno-10-7&#34; name=&#34;__codelineno-10-7&#34; href=&#34;#__codelineno-10-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;output-files&#34;&gt;Output Files&lt;/h2&gt; &lt;h3 id=&#34;inference-outputs&#34;&gt;Inference Outputs&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Directory&lt;/strong&gt;: &lt;code&gt;4_Inference_and_Visualization/outputs/&lt;/code&gt;&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;File&lt;/th&gt; &lt;th&gt;Size&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;FusionLSTM_kriging_predictions_TIMESTAMP.csv&lt;/code&gt;&lt;/td&gt; &lt;td&gt;~31 MB&lt;/td&gt; &lt;td&gt;100,283 points × 26 columns&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;FusionLSTM_kriging_predictions_TIMESTAMP_models.pkl&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;169 KB&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;Regression Kriging models (Temperature + RH)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;&lt;strong&gt;CSV Columns&lt;/strong&gt;: - Coordinates: &lt;code&gt;latitude&lt;/code&gt;, &lt;code&gt;longitude&lt;/code&gt;, &lt;code&gt;point_id&lt;/code&gt; - Spatial features: 9 LULC features - Predictions: &lt;code&gt;KrigingPrediction_Tem&lt;/code&gt;, &lt;code&gt;KrigingPrediction_RH&lt;/code&gt;&lt;/p&gt; &lt;h3 id=&#34;visualization-outputs&#34;&gt;Visualization Outputs&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Directory&lt;/strong&gt;: &lt;code&gt;4_Inference_and_Visualization/figures/&lt;/code&gt;&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;File&lt;/th&gt; &lt;th&gt;Size&lt;/th&gt; &lt;th&gt;Resolution&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;temperature_map_TIMESTAMP.png&lt;/code&gt;&lt;/td&gt; &lt;td&gt;~1.7 MB&lt;/td&gt; &lt;td&gt;4800×3600 px&lt;/td&gt; &lt;td&gt;Temperature spatial map&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;humidity_map_TIMESTAMP.png&lt;/code&gt;&lt;/td&gt; &lt;td&gt;~1.4 MB&lt;/td&gt; &lt;td&gt;4800×3600 px&lt;/td&gt; &lt;td&gt;Humidity spatial map&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;comparison_map_TIMESTAMP.png&lt;/code&gt;&lt;/td&gt; &lt;td&gt;~2.1 MB&lt;/td&gt; &lt;td&gt;7200×3000 px&lt;/td&gt; &lt;td&gt;Side-by-side comparison&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;*_lulc_importance.png&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;237 KB&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;4800×1800 px&lt;/td&gt; &lt;td&gt;LULC feature importance analysis&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;HOTTEST_*.png&lt;/code&gt;, &lt;code&gt;COLDEST_*.png&lt;/code&gt;, etc.&lt;/td&gt; &lt;td&gt;~1-2 MB each&lt;/td&gt; &lt;td&gt;4800×3600 px&lt;/td&gt; &lt;td&gt;Extreme scenario maps&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3 id=&#34;training-outputs&#34;&gt;Training Outputs&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Directory&lt;/strong&gt;: &lt;code&gt;3_Training_Model/&lt;/code&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;weights/TFT_weather_model.pth&lt;/code&gt; - CPU trained model&lt;/li&gt; &lt;li&gt;&lt;code&gt;weights_4heads/TFT_weather_model.pth&lt;/code&gt; - GPU trained model&lt;/li&gt; &lt;li&gt;&lt;code&gt;training_plots/&lt;/code&gt; - Loss curves, LR schedule&lt;/li&gt; &lt;li&gt;&lt;code&gt;evaluation_plots/&lt;/code&gt; - Predictions, residuals, scatter plots&lt;/li&gt; &lt;li&gt;&lt;code&gt;logs/&lt;/code&gt; - SLURM job outputs&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;dependencies&#34;&gt;Dependencies&lt;/h2&gt; &lt;h3 id=&#34;core-requirements&#34;&gt;Core Requirements&lt;/h3&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-11-1&#34;&gt;&lt;a id=&#34;__codelineno-11-1&#34; name=&#34;__codelineno-11-1&#34; href=&#34;#__codelineno-11-1&#34;&gt;&lt;/a&gt;# Deep Learning &lt;/span&gt;&lt;span id=&#34;__span-11-2&#34;&gt;&lt;a id=&#34;__codelineno-11-2&#34; name=&#34;__codelineno-11-2&#34; href=&#34;#__codelineno-11-2&#34;&gt;&lt;/a&gt;torch&amp;gt;=2.3.1 &lt;/span&gt;&lt;span id=&#34;__span-11-3&#34;&gt;&lt;a id=&#34;__codelineno-11-3&#34; name=&#34;__codelineno-11-3&#34; href=&#34;#__codelineno-11-3&#34;&gt;&lt;/a&gt;numpy&amp;gt;=1.26.4,&amp;lt;2.0.0 &lt;/span&gt;&lt;span id=&#34;__span-11-4&#34;&gt;&lt;a id=&#34;__codelineno-11-4&#34; name=&#34;__codelineno-11-4&#34; href=&#34;#__codelineno-11-4&#34;&gt;&lt;/a&gt;pandas==2.2.2 &lt;/span&gt;&lt;span id=&#34;__span-11-5&#34;&gt;&lt;a id=&#34;__codelineno-11-5&#34; name=&#34;__codelineno-11-5&#34; href=&#34;#__codelineno-11-5&#34;&gt;&lt;/a&gt;scikit-learn==1.7.2 &lt;/span&gt;&lt;span id=&#34;__span-11-6&#34;&gt;&lt;a id=&#34;__codelineno-11-6&#34; name=&#34;__codelineno-11-6&#34; href=&#34;#__codelineno-11-6&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-11-7&#34;&gt;&lt;a id=&#34;__codelineno-11-7&#34; name=&#34;__codelineno-11-7&#34; href=&#34;#__codelineno-11-7&#34;&gt;&lt;/a&gt;# Spatial Analysis &lt;/span&gt;&lt;span id=&#34;__span-11-8&#34;&gt;&lt;a id=&#34;__codelineno-11-8&#34; name=&#34;__codelineno-11-8&#34; href=&#34;#__codelineno-11-8&#34;&gt;&lt;/a&gt;pykrige==1.7.0 &lt;/span&gt;&lt;span id=&#34;__span-11-9&#34;&gt;&lt;a id=&#34;__codelineno-11-9&#34; name=&#34;__codelineno-11-9&#34; href=&#34;#__codelineno-11-9&#34;&gt;&lt;/a&gt;contextily==1.6.2 &lt;/span&gt;&lt;span id=&#34;__span-11-10&#34;&gt;&lt;a id=&#34;__codelineno-11-10&#34; name=&#34;__codelineno-11-10&#34; href=&#34;#__codelineno-11-10&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-11-11&#34;&gt;&lt;a id=&#34;__codelineno-11-11&#34; name=&#34;__codelineno-11-11&#34; href=&#34;#__codelineno-11-11&#34;&gt;&lt;/a&gt;# Visualization &lt;/span&gt;&lt;span id=&#34;__span-11-12&#34;&gt;&lt;a id=&#34;__codelineno-11-12&#34; name=&#34;__codelineno-11-12&#34; href=&#34;#__codelineno-11-12&#34;&gt;&lt;/a&gt;matplotlib==3.10.3 &lt;/span&gt;&lt;span id=&#34;__span-11-13&#34;&gt;&lt;a id=&#34;__codelineno-11-13&#34; name=&#34;__codelineno-11-13&#34; href=&#34;#__codelineno-11-13&#34;&gt;&lt;/a&gt;seaborn==0.13.2 &lt;/span&gt;&lt;span id=&#34;__span-11-14&#34;&gt;&lt;a id=&#34;__codelineno-11-14&#34; name=&#34;__codelineno-11-14&#34; href=&#34;#__codelineno-11-14&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-11-15&#34;&gt;&lt;a id=&#34;__codelineno-11-15&#34; name=&#34;__codelineno-11-15&#34; href=&#34;#__codelineno-11-15&#34;&gt;&lt;/a&gt;# Utilities &lt;/span&gt;&lt;span id=&#34;__span-11-16&#34;&gt;&lt;a id=&#34;__codelineno-11-16&#34; name=&#34;__codelineno-11-16&#34; href=&#34;#__codelineno-11-16&#34;&gt;&lt;/a&gt;tqdm==4.67.1 &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id=&#34;installation-options&#34;&gt;Installation Options&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Using UV (Recommended):&lt;/strong&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-12-1&#34;&gt;&lt;a id=&#34;__codelineno-12-1&#34; name=&#34;__codelineno-12-1&#34; href=&#34;#__codelineno-12-1&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;venv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;.venv/bin/activate &lt;/span&gt;&lt;span id=&#34;__span-12-2&#34;&gt;&lt;a id=&#34;__codelineno-12-2&#34; name=&#34;__codelineno-12-2&#34; href=&#34;#__codelineno-12-2&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Using pip:&lt;/strong&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-13-1&#34;&gt;&lt;a id=&#34;__codelineno-13-1&#34; name=&#34;__codelineno-13-1&#34; href=&#34;#__codelineno-13-1&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why UV?&lt;/strong&gt; UV provides 10-100x faster package installation compared to pip, with deterministic dependency resolution for reproducible environments. All SLURM scripts use UV by default for efficient HPC resource utilization.&lt;/p&gt; &lt;h2 id=&#34;package-management-with-uv&#34;&gt;Package Management with UV&lt;/h2&gt; &lt;p&gt;This project uses &lt;a href=&#34;https://github.com/astral-sh/uv&#34;&gt;UV&lt;/a&gt; for fast and reliable Python package management.&lt;/p&gt; &lt;h3 id=&#34;installation&#34;&gt;Installation&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;One-time setup:&lt;/strong&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-14-1&#34;&gt;&lt;a id=&#34;__codelineno-14-1&#34; name=&#34;__codelineno-14-1&#34; href=&#34;#__codelineno-14-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Install UV&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-14-2&#34;&gt;&lt;a id=&#34;__codelineno-14-2&#34; name=&#34;__codelineno-14-2&#34; href=&#34;#__codelineno-14-2&#34;&gt;&lt;/a&gt;curl&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-LsSf&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;https://astral.sh/uv/install.sh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;sh &lt;/span&gt;&lt;span id=&#34;__span-14-3&#34;&gt;&lt;a id=&#34;__codelineno-14-3&#34; name=&#34;__codelineno-14-3&#34; href=&#34;#__codelineno-14-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/.local/bin:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-14-4&#34;&gt;&lt;a id=&#34;__codelineno-14-4&#34; name=&#34;__codelineno-14-4&#34; href=&#34;#__codelineno-14-4&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-14-5&#34;&gt;&lt;a id=&#34;__codelineno-14-5&#34; name=&#34;__codelineno-14-5&#34; href=&#34;#__codelineno-14-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Make permanent (add to ~/.bashrc)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-14-6&#34;&gt;&lt;a id=&#34;__codelineno-14-6&#34; name=&#34;__codelineno-14-6&#34; href=&#34;#__codelineno-14-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;export PATH=&amp;quot;$HOME/.local/bin:$PATH&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&amp;gt;&amp;gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;~/.bashrc &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;h3 id=&#34;usage-on-hpc-phoenix-cluster&#34;&gt;Usage on HPC (Phoenix Cluster)&lt;/h3&gt; &lt;p&gt;All SLURM scripts automatically use UV for dependency installation:&lt;/p&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-15-1&#34;&gt;&lt;a id=&#34;__codelineno-15-1&#34; name=&#34;__codelineno-15-1&#34; href=&#34;#__codelineno-15-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ch&#34;&gt;#!/bin/bash&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-2&#34;&gt;&lt;a id=&#34;__codelineno-15-2&#34; name=&#34;__codelineno-15-2&#34; href=&#34;#__codelineno-15-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;#SBATCH --account=gts-pkastner3&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-3&#34;&gt;&lt;a id=&#34;__codelineno-15-3&#34; name=&#34;__codelineno-15-3&#34; href=&#34;#__codelineno-15-3&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-4&#34;&gt;&lt;a id=&#34;__codelineno-15-4&#34; name=&#34;__codelineno-15-4&#34; href=&#34;#__codelineno-15-4&#34;&gt;&lt;/a&gt;module&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;load&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;anaconda3 &lt;/span&gt;&lt;span id=&#34;__span-15-5&#34;&gt;&lt;a id=&#34;__codelineno-15-5&#34; name=&#34;__codelineno-15-5&#34; href=&#34;#__codelineno-15-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/.local/bin:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-6&#34;&gt;&lt;a id=&#34;__codelineno-15-6&#34; name=&#34;__codelineno-15-6&#34; href=&#34;#__codelineno-15-6&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-7&#34;&gt;&lt;a id=&#34;__codelineno-15-7&#34; name=&#34;__codelineno-15-7&#34; href=&#34;#__codelineno-15-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# UV automatically used (10-100x faster than pip)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-8&#34;&gt;&lt;a id=&#34;__codelineno-15-8&#34; name=&#34;__codelineno-15-8&#34; href=&#34;#__codelineno-15-8&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--system &lt;/span&gt;&lt;span id=&#34;__span-15-9&#34;&gt;&lt;a id=&#34;__codelineno-15-9&#34; name=&#34;__codelineno-15-9&#34; href=&#34;#__codelineno-15-9&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-15-10&#34;&gt;&lt;a id=&#34;__codelineno-15-10&#34; name=&#34;__codelineno-15-10&#34; href=&#34;#__codelineno-15-10&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;your_script.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; UV reduces package installation time from ~45 seconds (pip) to ~2 seconds (cached), saving over 1 hour for 100 job submissions.&lt;/p&gt; &lt;h3 id=&#34;local-development&#34;&gt;Local Development&lt;/h3&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-16-1&#34;&gt;&lt;a id=&#34;__codelineno-16-1&#34; name=&#34;__codelineno-16-1&#34; href=&#34;#__codelineno-16-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Create virtual environment&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-16-2&#34;&gt;&lt;a id=&#34;__codelineno-16-2&#34; name=&#34;__codelineno-16-2&#34; href=&#34;#__codelineno-16-2&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;venv &lt;/span&gt;&lt;span id=&#34;__span-16-3&#34;&gt;&lt;a id=&#34;__codelineno-16-3&#34; name=&#34;__codelineno-16-3&#34; href=&#34;#__codelineno-16-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;.venv/bin/activate &lt;/span&gt;&lt;span id=&#34;__span-16-4&#34;&gt;&lt;a id=&#34;__codelineno-16-4&#34; name=&#34;__codelineno-16-4&#34; href=&#34;#__codelineno-16-4&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-16-5&#34;&gt;&lt;a id=&#34;__codelineno-16-5&#34; name=&#34;__codelineno-16-5&#34; href=&#34;#__codelineno-16-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Install dependencies&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-16-6&#34;&gt;&lt;a id=&#34;__codelineno-16-6&#34; name=&#34;__codelineno-16-6&#34; href=&#34;#__codelineno-16-6&#34;&gt;&lt;/a&gt;uv&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;UV is a drop-in replacement for pip with identical command syntax and significantly improved performance.&lt;/p&gt; &lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt; &lt;p&gt;Detailed guides for each module:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;3_Training_Model/README.md&#34;&gt;3_Training_Model/README.md&lt;/a&gt;&lt;/strong&gt; - Complete training guide&lt;/li&gt; &lt;li&gt;Single-step architecture details&lt;/li&gt; &lt;li&gt;SLURM job configuration&lt;/li&gt; &lt;li&gt;Hyperparameter tuning&lt;/li&gt; &lt;li&gt; &lt;p&gt;Performance optimization&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;4_Inference_and_Visualization/README.md&#34;&gt;4_Inference_and_Visualization/README.md&lt;/a&gt;&lt;/strong&gt; - Inference &amp;amp; visualization&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Inference workflow&lt;/li&gt; &lt;li&gt;Kriging vs IDW fallback&lt;/li&gt; &lt;li&gt;Visualization settings&lt;/li&gt; &lt;li&gt; &lt;p&gt;LULC analysis&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&#34;PACE_PHOENIX_TUTORIAL.md&#34;&gt;PACE_PHOENIX_TUTORIAL.md&lt;/a&gt;&lt;/strong&gt; - Complete beginner&#39;s guide&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Step-by-step SSH connection&lt;/li&gt; &lt;li&gt;GlobalProtect VPN setup&lt;/li&gt; &lt;li&gt;File upload/download&lt;/li&gt; &lt;li&gt;Complete workflow examples&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;github-ssh-key-setup-for-private-repo&#34;&gt;GitHub SSH Key Setup (For Private Repo)&lt;/h2&gt; &lt;p&gt;This repository is private. Set up SSH key for access:&lt;/p&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-17-1&#34;&gt;&lt;a id=&#34;__codelineno-17-1&#34; name=&#34;__codelineno-17-1&#34; href=&#34;#__codelineno-17-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# On Phoenix (or local machine)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-2&#34;&gt;&lt;a id=&#34;__codelineno-17-2&#34; name=&#34;__codelineno-17-2&#34; href=&#34;#__codelineno-17-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 1. Generate SSH key&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-3&#34;&gt;&lt;a id=&#34;__codelineno-17-3&#34; name=&#34;__codelineno-17-3&#34; href=&#34;#__codelineno-17-3&#34;&gt;&lt;/a&gt;ssh-keygen&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-t&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ed25519&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-C&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;your_email@gatech.edu&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-4&#34;&gt;&lt;a id=&#34;__codelineno-17-4&#34; name=&#34;__codelineno-17-4&#34; href=&#34;#__codelineno-17-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Press Enter for default location, optionally set passphrase&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-5&#34;&gt;&lt;a id=&#34;__codelineno-17-5&#34; name=&#34;__codelineno-17-5&#34; href=&#34;#__codelineno-17-5&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-6&#34;&gt;&lt;a id=&#34;__codelineno-17-6&#34; name=&#34;__codelineno-17-6&#34; href=&#34;#__codelineno-17-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 2. Display public key&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-7&#34;&gt;&lt;a id=&#34;__codelineno-17-7&#34; name=&#34;__codelineno-17-7&#34; href=&#34;#__codelineno-17-7&#34;&gt;&lt;/a&gt;cat&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;~/.ssh/id_ed25519.pub &lt;/span&gt;&lt;span id=&#34;__span-17-8&#34;&gt;&lt;a id=&#34;__codelineno-17-8&#34; name=&#34;__codelineno-17-8&#34; href=&#34;#__codelineno-17-8&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-9&#34;&gt;&lt;a id=&#34;__codelineno-17-9&#34; name=&#34;__codelineno-17-9&#34; href=&#34;#__codelineno-17-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 3. Copy the output (starts with ssh-ed25519)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-10&#34;&gt;&lt;a id=&#34;__codelineno-17-10&#34; name=&#34;__codelineno-17-10&#34; href=&#34;#__codelineno-17-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 4. Add to GitHub: Settings → SSH and GPG keys → New SSH key&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-11&#34;&gt;&lt;a id=&#34;__codelineno-17-11&#34; name=&#34;__codelineno-17-11&#34; href=&#34;#__codelineno-17-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# 5. Paste key and save&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-12&#34;&gt;&lt;a id=&#34;__codelineno-17-12&#34; name=&#34;__codelineno-17-12&#34; href=&#34;#__codelineno-17-12&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-13&#34;&gt;&lt;a id=&#34;__codelineno-17-13&#34; name=&#34;__codelineno-17-13&#34; href=&#34;#__codelineno-17-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Test connection&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-17-14&#34;&gt;&lt;a id=&#34;__codelineno-17-14&#34; name=&#34;__codelineno-17-14&#34; href=&#34;#__codelineno-17-14&#34;&gt;&lt;/a&gt;ssh&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-T&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;git@github.com &lt;/span&gt;&lt;span id=&#34;__span-17-15&#34;&gt;&lt;a id=&#34;__codelineno-17-15&#34; name=&#34;__codelineno-17-15&#34; href=&#34;#__codelineno-17-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# Should see: &amp;quot;Hi USERNAME! You&amp;#39;ve successfully authenticated&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;model-validation-generalization&#34;&gt;Model Validation &amp;amp; Generalization&lt;/h2&gt; &lt;h3 id=&#34;overfitting-analysis&#34;&gt;Overfitting Analysis&lt;/h3&gt; &lt;p&gt;The model demonstrates &lt;strong&gt;excellent generalization&lt;/strong&gt; with minimal overfitting:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Test/Train RMSE Ratios&lt;/strong&gt;: - Temperature: 1.057 (5.7% increase) - Relative Humidity: 1.074 (7.4% increase) - &lt;strong&gt;Average: 1.065&lt;/strong&gt; ✅ (healthy - indicates robust generalization)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: - Ratio &amp;lt; 1.10: Excellent generalization - Ratio 1.10-1.20: Good generalization - Ratio &amp;gt; 1.20: Potential overfitting&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why This Works&lt;/strong&gt;: - Strong regularization (dropout=0.3, weight_decay=1e-3) - Early stopping (patience=20) prevents overtraining - Station holdout validation ensures spatial generalization - 24-hour sequence length with proper regularization&lt;/p&gt; &lt;h3 id=&#34;training-stability&#34;&gt;Training Stability&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Loss Analysis&lt;/strong&gt;: - Best Validation Loss: 0.000161 - Final Train Loss: 0.000835 - Train/Val Ratio: 5.17 (expected for scaled targets)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: - Smooth loss curves indicate stable training - Early stopping triggered appropriately - No gradient explosion or vanishing&lt;/p&gt; &lt;h2 id=&#34;tips-for-best-results&#34;&gt;Tips for Best Results&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;GPU Acceleration&lt;/strong&gt;: Use &lt;code&gt;--device cuda&lt;/code&gt; for 10x faster training/inference (~23 min vs ~24-48 hours)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;: Ensure clean, temporally ordered data with proper datetime format&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Target Time Selection&lt;/strong&gt;: Use timestamps within warm season 2015-2019 (e.g., 2017-06-25 14:00:00 for summer afternoon)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Visualization Quality&lt;/strong&gt;: &lt;/li&gt; &lt;li&gt;DPI 300 for standard quality&lt;/li&gt; &lt;li&gt;DPI 600 for high-quality posters&lt;/li&gt; &lt;li&gt;Adjust marker size/alpha for data density&lt;/li&gt; &lt;li&gt;&lt;strong&gt;LULC Analysis&lt;/strong&gt;: &lt;/li&gt; &lt;li&gt;Works with 16-station Regression Kriging&lt;/li&gt; &lt;li&gt;Random Forest permutation importance shows which spatial features matter most&lt;/li&gt; &lt;li&gt;Visualizes feature importance across temperature and humidity predictions&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Model Performance&lt;/strong&gt;:&lt;/li&gt; &lt;li&gt;Temperature predictions: Sub-0.5°C RMSE, &amp;gt;99% R²&lt;/li&gt; &lt;li&gt;Humidity predictions: ~1.3% RMSE, &amp;gt;99% R²&lt;/li&gt; &lt;li&gt;Excellent generalization (test/train ratio ~1.065)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;HPC Usage&lt;/strong&gt;: &lt;/li&gt; &lt;li&gt;Use GPU partition for training (100x faster: 23 min vs 24+ hours)&lt;/li&gt; &lt;li&gt;Use CPU partition for visualization&lt;/li&gt; &lt;li&gt;Monitor job status with &lt;code&gt;squeue -u $USER&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Set &lt;code&gt;UV_CACHE_DIR&lt;/code&gt; to scratch to avoid disk quota issues&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;known-limitations&#34;&gt;Known Limitations&lt;/h2&gt; &lt;h3 id=&#34;data-constraints&#34;&gt;Data Constraints&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Temporal Coverage&lt;/strong&gt;: Warm season only (April–September, 2015-2019)&lt;/li&gt; &lt;li&gt;Model optimized for heat stress conditions&lt;/li&gt; &lt;li&gt; &lt;p&gt;Not validated for cold season (October–March)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spatial Extent&lt;/strong&gt;: Georgia Tech campus only (~3.5 km²)&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Generalization to other locations requires retraining or transfer learning&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;technical-constraints&#34;&gt;Technical Constraints&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Grid Density&lt;/strong&gt;: 100,283 points → moderate memory requirements (~2-4 GB)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Computational&lt;/strong&gt;: GPU recommended for training (CPU training 10-20x slower)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Real-time&lt;/strong&gt;: No live data integration yet (historical data only)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt; &lt;h3 id=&#34;common-issues&#34;&gt;Common Issues&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Q: No prediction files found&lt;/strong&gt;&lt;br /&gt; A: Run inference first: &lt;code&gt;python _1_fusionlstm_inference_kriging.py&lt;/code&gt; or &lt;code&gt;sbatch _1_inference.sbatch&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: Model file not found&lt;/strong&gt;&lt;br /&gt; A: Train the model first (&lt;code&gt;sbatch phoenix_gpu_train.sbatch&lt;/code&gt;) or download pre-trained weights from Hugging Face&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: Weather data file not found&lt;/strong&gt;&lt;br /&gt; A: Download the 16-station dataset from &lt;a href=&#34;https://huggingface.co/datasets/yupengtang/gatech_10_min_long_format_sun_angles&#34;&gt;Hugging Face&lt;/a&gt; and place as &lt;code&gt;2_Data/gatech_16_stations_10_min_long_format_sun_angles.csv&lt;/code&gt; (see &lt;code&gt;2_Data/README.md&lt;/code&gt;)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: CUDA out of memory&lt;/strong&gt;&lt;br /&gt; A: Use &lt;code&gt;--device cpu&lt;/code&gt; or reduce batch size (default: 1024)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: ModuleNotFoundError&lt;/strong&gt;&lt;br /&gt; A: Install dependencies: &lt;code&gt;uv pip install -r requirements.txt&lt;/code&gt; or &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: Visualization too slow&lt;/strong&gt;&lt;br /&gt; A: Reduce DPI (&lt;code&gt;--dpi 150&lt;/code&gt;) or use GPU for inference&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Q: Training job pending too long&lt;/strong&gt;&lt;br /&gt; A: Check queue status with &lt;code&gt;squeue -p gpu-a100&lt;/code&gt;. A100 partition may have high demand; consider using A40 partition or CPU training&lt;/p&gt; &lt;h3 id=&#34;getting-help&#34;&gt;Getting Help&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Check module-specific READMEs&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://github.com/VIP-SMUR/25Fa-Microclimate-ML/issues&#34;&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Review &lt;a href=&#34;https://github.com/VIP-SMUR/25Fa-Microclimate-ML/issues/12&#34;&gt;Known Issues&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;research-context&#34;&gt;Research Context&lt;/h2&gt; &lt;p&gt;This project is part of the &lt;strong&gt;Georgia Tech VIP-SMUR&lt;/strong&gt; (Vertically Integrated Projects - Sustainable Microclimate Urban Research) initiative, focusing on understanding and predicting microclimate variations in urban environments for improved sustainability and resilience.&lt;/p&gt; &lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Urban Planning&lt;/strong&gt;: Heat island effect analysis and mitigation&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Climate Research&lt;/strong&gt;: Fine-grained microclimate pattern studies &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Smart Campus&lt;/strong&gt;: Weather-aware systems and applications&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Education&lt;/strong&gt;: Teaching tool for ML and spatial weather modeling&lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;architecture-inspiration&#34;&gt;Architecture Inspiration&lt;/h3&gt; &lt;p&gt;The single-step iterative prediction approach demonstrates superior long-term forecasting performance compared to multi-step architectures by maintaining consistent input-output distribution and avoiding temporal distribution gaps.&lt;/p&gt; &lt;h2 id=&#34;future-work&#34;&gt;Future Work&lt;/h2&gt; &lt;ul class=&#34;task-list&#34;&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled checked/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; &lt;del&gt;Increase weather station coverage (&amp;gt;3 stations) for robust Kriging&lt;/del&gt; &lt;strong&gt;✅ Completed: 16 stations&lt;/strong&gt;&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Extend temporal coverage to full year (currently warm season 2015-2019)&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Add more spatial features (vegetation density, sky view factor)&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Real-time prediction with live weather data integration&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Multi-location model generalization (transfer learning to other campuses)&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Integration with IoT sensor networks for real-time validation&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Ensemble predictions with uncertainty quantification&lt;/li&gt; &lt;li class=&#34;task-list-item&#34;&gt;&lt;label class=&#34;task-list-control&#34;&gt;&lt;input type=&#34;checkbox&#34; disabled/&gt;&lt;span class=&#34;task-list-indicator&#34;&gt;&lt;/span&gt;&lt;/label&gt; Extend to full-year prediction (cold season: October–March)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt; &lt;p&gt;If you use this project in your research, please cite:&lt;/p&gt; &lt;div class=&#34;language-bibtex highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-18-1&#34;&gt;&lt;a id=&#34;__codelineno-18-1&#34; name=&#34;__codelineno-18-1&#34; href=&#34;#__codelineno-18-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nc&#34;&gt;@software&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;gatech_microclimate_2025&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-2&#34;&gt;&lt;a id=&#34;__codelineno-18-2&#34; name=&#34;__codelineno-18-2&#34; href=&#34;#__codelineno-18-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{FusionLSTM: Multi-Scale Fusion LSTM with Attention for Urban Microclimate Prediction}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-3&#34;&gt;&lt;a id=&#34;__codelineno-18-3&#34; name=&#34;__codelineno-18-3&#34; href=&#34;#__codelineno-18-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{Georgia Tech VIP-SMUR Team}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-4&#34;&gt;&lt;a id=&#34;__codelineno-18-4&#34; name=&#34;__codelineno-18-4&#34; href=&#34;#__codelineno-18-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{2025}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-5&#34;&gt;&lt;a id=&#34;__codelineno-18-5&#34; name=&#34;__codelineno-18-5&#34; href=&#34;#__codelineno-18-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{https://github.com/VIP-SMUR/25Fa-Microclimate-ML}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-6&#34;&gt;&lt;a id=&#34;__codelineno-18-6&#34; name=&#34;__codelineno-18-6&#34; href=&#34;#__codelineno-18-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;note&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{TFT-inspired architecture with parallel LSTM branches for warm-season microclimate forecasting}&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-18-7&#34;&gt;&lt;a id=&#34;__codelineno-18-7&#34; name=&#34;__codelineno-18-7&#34; href=&#34;#__codelineno-18-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt; &lt;p&gt;This project is part of Georgia Tech research. See individual files for specific licensing.&lt;/p&gt; &lt;h2 id=&#34;contributing&#34;&gt;Contributing&lt;/h2&gt; &lt;p&gt;This is an active research project. For contributions or questions, please:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Check existing documentation in module READMEs&lt;/li&gt; &lt;li&gt;Review open &lt;a href=&#34;https://github.com/VIP-SMUR/25Fa-Microclimate-ML/issues&#34;&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Follow existing code style and structure&lt;/li&gt; &lt;li&gt;Document new features thoroughly&lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Georgia Tech VIP Program&lt;/strong&gt; - Project support and infrastructure&lt;/li&gt; &lt;li&gt;&lt;strong&gt;PACE Phoenix Cluster&lt;/strong&gt; - Computational resources&lt;/li&gt; &lt;li&gt;&lt;strong&gt;PyTorch Team&lt;/strong&gt; - Deep learning framework&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenStreetMap Contributors&lt;/strong&gt; - Geospatial data&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;p&gt;&lt;strong&gt;Project Status&lt;/strong&gt;: Active Development | &lt;strong&gt;Last Updated&lt;/strong&gt;: November 20, 2024&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Pipeline Version&lt;/strong&gt;: 2.0 (Single-step architecture, SLURM integration, structured outputs)&lt;/p&gt; &lt;p&gt;For detailed usage instructions, see module-specific READMEs: - &lt;a href=&#34;3_Training_Model/README.md&#34;&gt;Training Guide&lt;/a&gt; - &lt;a href=&#34;4_Inference_and_Visualization/README.md&#34;&gt;Inference &amp;amp; Visualization Guide&lt;/a&gt; - &lt;a href=&#34;PACE_PHOENIX_TUTORIAL.md&#34;&gt;Phoenix HPC Tutorial&lt;/a&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h1 id=&#34;microclimate-ml-geo-lstm-kriging&#34;&gt;Microclimate-ML (Geo-LSTM-Kriging)&lt;/h1&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oyDra0_vdQ0&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/oyDra0_vdQ0/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Thanasarn Changnawa&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Thanasarn-Changnawa&#34;&gt;Thanasarn-Changnawa&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Han-Syun Shih&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Benjaminhansyun&#34;&gt;Benjaminhansyun&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Edzel Sutanto&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Edzelandika&#34;&gt;Edzelandika&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Roshan Cerejo&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/rcerejo&#34;&gt;rcerejo&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Vikram Renganathan&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/viren108&#34;&gt;viren108&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Yupeng Tang&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/yupengtang&#34;&gt;yupengtang&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ze Yu Jiang&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/zeyujiang8800&#34;&gt;zeyujiang8800&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-microclimate-ml/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-microclimate-ml/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-microclimate-ml/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-microclimate-ml/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-Energy</title> <description>&lt;h1 id=&#34;enhancing-data-driven-urban-building-energy-model-with-multi-dimensional-data-resourcesmicroclimate-and-demographic-perspectives&#34;&gt;Enhancing Data-Driven Urban Building Energy Model with Multi-Dimensional Data Resources:Microclimate and Demographic Perspectives&lt;/h1&gt; &lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt; &lt;p&gt;&lt;img src=&#34;images/1130_preprocess diagram-01.png&#34; width=&#34;1000&#34;&gt;&lt;/p&gt; &lt;p&gt;The traditional Urban Building Energy Modeling (UBEM) approach predominantly relies on archetype-based simulations, which generalize building characteristics and operational patterns to estimate energy demand across urban areas. While effective for large-scale assessments, these methods often overlook the influence of microclimatic conditions—such as localized air temperature, humidity, solar radiation, and wind flow—which can vary significantly across urban environments due to morphological heterogeneity. This simplification limits the accuracy of energy predictions, particularly in dense and diverse urban contexts where microclimate dynamics play a critical role in shaping building energy performance. Recent studies have underscored the importance of integrating microclimate factors into UBEM, noting that urban heat island intensity, surface radiation balance, and convective conditions can substantially alter thermal loads at the building level. However, the lack of standardized methods for extracting and quantifying microclimatic variables at scale has constrained their application in mainstream UBEM workflows. To address this gap, this research develops a standardized data pipeline to systematically construct urban-scale datasets that incorporate both building attributes and localized microclimate indicators. Leveraging this dataset, statistical modeling techniques are employed to evaluate the relative influence of various microclimatic factors on building energy consumption. This work not only enhances our understanding of the interplay between urban form, climate, and energy use, but also offers a methodological foundation for future data-driven UBEM studies seeking to improve predictive accuracy and inform resilient urban energy planning.&lt;/p&gt; &lt;h1 id=&#34;satellite-data-collection&#34;&gt;Satellite data collection&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The satellite data acquisition pipeline is adapted and enhanced from the methodological framework proposed in prior New York City studies (Dougherty &amp;amp; Jain, 2023). For each building, local environmental conditions are characterized within a 100 m radius to capture neighborhood-scale microclimatic influences. Specifically, the original building footprint is first simplified using a convex hull algorithm to reduce geometric complexity while preserving its spatial extent. A 100 m radial buffer is then generated around the convex hull to define the final sampling domain for microclimate feature extraction. Satellite-derived environmental variables with native spatial resolutions ranging from 10 m to 2.5 km are processed and resampled within Google Earth Engine to a unified 100 m spatial scale. This resampling strategy ensures spatial consistency across heterogeneous data sources and guarantees that each building-level buffer reliably captures representative pixel-level microclimate information. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Microclimate information&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We place particular emphasis on vegetation coverage in the surroundings of each building. In a previous study, we investigated the relationship between the urban tree canopy ratio and building energy consumption (Xu et al. 2025). In the present work, we adopt the Normalized Difference Vegetation Index (NDVI) as the primary indicator to characterize the greenness of the local built environment. Compared with canopy ratio metrics derived from land-cover classifications, NDVI offers a key advantage in its ability to explicitly capture seasonal variations in vegetation phenology, which is critical for subsequent analyses under representative summer and winter conditions. NDVI data are obtained from the ECOSTRESS Tiled Ancillary NDVI and Albedo L2 Global 70 m V002 product. &lt;/p&gt; &lt;p&gt;For integrated microclimatic conditions surrounding each building, including air temperature, humidity, and wind speed, we utilize data from RTMA (Real-Time Mesoscale Analysis), a high-resolution near-surface atmospheric analysis system provided by NOAA and generated through real-time data assimilation of surface observations and numerical weather prediction outputs. In addition, to characterize nocturnal urban activity and radiative intensity, which serve as indirect proxies for urban vitality and anthropogenic carbon emissions, we employ the VIIRS Stray Light Corrected Nighttime Day/Night Band Composites Version 1 product to extract nighttime radiance information. &lt;/p&gt; &lt;p&gt;Our completed dataset can be found &lt;a href=&#34;data/2025_1120_Microclimate%20data.xlsx&#34;&gt;here&lt;/a&gt;, and an introduction to each variable can be found &lt;a href=&#34;data/Mircoclimate%data%introduction.docx&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Sky view factor&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1 id=&#34;building-facade-data-collection&#34;&gt;Building facade data collection&lt;/h1&gt; &lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt; &lt;p&gt;Dougherty, T. R., &amp;amp; Jain, R. K. (2023). Invisible walls: Exploration of microclimate effects on building energy consumption in New York City. Sustainable Cities and Society, 90, 104364.&lt;/p&gt; &lt;p&gt;Xu, H., Li, C., Kastner, P., &amp;amp; Dogan, T. (2024) Understand Urban Building Energy Consumption with Explainable Machine Learning Approaches.&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=DCX57r3rBbM&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/DCX57r3rBbM/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Yichao Shi&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture (DC)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/SHIyichao98&#34;&gt;SHIyichao98&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hang Xu&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/HangXXXu&#34;&gt;HangXXXu&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jiayi Li&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jli3307&#34;&gt;jli3307&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Aryan Bolakond&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AryanBolakond&#34;&gt;AryanBolakond&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Breno Veiga&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/veigab3&#34;&gt;veigab3&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nishanth Giridharan&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/NishanthG05&#34;&gt;NishanthG05&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sameer Jain&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sameerjain06&#34;&gt;sameerjain06&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-energyinbuildings/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-energyinbuildings/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-energyinbuildings/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-energyinbuildings/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-MPONC</title> <description>&lt;h1 id=&#34;modeling-processes-of-neighborhood-change-mponc&#34;&gt;Modeling Processes of Neighborhood Change (MPONC)&lt;/h1&gt; &lt;h2 id=&#34;reference-paper&#34;&gt;Reference paper&lt;/h2&gt; &lt;div class=&#34;language-bibtex highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-0-1&#34;&gt;&lt;a id=&#34;__codelineno-0-1&#34; name=&#34;__codelineno-0-1&#34; href=&#34;#__codelineno-0-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nc&#34;&gt;@misc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;mori2024modelingprocessesneighborhoodchange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-2&#34;&gt;&lt;a id=&#34;__codelineno-0-2&#34; name=&#34;__codelineno-0-2&#34; href=&#34;#__codelineno-0-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{Modeling Processes of Neighborhood Change}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-3&#34;&gt;&lt;a id=&#34;__codelineno-0-3&#34; name=&#34;__codelineno-0-3&#34; href=&#34;#__codelineno-0-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{J. Carlos Martínez Mori and Zhanzhan Zhao}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-4&#34;&gt;&lt;a id=&#34;__codelineno-0-4&#34; name=&#34;__codelineno-0-4&#34; href=&#34;#__codelineno-0-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;year&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{2024}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-5&#34;&gt;&lt;a id=&#34;__codelineno-0-5&#34; name=&#34;__codelineno-0-5&#34; href=&#34;#__codelineno-0-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;eprint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{2401.03307}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-6&#34;&gt;&lt;a id=&#34;__codelineno-0-6&#34; name=&#34;__codelineno-0-6&#34; href=&#34;#__codelineno-0-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;archivePrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{arXiv}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-7&#34;&gt;&lt;a id=&#34;__codelineno-0-7&#34; name=&#34;__codelineno-0-7&#34; href=&#34;#__codelineno-0-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;primaryClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{cs.MA}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-8&#34;&gt;&lt;a id=&#34;__codelineno-0-8&#34; name=&#34;__codelineno-0-8&#34; href=&#34;#__codelineno-0-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;na&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;{https://arxiv.org/abs/2401.03307}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-0-9&#34;&gt;&lt;a id=&#34;__codelineno-0-9&#34; name=&#34;__codelineno-0-9&#34; href=&#34;#__codelineno-0-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt; &lt;div class=&#34;language-bash highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-1-1&#34;&gt;&lt;a id=&#34;__codelineno-1-1&#34; name=&#34;__codelineno-1-1&#34; href=&#34;#__codelineno-1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;25Sp-MPONC/modeling_processes_of_neighborhood_change_new &lt;/span&gt;&lt;span id=&#34;__span-1-2&#34;&gt;&lt;a id=&#34;__codelineno-1-2&#34; name=&#34;__codelineno-1-2&#34; href=&#34;#__codelineno-1-2&#34;&gt;&lt;/a&gt;conda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;create&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-n&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;mponc&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;.10.16 &lt;/span&gt;&lt;span id=&#34;__span-1-3&#34;&gt;&lt;a id=&#34;__codelineno-1-3&#34; name=&#34;__codelineno-1-3&#34; href=&#34;#__codelineno-1-3&#34;&gt;&lt;/a&gt;conda&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;activate&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;mponc &lt;/span&gt;&lt;span id=&#34;__span-1-4&#34;&gt;&lt;a id=&#34;__codelineno-1-4&#34; name=&#34;__codelineno-1-4&#34; href=&#34;#__codelineno-1-4&#34;&gt;&lt;/a&gt;pip&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-r&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;requirements.txt &lt;/span&gt;&lt;span id=&#34;__span-1-5&#34;&gt;&lt;a id=&#34;__codelineno-1-5&#34; name=&#34;__codelineno-1-5&#34; href=&#34;#__codelineno-1-5&#34;&gt;&lt;/a&gt;python&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;main.py &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt; &lt;blockquote&gt; &lt;p&gt;This research project simulates the impact of the Atlanta Beltline on the surrounding neighborhoods using no-regret-dynamics game theory. The simulation models agent movement across census tracts within Atlanta, GA&#39;s Fulton and Dekalb counties, with agents seeking to move optimally (prioritizing real-life incentives) based on several census tract attributes.&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id=&#34;intro-and-description&#34;&gt;Intro and Description&lt;/h2&gt; &lt;p&gt;This project is based on the reference paper created by Dr. Martinez and Dr. Zhao, which aims to address the following: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;How does the layout of transportation infrastructure affect the demographics of nearby neighborhoods? &lt;/li&gt; &lt;li&gt;Does the creation of these infrastructure actually benefit everyone equally; is it fair? &lt;/li&gt; &lt;li&gt;Can we predict the effects on surrounding communities before these structures are actually built? &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These questions are primarily motivated by the issue of gentrification, an issue prevalent in many major cities. We utilized concepts in game theory, more specifically no-regret dynamics, in order to simulate the effects of the Atlanta Beltline on gentrification. To summarize our approach with no-regret dynamics:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;People, or &#39;agents&#39;, repeatedly select census tracts for relocation, from an initially uniform probability distribution. Computed from the tract&#39;s attributes, a &lt;strong&gt;&#39;cost&#39;&lt;/strong&gt; value is assigned to the taken action, and the agent negates this cost from the chosen tract&#39;s selection probability. &lt;/li&gt; &lt;li&gt;&lt;em&gt;&#39;Cost&#39; is a function of region affordability, upkeep, and attractiveness.&lt;/em&gt; &lt;/li&gt; &lt;li&gt;The higher the cost, the less likely an agent is to visit that census tract in the future. &lt;/li&gt; &lt;li&gt;This process is repeated until the probability distribution of visting census tracts converges - an equilibrium is reached, and agents have successfully &#39;learned&#39; the attractiveness of each tract. Further actions make negligible difference to the probability distribution. &lt;/li&gt; &lt;li&gt;This semester, we have changed the way we compute simulation convergence by using the &lt;em&gt;maximum best-action regret&lt;/em&gt; across all agents between two sliding windows of recent agent‑distributions: &lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ r = \frac{1}{T} \big(\sum_{t = 1}^{T} c_t(a_t) - \sum_{t = 1}^{T} c_t(a_t^*) \big) \]&lt;/div&gt; &lt;p&gt;where &lt;span class=&#34;arithmatex&#34;&gt;\(c_t(a_t)\)&lt;/span&gt; denotes the cost of action &lt;span class=&#34;arithmatex&#34;&gt;\(a_t\)&lt;/span&gt; and &lt;span class=&#34;arithmatex&#34;&gt;\(a_t^*\)&lt;/span&gt; is the optimal action in hindsight at timestep &lt;span class=&#34;arithmatex&#34;&gt;\(t\)&lt;/span&gt;. If &lt;span class=&#34;arithmatex&#34;&gt;\(r ≤ \epsilon\)&lt;/span&gt; (default = 0.01) the system is deemed converged and the run halts automatically. All thresholds are configurable in &lt;code&gt;config.py&lt;/code&gt;. - For practical purposes, an upper limit of &lt;span class=&#34;arithmatex&#34;&gt;\(T = \frac{4 \ln{A}}{\epsilon^2}\)&lt;/span&gt; timesteps is set for each simulation, where &lt;span class=&#34;arithmatex&#34;&gt;\(A\)&lt;/span&gt; is the size of the action space. &lt;/p&gt; &lt;h2 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h2&gt; &lt;p&gt;Every agent evaluates a tract with a cost defined as&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;cost = 1 – (affordability × upkeep x attractiveness)&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Factor&lt;/th&gt; &lt;th&gt;Scale&lt;/th&gt; &lt;th&gt;Quick intuition&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Affordability&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0 or 1&lt;/td&gt; &lt;td&gt;1 if the tract still has room &lt;em&gt;or&lt;/em&gt; the agent is selected from an income-weighted lottery when the tract is overpopulated; 0 otherwise.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Upkeep&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;How “maintained” and inhabited the tract is, based on the fraction of its resident capacity currently filled.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Attractiveness&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;How nice the tract is to live in, combining amenity access and community similarity (see sub-components below).&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h3 id=&#34;attractiveness-upkeep-amenity_access-beltline_factor&#34;&gt;Attractiveness = upkeep × amenity_access × beltline_factor&lt;/h3&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Sub‑component&lt;/th&gt; &lt;th&gt;Range&lt;/th&gt; &lt;th&gt;What it captures&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Amenity access&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;Density of key POIs (restaurants, shops, transit stops, etc.), spatially smoothed over neighbouring tracts and modified by BeltLine factor β.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Community&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;0–1&lt;/td&gt; &lt;td&gt;How well an agent’s income matches incomes in the surrounding tracts—closer ⇒ higher score.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;BeltLine factor β&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;≥ 1&lt;/td&gt; &lt;td&gt;Extra accessibility for tracts in the BeltLine catchment area: β = B (max boost) on the BeltLine, tapering linearly down to 1 at radius R, and staying 1 outside R.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;* Amenity list adapted from &lt;strong&gt;&lt;a href=&#34;https://vip-smur.github.io/24sp-mobility-seg/&#34;&gt;24Sp‑Mobility‑Seg&lt;/a&gt;&lt;/strong&gt;; we omit several tags such as “shed”, “guardhouse”, “ferry_terminal”, “garages”, and “bridge”.&lt;/p&gt; &lt;h3 id=&#34;spatial-smoothing-of-amenity-data&#34;&gt;Spatial Smoothing of Amenity Data&lt;/h3&gt; &lt;p&gt;To ensure that the amenity component of a tract&#39;s Attractiveness score accurately reflects the &lt;em&gt;true&lt;/em&gt; environment and facilitates realistic agent decision-making, we employ a spatial smoothing strategy. Direct raw counts from OpenStreetMap (OSM) frequently register zero amenities in certain census tracts. Allowing these zero values to persist would be misleading, as agents rarely perceive their neighborhood&#39;s amenities as strictly limited to their immediate tract boundary; instead, they consider nearby shops, parks, and transit.&lt;/p&gt; &lt;p&gt;To counteract this data sparsity and noise, we use &lt;strong&gt;Queen contiguity weights&lt;/strong&gt; to define the neighborhood structure. This definition is inclusive, considering two tracts to be neighbors if they share any common border &lt;em&gt;or&lt;/em&gt; a single corner point. Leveraging the PySAL library, we then compute a &lt;strong&gt;spatial lag&lt;/strong&gt; on the raw amenity densities. Conceptually, this process calculates a weighted average for each tract&#39;s amenity score, blending its own raw density with the densities of all its Queen-contiguous neighbors. This produces a smoothed, more plausible amenity distribution across the region, which is essential for governing agents&#39; relocation decisions and ultimately modeling gentrification dynamics accurately.&lt;/p&gt; &lt;h4 id=&#34;implemented-amenities-weights-openstreetmap-labels&#34;&gt;Implemented Amenities &amp;amp; weights (OpenStreetMap labels):&lt;/h4&gt; &lt;p&gt;&lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-2-1&#34;&gt;&lt;a id=&#34;__codelineno-2-1&#34; name=&#34;__codelineno-2-1&#34; href=&#34;#__codelineno-2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;AMENITY_TAGS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-2&#34;&gt;&lt;a id=&#34;__codelineno-2-2&#34; name=&#34;__codelineno-2-2&#34; href=&#34;#__codelineno-2-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;amenity&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;bus_station|cafe|college|fast_food|food_court|fuel|library|restaurant|train_station|university|parking|school|hospital&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-3&#34;&gt;&lt;a id=&#34;__codelineno-2-3&#34; name=&#34;__codelineno-2-3&#34; href=&#34;#__codelineno-2-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;shop&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;supermarket|food|general|department_store|mall|wholesale&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-4&#34;&gt;&lt;a id=&#34;__codelineno-2-4&#34; name=&#34;__codelineno-2-4&#34; href=&#34;#__codelineno-2-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;landuse&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;residential|industrial|commercial|retail&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-2-5&#34;&gt;&lt;a id=&#34;__codelineno-2-5&#34; name=&#34;__codelineno-2-5&#34; href=&#34;#__codelineno-2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; * We operationalize &lt;strong&gt;β&lt;/strong&gt; by giving tracts within &lt;strong&gt;800 m&lt;/strong&gt; of the BeltLine a &lt;strong&gt;+20 %&lt;/strong&gt; boost to their Attractiveness score (β = 1.20/1.20); the boost then tapers linearly to &lt;strong&gt;+10 %&lt;/strong&gt; at &lt;strong&gt;1.6 km&lt;/strong&gt;, and falls to β = 1.00/1.20 beyond that distance. This &lt;strong&gt;β&lt;/strong&gt; is applied as an exponent: each tract’s amenity density is raised to the power &lt;span class=&#34;arithmatex&#34;&gt;\(1/β_c\)&lt;/span&gt;. This provides a stronger &lt;em&gt;relative&lt;/em&gt; boost to low-amenity tracts and milder gains for amenity-rich tracts, approximating the diminishing-returns effect of BeltLine’s observed proximity on nearby housing prices.&lt;/p&gt; &lt;h3 id=&#34;community-score-local-morans-i&#34;&gt;Community Score (Local Moran’s I)&lt;/h3&gt; &lt;p&gt;Due to the difficulties with Moran&#39;s, we are using a simplified implementation of the Community Score calculation. Community ties &lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\((Community_a(c))\)&lt;/span&gt;\)&lt;/span&gt; model socioeconomic affinity by measuring how closely a specific agent&#39;s endowment matches the endowments of nearby agents. For each agent, we compute a community endowment defined as the mean income of the tract the agent currently occupies along with all tracts adjacent to it. The model uses PySAL to calculate the average income of the tract and its neighbors for whichever year is selected.&lt;/p&gt; &lt;p&gt;The community endowment is computed as:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \bar{E}_c = \frac{1}{N_c} \sum_{i \in \{c \cup \text{Neighbors}(c)\}} E_i \]&lt;/div&gt; &lt;p&gt;The agent’s community-tie value is then calculated as the difference between the agent’s own endowment and this community endowment:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ \mathrm{Community}_a(c) = E_a - \bar{E}_c \]&lt;/div&gt; &lt;p&gt;Agents whose incomes closely match the incomes of their surrounding tracts receive stronger community-tie scores, while those whose incomes differ substantially receive weaker ties. A closer match ⇒ value near 1 ⇒ lower cost.&lt;/p&gt; &lt;p&gt;For a deep explanation of how Moran&#39;s works, why it isn&#39;t implemented into the paper yet, and the next steps, please see the Spatial Autocorrelation portion of the readme.&lt;/p&gt; &lt;h3 id=&#34;weighting-amenity-access-vs-community&#34;&gt;Weighting amenity access vs community (λ)&lt;/h3&gt; &lt;p&gt;A tunable parameter &lt;strong&gt;λ ∈ [0, 1]&lt;/strong&gt; lets you emphasize either amenity access (high λ) or community match (low λ).&lt;br /&gt; Internally we rewrite&lt;br /&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-3-1&#34;&gt;&lt;a id=&#34;__codelineno-3-1&#34; name=&#34;__codelineno-3-1&#34; href=&#34;#__codelineno-3-1&#34;&gt;&lt;/a&gt;cost = 1 - [[Affordability] × [Upkeep x (λ × AmenityAccess)] × [(1-λ) × Community]] &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt; &lt;h3 id=&#34;tigerline-geodatabases-shapefiles&#34;&gt;TIGER/Line Geodatabases shapefiles:&lt;/h3&gt; &lt;p&gt;&lt;img src=&#34;./Figures/ZIP_URLs.png&#34; alt=&#34;Alt text&#34; max-width=&#34;600&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;project-status&#34;&gt;Project status&lt;/h2&gt; &lt;h3 id=&#34;outputs-configuration&#34;&gt;Outputs &amp;amp; configuration&lt;/h3&gt; &lt;p&gt;Our code outputs a GIF to visualize agent behavior over time. Each circle represents the centroid of a census tract - green signifying those in the Atlanta Beltline - and the encircled number is the agent population. Our code also outputs a CSV file containing all the simulated data at every individual timestep.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;Data contained in CSV&#39;s: Census tract name, agent population, raw average income, average income reported by census, normalized average incomes, and amenity density.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;Note: &#39;Timestep&#39; refers to a single instance agent action (relocation); 20,000 timesteps mean the agents relocate a total of 20,000 times during the simulation.&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h4 id=&#34;gif&#34;&gt;GIF&lt;/h4&gt; &lt;p&gt;This GIF shows the behavior of 1,000 agents up to 20,000 timesteps, frames being captured every 400 timesteps. Rho=1, alpha=0.25. &lt;img src=&#34;./Figures/SimulationGIF2025.gif&#34; alt=&#34;Alt text&#34; max-width=&#34;600&#34; /&gt;&lt;/p&gt; &lt;h3 id=&#34;runtimes&#34;&gt;Runtimes&lt;/h3&gt; &lt;blockquote&gt; &lt;p&gt;(1000 agents, 349 census tracts) - Simulation: 3 min * Graph, amenities, and centroids are cached after first build&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id=&#34;census-based-approach&#34;&gt;Census-based approach&lt;/h2&gt; &lt;p&gt;Our project utilizes US Census data in that: - The geographical regions our agents inhabit correspond directly to US census tracts (can correspond to any other census-defined geographic unit, i.e. zip codes, housing districts, and school districts). - Each &#39;agent&#39; is assigned a &#39;wealth&#39; value in our simulation. We create this distribution of wealth using Census data (population &amp;amp; median incomes), to represent real-world demographics.&lt;/p&gt; &lt;h2 id=&#34;atlanta-beltline-in-our-simulation&#34;&gt;Atlanta Beltline in our Simulation&lt;/h2&gt; &lt;p&gt;We automate the process of labelling certain regions as &#39;within the Atlanta Beltline&#39;s catchment zone&#39; by using commuting paths from OpenStreetMap that correspond to the Atlanta Beltline - namely, a bike trail and a railway. To experiment with a different beltline, such as a beltline that spanned across Atlanta horizontally, or simply expanded north by x miles, we would acquire the OpenStreetMap ID&#39;s of existing paths (bike trails, walking paths, roads, etc.) corresponding to our desired Beltline, and paste these into &lt;strong&gt;config.py&lt;/strong&gt;. Alternatively, we can create a such path ourselves in OpenStreetMap. Then, any region containing segments of these trails would automatically receive a &#34;Beltline Score&#34; which boosts its perceived attractiveness by agents. &lt;/p&gt; &lt;p&gt;In &lt;strong&gt;config.py&lt;/strong&gt; - bike trail and railroad OpenStreetMap ID&#39;s for the beltline are as follows:&lt;/p&gt; &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-4-1&#34;&gt;&lt;a id=&#34;__codelineno-4-1&#34; name=&#34;__codelineno-4-1&#34; href=&#34;#__codelineno-4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;sd&#34;&gt;&amp;quot;&amp;quot;&amp;quot; Beltline &amp;#39;relation&amp;#39; IDs from Open Street Map &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-4-2&#34;&gt;&lt;a id=&#34;__codelineno-4-2&#34; name=&#34;__codelineno-4-2&#34; href=&#34;#__codelineno-4-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;RELATION_IDS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8408433&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;13048389&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th style=&#34;text-align: center;&#34;&gt;Bike Trail&lt;/th&gt; &lt;th style=&#34;text-align: center;&#34;&gt;Railroad&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td style=&#34;text-align: center;&#34;&gt;&lt;img src=&#34;./Figures/BeltlineBikeTrail.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &lt;td style=&#34;text-align: center;&#34;&gt;&lt;img src=&#34;./Figures/BeltlineRailroad.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Compare with Atlanta Beltline geography:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;./Figures/AtlantaBeltlineVisual.jpg&#34; width=&#34;250&#34;&gt;&lt;/p&gt; &lt;h2 id=&#34;adapting-the-model-to-other-cities&#34;&gt;Adapting the Model to Other Cities&lt;/h2&gt; &lt;p&gt;Although Atlanta serves as our case study, every pipeline stage—census shapefiles, OSM‑derived amenities, cost parameters, and even the BeltLine decision‑agent—can be swapped for a different region:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Geometry &amp;amp; Demographics&lt;/strong&gt;&lt;br /&gt; • Replace the Fulton/DeKalb TIGER/Line shapefiles with those of your target city.&lt;br /&gt; • Point the &lt;code&gt;MEDIAN_INCOME_URL&lt;/code&gt; and &lt;code&gt;POP_URL&lt;/code&gt; in &lt;code&gt;config.py&lt;/code&gt; to that city’s American Community Survey &#34;ACS&#34; tables.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transit‑Ring Definition&lt;/strong&gt;&lt;br /&gt; • Identify (or sketch in OSM) the planned loop / BRT corridor / rail spur you want to study, then list its OSM relation IDs in &lt;code&gt;config.py&lt;/code&gt;.&lt;br /&gt; • The same β‑taper and DecisionAgent logic will assign accessibility boosts and density bonuses around the new corridor.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Policy Levers&lt;/strong&gt;&lt;br /&gt; • Tweak &lt;code&gt;RHO_SCALAR&lt;/code&gt; to explore how strong the up‑zoning response should be for the above transit ring.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Because the simulation is purely data‑driven, you can rapidly prototype “what‑if” BeltLine analogues for &lt;strong&gt;anywhere with open census and OSM data while measuring potential community shifts/gentrification before shovels hit the ground.&lt;/strong&gt; Example: &lt;img src=&#34;./Figures/OldZipURL.png&#34; alt=&#34;Alt text&#34; max-width=&#34;600&#34; /&gt; * By changing the above URL, we get the following:&lt;/p&gt; &lt;p&gt;&lt;img src=&#34;./Figures/AtlantaBeltlineCloseupGraph.png&#34; alt=&#34;Alt text&#34; width=&#34;250&#34; /&gt;&lt;/p&gt; &lt;h2 id=&#34;policy-scenarios-vertical-vs-horizontal-scaling&#34;&gt;Policy Scenarios: Vertical vs Horizontal Scaling&lt;/h2&gt; &lt;p&gt;The simulation now supports two high-level policy experiments:&lt;/p&gt; &lt;h3 id=&#34;1-vertical-scaling-decision-making-agent-learns-kappa&#34;&gt;1. Vertical Scaling — Decision-Making Agent learns &lt;span class=&#34;arithmatex&#34;&gt;\(\kappa\)&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;A dedicated &lt;code&gt;DecisionAgent&lt;/code&gt; treats &lt;strong&gt;how aggressively to expand housing capacity near the Beltline&lt;/strong&gt; as a no-regret learning problem:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Action space&lt;/strong&gt;: &lt;span class=&#34;arithmatex&#34;&gt;\( \kappa \in \{0.00, 0.01, \dots, 1.00\} \)&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;sampled each timestep by multiplicative‑weights (no‑regret-dynamics).&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Base capacity curve&lt;/strong&gt;:&lt;br&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-5-1&#34;&gt;&lt;a id=&#34;__codelineno-5-1&#34; name=&#34;__codelineno-5-1&#34; href=&#34;#__codelineno-5-1&#34;&gt;&lt;/a&gt;U_c = 1 + \frac{\texttt{beltline\_score}_c - \texttt{BL\_LOW}}{\texttt{BL\_HIGH} - \texttt{BL\_LOW}} \times \bigl(\texttt{RHO\_SCALAR}_{max} - 1\bigr) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h4 id=&#34;effective-multiplier&#34;&gt;Effective multiplier&lt;/h4&gt; &lt;div class=&#34;language-text highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-6-1&#34;&gt;&lt;a id=&#34;__codelineno-6-1&#34; name=&#34;__codelineno-6-1&#34; href=&#34;#__codelineno-6-1&#34;&gt;&lt;/a&gt;\rho_c^{\text{new}} &lt;/span&gt;&lt;span id=&#34;__span-6-2&#34;&gt;&lt;a id=&#34;__codelineno-6-2&#34; name=&#34;__codelineno-6-2&#34; href=&#34;#__codelineno-6-2&#34;&gt;&lt;/a&gt; = \rho_c^{\text{base}} &lt;/span&gt;&lt;span id=&#34;__span-6-3&#34;&gt;&lt;a id=&#34;__codelineno-6-3&#34; name=&#34;__codelineno-6-3&#34; href=&#34;#__codelineno-6-3&#34;&gt;&lt;/a&gt; \times &lt;/span&gt;&lt;span id=&#34;__span-6-4&#34;&gt;&lt;a id=&#34;__codelineno-6-4&#34; name=&#34;__codelineno-6-4&#34; href=&#34;#__codelineno-6-4&#34;&gt;&lt;/a&gt; \left[1 + \kappa\,M_c\right] &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;where &lt;span class=&#34;arithmatex&#34;&gt;\(M_c\)&lt;/span&gt; is the &lt;strong&gt;maximum permissible percent increase&lt;/strong&gt; for tract &lt;span class=&#34;arithmatex&#34;&gt;\(c\)&lt;/span&gt; based on distance to the Beltline.&lt;/p&gt; &lt;p&gt;Two alternative utility metrics guide learning:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;code&gt;UTILITY_METRIC&lt;/code&gt;&lt;/th&gt; &lt;th&gt;Algorithm maximises&lt;/th&gt; &lt;th&gt;Real‑world analogy&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;0&lt;/code&gt; &lt;em&gt;(default)&lt;/em&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;average utility&lt;/strong&gt; (mean well‑being across all agents)&lt;/td&gt; &lt;td&gt;“Greatest good for the greatest number.”&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;minimum utility&lt;/strong&gt; (well‑being of the worst‑off agent)&lt;/td&gt; &lt;td&gt;Rawlsian / max‑min fairness.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The DecisionAgent reinforces actions that raise the chosen utility, gradually converging to an ideal &lt;em&gt;m&lt;/em&gt; for the current policy goal. &lt;/p&gt; &lt;p&gt;These “concrete zoning‑bonus percentages and distance bands” are the literal numbers (+20 %, +10 %, 800 m, 1600 m) encoded in &lt;code&gt;DecisionAgent.py&lt;/code&gt;. Feel free to edit them in &lt;code&gt;config.py&lt;/code&gt;.&lt;/p&gt; &lt;h3 id=&#34;2-horizontal-scaling-complete-beltline-from-day-0&#34;&gt;2. Horizontal Scaling (complete BeltLine from day 0)&lt;/h3&gt; &lt;p&gt;All census tracts whose centroids fall inside the Beltline’s catchment radius begin with &lt;strong&gt;β_c &amp;gt; 1&lt;/strong&gt;, following the same taper function used in the baseline model.&lt;br /&gt; Unlike vertical scaling, &lt;strong&gt;capacities do not change&lt;/strong&gt;—only the geography of Beltline-induced accessibility (amenity-attractiveness) changes.&lt;/p&gt; &lt;p&gt;This models a scenario where the entire Beltline loop has been completed.&lt;/p&gt; &lt;h2 id=&#34;strengths-and-weaknesses&#34;&gt;Strengths and Weaknesses&lt;/h2&gt; &lt;h3 id=&#34;strengths&#34;&gt;Strengths&lt;/h3&gt; &lt;p&gt;Our approach is very modularized. For instance, our code can easily be ran on other regions, with customizable &#39;Beltlines&#39; and parameters. Furthermore, Our approach is backed by established human behavior approaches (no-regret dynamics) rather than pre-defined, non-adaptive agent behavior. We are also able to produce dynamic visuals (GIFs).&lt;/p&gt; &lt;h3 id=&#34;weaknesses&#34;&gt;Weaknesses&lt;/h3&gt; &lt;p&gt;Our simulation also assumes that there is no immigration/emigration in Atlanta, as we set a fixed number of agents which are able to exit, and hence re-enter, our defined area. We also limit transportation choices to cars and public transportation, despite other modes of transport being popular (walking or biking). Additionally, our runtimes may be relatively long due to the computationally expensive nature of the simulation (several minutes). Ideally, our simulation would be ran in just seconds.&lt;/p&gt; &lt;h3 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h3&gt; &lt;p&gt;We hope to improve the readability of our GIF&#39;s, improve the runtime of the simulation, and include additional visualizations of our results to better communicate our analysis during discussion. We also hope to run SOBOL sensitivity nalysis of our parameters once more.&lt;/p&gt; &lt;h1 id=&#34;spatial-autocorrelation&#34;&gt;Spatial Autocorrelation&lt;/h1&gt; &lt;p&gt;This section serves as an explanation for the conceptual and applied framework for spatial autocorrelation in the MPONC simulation. I will begin by explaining the concepts necessary to understand spatial autocorrelation, specifically for Local Moran&#39;s I. It&#39;s important to understand that spatial autocorrelation is used to calculate the community score and if you are unsure what community score represents or the justification for it, then see the general readME. This readme is speficially for community score&#39;s implementation. &lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;the-math&#34;&gt;The Math&lt;/h2&gt; &lt;h3 id=&#34;local-morans-i&#34;&gt;Local Moran&#39;s I&lt;/h3&gt; &lt;p&gt;Spatial Autocorrelation is a geographic concept for finding clusters of similarity or dissimilarity in geographic data. The most common formula is &lt;strong&gt;Local Moran&#39;s I&lt;/strong&gt;:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ I_i = \frac{(x_i - \bar{x})}{m_2} \sum_{j=1}^{n} w_{ij} (x_j - \bar{x}) \]&lt;/div&gt; &lt;p&gt;Where:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\( x_i \)\)&lt;/span&gt;: value of the variable at location &lt;em&gt;i&lt;/em&gt; (agent endowments)&lt;/li&gt; &lt;li&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\( \bar{x} \)\)&lt;/span&gt;: mean of all &lt;span class=&#34;arithmatex&#34;&gt;\( x \)&lt;/span&gt; values (average endowments of all agents)&lt;/li&gt; &lt;li&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\( w_{ij} \)\)&lt;/span&gt;: spatial weight between locations &lt;em&gt;i&lt;/em&gt; and &lt;em&gt;j&lt;/em&gt; (morans weights)&lt;/li&gt; &lt;li&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\( n \)\)&lt;/span&gt;: total number of observations&lt;/li&gt; &lt;li&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(\( m_2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2 \)\)&lt;/span&gt;: variance normalization term&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span class=&#34;arithmatex&#34;&gt;\(&lt;span class=&#34;arithmatex&#34;&gt;\(I_i\)&lt;/span&gt;\)&lt;/span&gt; represents the value of morans for the specific agent. In our case, we can obtain the &#34;community score&#34; by calculating the local moran&#39;s value for that agent and normalizing this value to be between 0 and 1. While this formula is how Moran&#39;s I runs, our simulation uses esda.local_moran, instead of manually implementing the math. In order to do this, we need to form our own weights value and way of tracking endowments for each agent to give to esda. &lt;strong&gt;Importantly, the weights matrix is per census tract and represents the weights between census tracts, while agent endowments are per agent.&lt;/strong&gt;&lt;/p&gt; &lt;h3 id=&#34;neighbors&#34;&gt;Neighbors&lt;/h3&gt; &lt;p&gt;In the pure mathematical form of Local Moran&#39;s I, every node is compared with every other node in the set. However, this is computationally expensive and also causes odd behavior around edges (see Appendix A). The common alternate approach is to only consider neighbors. So if a census tract is touching 6 other census tracts, then that tract has 6 neighbors to compare with and effectively only those 6 neighbors impact the agent&#39;s community score. Another common approach is to use decay over the entire set of nodes. So every node is a “neighbor,” but the Moran’s weights reflect that closer neighbors have a stronger impact on the community of a node.&lt;/p&gt; &lt;p&gt;For our simulation we use a K-nearest neighbors approach, which sets a fixed set of neighbors - that we can configure for each simulation - and then uses decay. So if we set neighbors to 20, then the closest 20 nodes are neighbors with the closer ones counting more. We chose this because it’s much faster than a full decay (with full decay you have to iterate over 500 nodes for every moran’s calculation for each node), but reflects that people’s perception of their neighborhood extends further than 10-20 minutes away from them. The decay should remain high.&lt;/p&gt; &lt;h3 id=&#34;normalization&#34;&gt;Normalization&lt;/h3&gt; &lt;p&gt;Normalization is important for local morans because the raw values for morans can vary without range. They often are negative and they are not constrained to any range. Community score, however, does need to be constrained from 0 to 1. Therefore, we need a way to constrain our morans values to between 0 and 1. &lt;/p&gt; &lt;p&gt;Our original approach was to use z-score-to-cdf. This means we first take the morans values we calculate and perform a z-score normalization (this is standard in statistics) and then map those values to [0,1] using CDF which conceptually is like saying “this is the 90&lt;sup&gt;th&lt;/sup&gt; percentile value in our simulation so the value is really 0.9”. The issue with this was that it causes more extreme values if the moran’s values have a low standard deviation. &lt;/p&gt; &lt;p&gt;The new approach is to use a direct mapping after z-score. The equation for that is simply:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ p_i = \frac{z_i - \min(z)}{\max(z) - \min(z)} \]&lt;/div&gt; &lt;p&gt;&lt;strong&gt;IMPORTANT, this is currently not reflected in the main branch of the code. We’ll need to update this if we go back to moran’s&lt;/strong&gt;&lt;/p&gt; &lt;h2 id=&#34;the-simulation&#34;&gt;The Simulation&lt;/h2&gt; &lt;h2 id=&#34;morans_analysispy&#34;&gt;Morans_analysis.py&lt;/h2&gt; &lt;p&gt;Let’s go through the code one section at a time to review the design principles. &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-7-1&#34;&gt;&lt;a id=&#34;__codelineno-7-1&#34; name=&#34;__codelineno-7-1&#34; href=&#34;#__codelineno-7-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;_library_spatial_autocorrelation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-2&#34;&gt;&lt;a id=&#34;__codelineno-7-2&#34; name=&#34;__codelineno-7-2&#34; href=&#34;#__codelineno-7-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Prefer tract-level Moran&amp;#39;s weights stored on the city (centroid-level).&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-3&#34;&gt;&lt;a id=&#34;__codelineno-7-3&#34; name=&#34;__codelineno-7-3&#34; href=&#34;#__codelineno-7-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# If not present, build weights from cached distances below.&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-4&#34;&gt;&lt;a id=&#34;__codelineno-7-4&#34; name=&#34;__codelineno-7-4&#34; href=&#34;#__codelineno-7-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;getattr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;quot;morans_weights&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-5&#34;&gt;&lt;a id=&#34;__codelineno-7-5&#34; name=&#34;__codelineno-7-5&#34; href=&#34;#__codelineno-7-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;agent_endowments&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agt_dows&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-6&#34;&gt;&lt;a id=&#34;__codelineno-7-6&#34; name=&#34;__codelineno-7-6&#34; href=&#34;#__codelineno-7-6&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-7&#34;&gt;&lt;a id=&#34;__codelineno-7-7&#34; name=&#34;__codelineno-7-7&#34; href=&#34;#__codelineno-7-7&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-8&#34;&gt;&lt;a id=&#34;__codelineno-7-8&#34; name=&#34;__codelineno-7-8&#34; href=&#34;#__codelineno-7-8&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# If city provides a tract-level numpy matrix, convert to libpysal W&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-9&#34;&gt;&lt;a id=&#34;__codelineno-7-9&#34; name=&#34;__codelineno-7-9&#34; href=&#34;#__codelineno-7-9&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;isinstance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ndarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-10&#34;&gt;&lt;a id=&#34;__codelineno-7-10&#34; name=&#34;__codelineno-7-10&#34; href=&#34;#__codelineno-7-10&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isfinite&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-11&#34;&gt;&lt;a id=&#34;__codelineno-7-11&#34; name=&#34;__codelineno-7-11&#34; href=&#34;#__codelineno-7-11&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;nan_positions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isfinite&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-12&#34;&gt;&lt;a id=&#34;__codelineno-7-12&#34; name=&#34;__codelineno-7-12&#34; href=&#34;#__codelineno-7-12&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;ValueError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;Found non-finite values in tract-level weights matrix at positions: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nan_positions&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-13&#34;&gt;&lt;a id=&#34;__codelineno-7-13&#34; name=&#34;__codelineno-7-13&#34; href=&#34;#__codelineno-7-13&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# build weights_dict expected by libpysal.W&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-14&#34;&gt;&lt;a id=&#34;__codelineno-7-14&#34; name=&#34;__codelineno-7-14&#34; href=&#34;#__codelineno-7-14&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;weights_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-15&#34;&gt;&lt;a id=&#34;__codelineno-7-15&#34; name=&#34;__codelineno-7-15&#34; href=&#34;#__codelineno-7-15&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-16&#34;&gt;&lt;a id=&#34;__codelineno-7-16&#34; name=&#34;__codelineno-7-16&#34; href=&#34;#__codelineno-7-16&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-17&#34;&gt;&lt;a id=&#34;__codelineno-7-17&#34; name=&#34;__codelineno-7-17&#34; href=&#34;#__codelineno-7-17&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tract_W_mat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-18&#34;&gt;&lt;a id=&#34;__codelineno-7-18&#34; name=&#34;__codelineno-7-18&#34; href=&#34;#__codelineno-7-18&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;neigh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-19&#34;&gt;&lt;a id=&#34;__codelineno-7-19&#34; name=&#34;__codelineno-7-19&#34; href=&#34;#__codelineno-7-19&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;weights_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neigh&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-20&#34;&gt;&lt;a id=&#34;__codelineno-7-20&#34; name=&#34;__codelineno-7-20&#34; href=&#34;#__codelineno-7-20&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;w_obj&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weights_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-21&#34;&gt;&lt;a id=&#34;__codelineno-7-21&#34; name=&#34;__codelineno-7-21&#34; href=&#34;#__codelineno-7-21&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;w_obj&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;quot;r&amp;quot;&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-22&#34;&gt;&lt;a id=&#34;__codelineno-7-22&#34; name=&#34;__codelineno-7-22&#34; href=&#34;#__codelineno-7-22&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w_obj&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-23&#34;&gt;&lt;a id=&#34;__codelineno-7-23&#34; name=&#34;__codelineno-7-23&#34; href=&#34;#__codelineno-7-23&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-24&#34;&gt;&lt;a id=&#34;__codelineno-7-24&#34; name=&#34;__codelineno-7-24&#34; href=&#34;#__codelineno-7-24&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-25&#34;&gt;&lt;a id=&#34;__codelineno-7-25&#34; name=&#34;__codelineno-7-25&#34; href=&#34;#__codelineno-7-25&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-26&#34;&gt;&lt;a id=&#34;__codelineno-7-26&#34; name=&#34;__codelineno-7-26&#34; href=&#34;#__codelineno-7-26&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-27&#34;&gt;&lt;a id=&#34;__codelineno-7-27&#34; name=&#34;__codelineno-7-27&#34; href=&#34;#__codelineno-7-27&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_distances&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-28&#34;&gt;&lt;a id=&#34;__codelineno-7-28&#34; name=&#34;__codelineno-7-28&#34; href=&#34;#__codelineno-7-28&#34;&gt;&lt;/a&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_distances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;neighbors.npy&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mmap_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-29&#34;&gt;&lt;a id=&#34;__codelineno-7-29&#34; name=&#34;__codelineno-7-29&#34; href=&#34;#__codelineno-7-29&#34;&gt;&lt;/a&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;[MoransAnalyzer] Loaded cached centroid distances for &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_distances&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; centroids&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-30&#34;&gt;&lt;a id=&#34;__codelineno-7-30&#34; name=&#34;__codelineno-7-30&#34; href=&#34;#__codelineno-7-30&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-31&#34;&gt;&lt;a id=&#34;__codelineno-7-31&#34; name=&#34;__codelineno-7-31&#34; href=&#34;#__codelineno-7-31&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_KNN&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-32&#34;&gt;&lt;a id=&#34;__codelineno-7-32&#34; name=&#34;__codelineno-7-32&#34; href=&#34;#__codelineno-7-32&#34;&gt;&lt;/a&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_KNN&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argsort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_distances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SPATIAL_K_NEIGHBORS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-33&#34;&gt;&lt;a id=&#34;__codelineno-7-33&#34; name=&#34;__codelineno-7-33&#34; href=&#34;#__codelineno-7-33&#34;&gt;&lt;/a&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;[MoransAnalyzer] Cached KNN neighbors with k=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SPATIAL_K_NEIGHBORS&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-34&#34;&gt;&lt;a id=&#34;__codelineno-7-34&#34; name=&#34;__codelineno-7-34&#34; href=&#34;#__codelineno-7-34&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-35&#34;&gt;&lt;a id=&#34;__codelineno-7-35&#34; name=&#34;__codelineno-7-35&#34; href=&#34;#__codelineno-7-35&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;getattr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;quot;cached_W&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-36&#34;&gt;&lt;a id=&#34;__codelineno-7-36&#34; name=&#34;__codelineno-7-36&#34; href=&#34;#__codelineno-7-36&#34;&gt;&lt;/a&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_ensure_cached_W_from_distances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-37&#34;&gt;&lt;a id=&#34;__codelineno-7-37&#34; name=&#34;__codelineno-7-37&#34; href=&#34;#__codelineno-7-37&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# --- Step 3: Align agent_endowments with weight matrix ---&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-7-38&#34;&gt;&lt;a id=&#34;__codelineno-7-38&#34; name=&#34;__codelineno-7-38&#34; href=&#34;#__codelineno-7-38&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cached_W&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; Okay, let&#39;s review this. The library call accepts the entire city, which is not the most efficient, but otherwise we would need 4 or 5 input parameters from the city, so this is simpler. The code itself ensures that a spatial weights matrix (W) exists, which is essential for computing Local Moran’s I.&lt;/p&gt; &lt;p&gt;Spatial weights define which regions (or agents) are considered neighbors and how strongly they influence each other. The code first checks whether these weights already exist (as a tract-level NumPy matrix on the city object). If not, it dynamically builds them from cached distance data.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Using Precomputed Tract Weights&lt;/li&gt; &lt;li&gt;If the city object already provides a tract-level distance matrix (morans_weights):&lt;/li&gt; &lt;li&gt;The code verifies that all values are finite (no NaNs or infinities).&lt;/li&gt; &lt;li&gt;It converts the NumPy distance matrix into a Libpysal W object, the standard spatial weights format used by the PySAL ecosystem.&lt;/li&gt; &lt;li&gt;Each tract’s row is converted into a dictionary mapping neighbor indices → weight values.&lt;/li&gt; &lt;li&gt;Finally, the matrix is row-standardized (w_obj.transform = &#34;r&#34;), so each row sums to 1.&lt;/li&gt; &lt;li&gt; &lt;p&gt;This path is used when a ready-made Moran’s weights matrix is already available (for example, from prior preprocessing or caching).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Building Weights from Cached Distances&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If the city object doesn’t have a precomputed weights matrix (w is None), the method builds one on the fly:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;It loads a precomputed centroid distance matrix from neighbors.npy, which stores pairwise distances between tracts.&lt;/li&gt; &lt;li&gt;It constructs a k-nearest-neighbor (KNN) structure (self.cached_KNN), where each tract is connected to its SPATIAL_K_NEIGHBORS closest neighbors.&lt;/li&gt; &lt;li&gt;If a cached Libpysal W object (self.cached_W) doesn’t exist yet, it calls _ensure_cached_W_from_distances() to create it.&lt;/li&gt; &lt;li&gt;This helper computes inverse-distance weights, so closer tracts have stronger influence.&lt;/li&gt; &lt;li&gt;The resulting matrix is also row-standardized.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;After these steps, the method guarantees that a valid Libpysal W object (w) exists — ready for use in the Local Moran’s I calculation that follows.&lt;/p&gt; &lt;p&gt;&lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-8-1&#34;&gt;&lt;a id=&#34;__codelineno-8-1&#34; name=&#34;__codelineno-8-1&#34; href=&#34;#__codelineno-8-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agent_endowments&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-2&#34;&gt;&lt;a id=&#34;__codelineno-8-2&#34; name=&#34;__codelineno-8-2&#34; href=&#34;#__codelineno-8-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;n_agents&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-3&#34;&gt;&lt;a id=&#34;__codelineno-8-3&#34; name=&#34;__codelineno-8-3&#34; href=&#34;#__codelineno-8-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-4&#34;&gt;&lt;a id=&#34;__codelineno-8-4&#34; name=&#34;__codelineno-8-4&#34; href=&#34;#__codelineno-8-4&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-5&#34;&gt;&lt;a id=&#34;__codelineno-8-5&#34; name=&#34;__codelineno-8-5&#34; href=&#34;#__codelineno-8-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Adjust sizes&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-6&#34;&gt;&lt;a id=&#34;__codelineno-8-6&#34; name=&#34;__codelineno-8-6&#34; href=&#34;#__codelineno-8-6&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_agents&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-7&#34;&gt;&lt;a id=&#34;__codelineno-8-7&#34; name=&#34;__codelineno-8-7&#34; href=&#34;#__codelineno-8-7&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# pad missing nodes with mean value (not NaN to avoid broadcasting)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-8&#34;&gt;&lt;a id=&#34;__codelineno-8-8&#34; name=&#34;__codelineno-8-8&#34; href=&#34;#__codelineno-8-8&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;mean_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-9&#34;&gt;&lt;a id=&#34;__codelineno-8-9&#34; name=&#34;__codelineno-8-9&#34; href=&#34;#__codelineno-8-9&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;padded&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;full&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean_val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-10&#34;&gt;&lt;a id=&#34;__codelineno-8-10&#34; name=&#34;__codelineno-8-10&#34; href=&#34;#__codelineno-8-10&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;padded&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_agents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-11&#34;&gt;&lt;a id=&#34;__codelineno-8-11&#34; name=&#34;__codelineno-8-11&#34; href=&#34;#__codelineno-8-11&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padded&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-12&#34;&gt;&lt;a id=&#34;__codelineno-8-12&#34; name=&#34;__codelineno-8-12&#34; href=&#34;#__codelineno-8-12&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_agents&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_nodes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-13&#34;&gt;&lt;a id=&#34;__codelineno-8-13&#34; name=&#34;__codelineno-8-13&#34; href=&#34;#__codelineno-8-13&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# truncate if too many agents: average agents into tract-level values.&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-14&#34;&gt;&lt;a id=&#34;__codelineno-8-14&#34; name=&#34;__codelineno-8-14&#34; href=&#34;#__codelineno-8-14&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Use the simulation&amp;#39;s canonical number of tracts (centroids) rather than&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-15&#34;&gt;&lt;a id=&#34;__codelineno-8-15&#34; name=&#34;__codelineno-8-15&#34; href=&#34;#__codelineno-8-15&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# deriving it from agent_positions, which can change as agents move.&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-16&#34;&gt;&lt;a id=&#34;__codelineno-8-16&#34; name=&#34;__codelineno-8-16&#34; href=&#34;#__codelineno-8-16&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;num_tracts&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;getattr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;quot;centroids&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]))&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-17&#34;&gt;&lt;a id=&#34;__codelineno-8-17&#34; name=&#34;__codelineno-8-17&#34; href=&#34;#__codelineno-8-17&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_average_agents_by_tract&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agent_endowments&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_tracts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_tracts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-18&#34;&gt;&lt;a id=&#34;__codelineno-8-18&#34; name=&#34;__codelineno-8-18&#34; href=&#34;#__codelineno-8-18&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-19&#34;&gt;&lt;a id=&#34;__codelineno-8-19&#34; name=&#34;__codelineno-8-19&#34; href=&#34;#__codelineno-8-19&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Replace NaNs with mean for stability&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-20&#34;&gt;&lt;a id=&#34;__codelineno-8-20&#34; name=&#34;__codelineno-8-20&#34; href=&#34;#__codelineno-8-20&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;mean_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nanmean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-21&#34;&gt;&lt;a id=&#34;__codelineno-8-21&#34; name=&#34;__codelineno-8-21&#34; href=&#34;#__codelineno-8-21&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nan_to_num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nan&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean_val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-22&#34;&gt;&lt;a id=&#34;__codelineno-8-22&#34; name=&#34;__codelineno-8-22&#34; href=&#34;#__codelineno-8-22&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-23&#34;&gt;&lt;a id=&#34;__codelineno-8-23&#34; name=&#34;__codelineno-8-23&#34; href=&#34;#__codelineno-8-23&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-8-24&#34;&gt;&lt;a id=&#34;__codelineno-8-24&#34; name=&#34;__codelineno-8-24&#34; href=&#34;#__codelineno-8-24&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;ValueError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;Length mismatch: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; values vs &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; weights&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; To ensure the endowment vector and the spatial weights matrix are compatible in size, the function performs the following adjustments:&lt;/p&gt; &lt;p&gt;Case 1: Fewer agents than spatial nodes If the number of agents (n_agents) is less than the number of spatial nodes (n_nodes), the missing nodes are padded with the mean endowment value.&lt;/p&gt; &lt;p&gt;Mathematically:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ values[i] = \begin{cases} agent\_endowment[i], &amp;amp; i &amp;lt; n\_{\text{agents}} \\ \bar{x}, &amp;amp; i \ge n\_{\text{agents}} \end{cases} \]&lt;/div&gt; &lt;p&gt;where x̄ is the mean of all agent endowments. This ensures every spatial node has a corresponding endowment value.&lt;/p&gt; &lt;p&gt;Case 2: More agents than spatial nodes If the number of agents (n_agents) exceeds the number of nodes (n_nodes), agents are aggregated by tract, and the mean endowment per tract is used.&lt;/p&gt; &lt;p&gt;Mathematically:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ tract\_value[j] = \frac{1}{|A_j|} \sum_{i \in A_j} endowment\_i \]&lt;/div&gt; &lt;p&gt;where Aⱼ is the set of agents that belong to tract j. Each tract’s endowment value becomes the average of all agents in that tract.&lt;/p&gt; &lt;p&gt;Case 3: Handle missing or invalid values Any missing (NaN) or undefined values are replaced by the overall mean value x̄ to ensure numerical stability and prevent errors during computation.&lt;/p&gt; &lt;p&gt;Final check After these adjustments, the endowment vector and the spatial weights matrix always have the same length:&lt;/p&gt; &lt;div class=&#34;arithmatex&#34;&gt;\[ |values| = n_nodes = |W| \]&lt;/div&gt; &lt;p&gt;This guarantees proper alignment between endowments and spatial weights when computing Moran’s I.&lt;/p&gt; &lt;div class=&#34;language-python highlight&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&#34;__span-9-1&#34;&gt;&lt;a id=&#34;__codelineno-9-1&#34; name=&#34;__codelineno-9-1&#34; href=&#34;#__codelineno-9-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;c1&#34;&gt;# I need to check what 0 permutations actually means&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-2&#34;&gt;&lt;a id=&#34;__codelineno-9-2&#34; name=&#34;__codelineno-9-2&#34; href=&#34;#__codelineno-9-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;USE_SIMPLIFIED_COMMUNITY_SCORE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;morans&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-3&#34;&gt;&lt;a id=&#34;__codelineno-9-3&#34; name=&#34;__codelineno-9-3&#34; href=&#34;#__codelineno-9-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;lisa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Moran_Local&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;permutations&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-4&#34;&gt;&lt;a id=&#34;__codelineno-9-4&#34; name=&#34;__codelineno-9-4&#34; href=&#34;#__codelineno-9-4&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lisa&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Is&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-5&#34;&gt;&lt;a id=&#34;__codelineno-9-5&#34; name=&#34;__codelineno-9-5&#34; href=&#34;#__codelineno-9-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;USE_SIMPLIFIED_COMMUNITY_SCORE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;gearys&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-6&#34;&gt;&lt;a id=&#34;__codelineno-9-6&#34; name=&#34;__codelineno-9-6&#34; href=&#34;#__codelineno-9-6&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;local_geary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Geary_Local&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;permutations&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-7&#34;&gt;&lt;a id=&#34;__codelineno-9-7&#34; name=&#34;__codelineno-9-7&#34; href=&#34;#__codelineno-9-7&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;local_geary&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;local_geary&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-8&#34;&gt;&lt;a id=&#34;__codelineno-9-8&#34; name=&#34;__codelineno-9-8&#34; href=&#34;#__codelineno-9-8&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;local_geary&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localG&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-9&#34;&gt;&lt;a id=&#34;__codelineno-9-9&#34; name=&#34;__codelineno-9-9&#34; href=&#34;#__codelineno-9-9&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-10&#34;&gt;&lt;a id=&#34;__codelineno-9-10&#34; name=&#34;__codelineno-9-10&#34; href=&#34;#__codelineno-9-10&#34;&gt;&lt;/a&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;quot;invalid use_simplified_community_score value&amp;quot;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-11&#34;&gt;&lt;a id=&#34;__codelineno-9-11&#34; name=&#34;__codelineno-9-11&#34; href=&#34;#__codelineno-9-11&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-12&#34;&gt;&lt;a id=&#34;__codelineno-9-12&#34; name=&#34;__codelineno-9-12&#34; href=&#34;#__codelineno-9-12&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-13&#34;&gt;&lt;a id=&#34;__codelineno-9-13&#34; name=&#34;__codelineno-9-13&#34; href=&#34;#__codelineno-9-13&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;#Convert to NumPy array for consistency&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-14&#34;&gt;&lt;a id=&#34;__codelineno-9-14&#34; name=&#34;__codelineno-9-14&#34; href=&#34;#__codelineno-9-14&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-15&#34;&gt;&lt;a id=&#34;__codelineno-9-15&#34; name=&#34;__codelineno-9-15&#34; href=&#34;#__codelineno-9-15&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-16&#34;&gt;&lt;a id=&#34;__codelineno-9-16&#34; name=&#34;__codelineno-9-16&#34; href=&#34;#__codelineno-9-16&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Convert tract-level results to CDF-normalized scores&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-17&#34;&gt;&lt;a id=&#34;__codelineno-9-17&#34; name=&#34;__codelineno-9-17&#34; href=&#34;#__codelineno-9-17&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;tract_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zscore_to_cdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# shape (C,)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-18&#34;&gt;&lt;a id=&#34;__codelineno-9-18&#34; name=&#34;__codelineno-9-18&#34; href=&#34;#__codelineno-9-18&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-19&#34;&gt;&lt;a id=&#34;__codelineno-9-19&#34; name=&#34;__codelineno-9-19&#34; href=&#34;#__codelineno-9-19&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Map tract-level scores to per-agent scores so callers receive an (N,) array&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-20&#34;&gt;&lt;a id=&#34;__codelineno-9-20&#34; name=&#34;__codelineno-9-20&#34; href=&#34;#__codelineno-9-20&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# (every agent in the same tract receives the same tract score).&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-21&#34;&gt;&lt;a id=&#34;__codelineno-9-21&#34; name=&#34;__codelineno-9-21&#34; href=&#34;#__codelineno-9-21&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;intp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-22&#34;&gt;&lt;a id=&#34;__codelineno-9-22&#34; name=&#34;__codelineno-9-22&#34; href=&#34;#__codelineno-9-22&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-23&#34;&gt;&lt;a id=&#34;__codelineno-9-23&#34; name=&#34;__codelineno-9-23&#34; href=&#34;#__codelineno-9-23&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# no agents present -&amp;gt; return empty array&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-24&#34;&gt;&lt;a id=&#34;__codelineno-9-24&#34; name=&#34;__codelineno-9-24&#34; href=&#34;#__codelineno-9-24&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-25&#34;&gt;&lt;a id=&#34;__codelineno-9-25&#34; name=&#34;__codelineno-9-25&#34; href=&#34;#__codelineno-9-25&#34;&gt;&lt;/a&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-26&#34;&gt;&lt;a id=&#34;__codelineno-9-26&#34; name=&#34;__codelineno-9-26&#34; href=&#34;#__codelineno-9-26&#34;&gt;&lt;/a&gt; &lt;span class=&#34;c1&#34;&gt;# Direct mapping: assume agent_positions are valid tract indices.&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-27&#34;&gt;&lt;a id=&#34;__codelineno-9-27&#34; name=&#34;__codelineno-9-27&#34; href=&#34;#__codelineno-9-27&#34;&gt;&lt;/a&gt; &lt;span class=&#34;n&#34;&gt;agent_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tract_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agent_positions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;/span&gt;&lt;span id=&#34;__span-9-28&#34;&gt;&lt;a id=&#34;__codelineno-9-28&#34; name=&#34;__codelineno-9-28&#34; href=&#34;#__codelineno-9-28&#34;&gt;&lt;/a&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agent_scores&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This is where the actual morans/gearys happens. Here we determine which Spatial Autocorrelation algorithm to use and then run that using the library. The &#39;0 permutations&#39; means the library only runs once. You can set a higher amount of permutations and then calculate means, medians, standard deviations, etc... but we choose not to do this because every permutation slows the simulation down. Then we make sure the data is in the right format and uses the correct normalization. Then when we &#39;map tract-level scores to per-agent scores&#39;, this ensures that the agents recieve the correct score for their track.&lt;/p&gt; &lt;p&gt;The issue with this is that all agents in the tract will recieve the same morans score. The library runs on a node basis not an agent basis, which means we have to manipulate the data to get the results we want. There&#39;s a few potential ways to convert tract-level morans to agent-level morans. Potentially, you can add a faux tract with the same distances as the real tract the agent is and then set the endowment of the faux tract to the endowment of the agent. The issue with this is it requires a loop for every agent which means if there&#39;s N agents, then you need to run the library-morans N times, which is far too slow to be useful.Another way is to not use the library and instead do the calculations manually, which leaves more error for potential coding issues and will also be slower than the regular library due to the library&#39;s optimizations.&lt;/p&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=V6XC36CP5ew&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/V6XC36CP5ew/maxresdefault.jpg&#34; width=&#34;480&#34; class=&#34;off-glb&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Matthew Lim&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mlim70&#34;&gt;mlim70&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Justin Xu&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/JXU037&#34;&gt;JXU037&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Devam Mondal&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Dodesimo&#34;&gt;Dodesimo&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nithish Sabapathy&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nithish101&#34;&gt;nithish101&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ian Baracskay&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/ianBaracskay&#34;&gt;ianBaracskay&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jason Tran&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/JTran86&#34;&gt;JTran86&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-mponc/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:54 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-mponc/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-mponc/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-mponc/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fa-MedialAxis</title> <description>&lt;h1 id=&#34;medial-axis-transformation-for-building-floor-plans&#34;&gt;Medial Axis Transformation for Building Floor Plans&lt;/h1&gt; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;figures/f25_visual_abstract.png&#34; width=&#34;1000&#34; alt=&#34;f25_visual_abstract&#34;&gt; &lt;/p&gt; &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt; &lt;p&gt;The &lt;strong&gt;Medial Axis Transformation (MAT)&lt;/strong&gt; is a method that converts the two-dimensional layout of a building&#39;s interior space into a one-dimensional representation. This transformation is crucial because it reduces the complexity of the data while preserving essential information about the space&#39;s structure, including both circulation and partition details. This simplification facilitates easier computational analysis of complex building geometries.&lt;/p&gt; &lt;p&gt;This project implements the Medial Axis Transformation for building floor plans inside the &lt;strong&gt;Rhino / Grasshopper&lt;/strong&gt; environment, with the goal of producing a robust, vector-based representation of interior space that supports downstream data-driven and machine learning applications.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt; &lt;p&gt;One of the primary motivations for using the Medial Axis is that most modern buildings are unique, making systematic and automated analysis challenging. The Medial Axis provides an automated method for identifying the inherent structure of interior space.&lt;/p&gt; &lt;p&gt;By capturing underlying structural and circulation information, the MAT opens up pathways for advanced applications in architecture, urbanism, and real estate, such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Prediction of social or functional information (e.g., room usage levels)&lt;/li&gt; &lt;li&gt;Classification of building layouts&lt;/li&gt; &lt;li&gt;Generative design using &lt;strong&gt;Graph Neural Networks (GNNs)&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;project-objective&#34;&gt;Project Objective&lt;/h2&gt; &lt;p&gt;The core objective of this project is to develop a &lt;strong&gt;custom implementation of the Medial Axis Transformation&lt;/strong&gt; capable of handling complex shapes commonly found in real building floor plans, particularly &lt;strong&gt;polygons with interior holes&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Key requirements of the implementation include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A &lt;strong&gt;vector-based&lt;/strong&gt; (non-raster) representation to maintain geometric precision &lt;/li&gt; &lt;li&gt;Robust handling of highly symmetrical geometries without producing unstable results &lt;/li&gt; &lt;li&gt;Seamless integration into the &lt;strong&gt;Rhinoceros–Grasshopper&lt;/strong&gt; environment &lt;/li&gt; &lt;li&gt;A graph-based output suitable for computational and data-driven analysis &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;theoretical-background&#34;&gt;Theoretical Background&lt;/h2&gt; &lt;p&gt;The Medial Axis of a polygon is closely related to the &lt;strong&gt;Voronoi diagram&lt;/strong&gt; of its boundary geometry. For floor plans represented as line segments, the Voronoi diagram provides a natural computational foundation for extracting medial axis segments.&lt;/p&gt; &lt;p&gt;However, Voronoi diagrams generated from boundary segments contain additional geometry that does not belong to the true medial axis. A substantial portion of this project therefore focuses on &lt;strong&gt;post-processing&lt;/strong&gt;, classification, and filtering of Voronoi output to recover only the meaningful medial axis structure.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;implementation-overview&#34;&gt;Implementation Overview&lt;/h2&gt; &lt;p&gt;Two primary implementation paths were pursued in parallel.&lt;/p&gt; &lt;h2 id=&#34;method-1-pyvoronoi-based-implementation&#34;&gt;Method 1: PyVoronoi-Based Implementation&lt;/h2&gt; &lt;p&gt;This approach leverages &lt;strong&gt;PyVoronoi&lt;/strong&gt;, a Python wrapper around Boost’s computational geometry algorithms, to generate Voronoi diagrams from floor plan line segments directly inside Grasshopper.&lt;/p&gt; &lt;h3 id=&#34;tools&#34;&gt;Tools&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Custom Grasshopper Python component &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Python 3&lt;/strong&gt; &lt;/li&gt; &lt;li&gt;&lt;strong&gt;PyVoronoi&lt;/strong&gt; (Python port of Boost C++ computational geometry) &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;input-representation&#34;&gt;Input Representation&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Floor plans represented as integer-based line segments&lt;/li&gt; &lt;li&gt;Includes both:&lt;/li&gt; &lt;li&gt;Exterior polygon boundaries &lt;/li&gt; &lt;li&gt;Interior holes and partitions &lt;/li&gt; &lt;/ul&gt; &lt;h3 id=&#34;processing-pipeline&#34;&gt;Processing Pipeline&lt;/h3&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Voronoi Diagram Generation&lt;/strong&gt;&lt;br /&gt; A 2D Voronoi diagram is computed from the floor plan boundary segments.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Voronoi Cell Classification&lt;/strong&gt;&lt;br /&gt; Voronoi edges are classified based on the originating boundary feature types, including:&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Concave &lt;/li&gt; &lt;li&gt;Convex–Convex &lt;/li&gt; &lt;li&gt;Convex–Line &lt;/li&gt; &lt;li&gt; &lt;p&gt;Line–Line &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Medial Axis Extraction&lt;/strong&gt;&lt;br /&gt; Voronoi geometry that does not correspond to the true medial axis is filtered out, leaving only valid medial axis segments.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Graph Construction&lt;/strong&gt;&lt;br /&gt; The remaining medial axis segments are treated as nodes, adjacency relationships are computed, and a complete graph representation of the interior space is constructed.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2 id=&#34;method-2-cgal-library-port&#34;&gt;Method 2: CGAL Library Port&lt;/h2&gt; &lt;p&gt;The second implementation path focuses on utilizing &lt;strong&gt;CGAL (Computational Geometry Algorithms Library)&lt;/strong&gt; to perform medial axis computation with greater robustness.&lt;/p&gt; &lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt; &lt;p&gt;A multi-layered framework bridges native CGAL C++ code into Rhino’s .NET environment:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native C++ Layer&lt;/strong&gt;&lt;br /&gt; Selected CGAL algorithms are compiled and exposed through a stable Application Binary Interface (ABI).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native Interop Layer (.NET)&lt;/strong&gt;&lt;br /&gt; Platform Invocation (&lt;strong&gt;P/Invoke&lt;/strong&gt;) is used to call the native C++ functions.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;.NET Bridge Layer&lt;/strong&gt;&lt;br /&gt; CGAL data structures are converted into Rhino-compatible primitive types.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Grasshopper Component&lt;/strong&gt;&lt;br /&gt; A user-facing component exposes the functionality within the Grasshopper interface.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id=&#34;current-status&#34;&gt;Current Status&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;The full framework has been successfully established using &lt;strong&gt;.NET 7&lt;/strong&gt;, which is compatible with Rhino.&lt;/li&gt; &lt;li&gt;The next milestone is the integration of &lt;strong&gt;2D Voronoi segment computation&lt;/strong&gt;, which forms the basis of the Medial Axis Transformation.&lt;/li&gt; &lt;li&gt;More info here: https://github.com/VIP-SMUR/25Fa-MedialAxis/blob/main/cgal_port_2/README.md&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;graph-representation&#34;&gt;Graph Representation&lt;/h2&gt; &lt;p&gt;Once the medial axis segments are extracted and classified, they are used to build a &lt;strong&gt;graph structure&lt;/strong&gt; that encodes the connectivity and topology of the building’s interior space.&lt;/p&gt; &lt;p&gt;This graph representation captures: - Circulation paths&lt;br /&gt; - Spatial adjacency&lt;br /&gt; - Topological structure of interior partitions &lt;/p&gt; &lt;p&gt;The resulting graph serves as the primary interface for downstream computational analysis and machine learning workflows.&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;future-work&#34;&gt;Future Work&lt;/h2&gt; &lt;h3 id=&#34;data-integration-and-machine-learning&#34;&gt;Data Integration and Machine Learning&lt;/h3&gt; &lt;p&gt;Planned future work includes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Encoding semantic or social information directly onto the medial axis graph &lt;/li&gt; &lt;li&gt;Converting graphs into &lt;strong&gt;Directed Acyclic Graphs (DAGs)&lt;/strong&gt; where appropriate &lt;/li&gt; &lt;li&gt;Training &lt;strong&gt;Graph Neural Networks (GNNs)&lt;/strong&gt; for:&lt;/li&gt; &lt;li&gt;Prediction tasks &lt;/li&gt; &lt;li&gt;Building classification &lt;/li&gt; &lt;li&gt;Generative architectural design &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt; &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GZbaGNxTMrI&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; &lt;img src=&#34;https://img.youtube.com/vi/GZbaGNxTMrI/maxresdefault.jpg&#34; width=&#34;480&#34;&gt; &lt;/a&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Kavya Lalith&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/kavya-oop&#34;&gt;kavya-oop&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jessica Hernandez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jhernandez312&#34;&gt;jhernandez312&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gonzalo Vegas&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/gvegasol&#34;&gt;gvegasol&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/25fa-medialaxis/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Mon, 15 Dec 2025 23:45:53 +0000</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/25fa-medialaxis/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/25fa-medialaxis/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/25fa-medialaxis/README.png" type="image/png" length="None" /> </item> <item> <title>VIP-SMUR</title> <description>&lt;style&gt; /* find better solution for this later */ .md-typeset h1 { position: absolute; left: -999px; } &lt;/style&gt; &lt;p&gt;&lt;img _=&#34;,&#34; align=&#34;left,&#34; alt=&#34;SustainLab Logo&#34; class=&#34;off-glb&#34; src=&#34;images/sustainlab-smur-logo-wordmark-color-white.svg#dark-only&#34; width=&#34;500&#34; /&gt; &lt;img _=&#34;,&#34; align=&#34;left,&#34; alt=&#34;SustainLab Logo&#34; class=&#34;off-glb&#34; src=&#34;images/sustainlab-smur-logo-wordmark-color-black.svg#light-only&#34; width=&#34;500&#34; /&gt;&lt;/p&gt; &lt;p&gt;Welcome to the project page of the &lt;a href=&#34;https://vip.gatech.edu/vip-vertically-integrated-projects-program&#34; title=&#34;The Vertically Integrated Projects (VIP) Program is a transformative approach to enhancing higher education by engaging undergraduate and graduate students in ambitious, long-term, large-scale, multidisciplinary project teams led by faculty. The program has been rigorously evaluated and refined over two decades.&#34;&gt;VIP&lt;/a&gt; team &lt;a href=&#34;https://vip-smur.github.io/&#34;&gt;Surrogate Modeling for Urban Regeneration&lt;/a&gt; (SMUR) at Georgia Tech. This course is led by Dr. Patrick Kastner, head of the &lt;a href=&#34;https://sustain.arch.gatech.edu&#34;&gt;Sustainable Urban Systems Lab&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&#34;the-problem&#34;&gt;📝 The Problem&lt;/h2&gt; &lt;p&gt;Many performance-related decisions in architectural and urban design happen too late in the decision-making process to ensure they suit the clients&#39; purposes. We believe this hinders true &lt;a href=&#34;https://unhabitat.org/topic/urban-regeneration&#34; title=&#34;Urban regeneration brings back underutilized assets and redistributes opportunities, increasing urban prosperity and quality of life.&#34;&gt;urban regeneration&lt;/a&gt;. This research course challenges this status quo by developing software tools that empower communities and urban decision-makers.&lt;/p&gt; &lt;figure&gt; &lt;img _=&#34;,&#34; align=&#34;left,&#34; alt=&#34;MacLeamy Influence Curve&#34; class=&#34;off-glb&#34; src=&#34;images/SVG/InfluenceCurveWhite.svg#dark-only&#34; width=&#34;640&#34; /&gt; &lt;img _=&#34;,&#34; align=&#34;left,&#34; alt=&#34;MacLeamy Influence Curve&#34; class=&#34;off-glb&#34; src=&#34;images/SVG/InfluenceCurveBlack.svg#light-only&#34; width=&#34;640&#34; /&gt; &lt;br /&gt; &lt;figcaption&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=9bUlBYc_Gl4&#34;&gt;MacLeamy Curve&lt;/a&gt; illustrating the need for rapid performance feedback in architectural decision-making. &lt;a href=&#34;https://www.danieldavis.com/macleamy/&#34;&gt;(more info)&lt;/a&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Our models will enable urban decision-making by enabling real-time testing of interventions. By involving a multitude of urban &lt;a href=&#34;https://www.rescue.org/sites/default/files/document/1501/weburbanstakeholderengagementandcoordinationweb.pdf&#34; title=&#34;- Affected populations&amp;lt;br&amp;gt;- Community leaders&amp;lt;br&amp;gt;- Civil society:&amp;lt;br&amp;gt;&amp;emsp;- local non-governmental organisations&amp;lt;br&amp;gt;&amp;emsp;- community-based organisations&amp;lt;br&amp;gt;&amp;emsp;- non-state armed actor&amp;lt;br&amp;gt;- International actors and donors&amp;lt;br&amp;gt;- National government, sub-national and local government&amp;lt;br&amp;gt;- Urban planning institutions&amp;lt;br&amp;gt;- Architects / Urban Designers&amp;lt;br&amp;gt;- Private sector&amp;lt;br&amp;gt;- Academia&#34;&gt;stakeholders&lt;/a&gt;, we make regenerative cities tangible, actionable, and inclusive. Our work will address:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Air quality, pollution, natural ventilation potential&lt;/li&gt; &lt;li&gt;Microclimate assessment (outdoor thermal comfort, urban heat islands)&lt;/li&gt; &lt;li&gt;Flood, stormwater, water runoff&lt;/li&gt; &lt;li&gt;Mobility, walkability, transportation&lt;/li&gt; &lt;li&gt;Global warming, climate change (heat waves)&lt;/li&gt; &lt;li&gt;Urban building energy, district energy, decarbonization modeling&lt;/li&gt; &lt;li&gt;Etc.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;goals&#34;&gt;🎯 Goals&lt;/h2&gt; &lt;p&gt;Conventional environmental simulation approaches in urban design are time-consuming and often incompatible with fast-paced decision-making processes. This VIP aims to address this by developing &lt;a href=&#34;https://en.wikipedia.org/wiki/Surrogate_model&#34; title=&#34;A surrogate model is a mathematical approximation or metamodel that mimics the behavior of a computationally expensive or complex system, allowing for faster analysis and optimization.&#34;&gt;surrogate models&lt;/a&gt; that accelerate simulations (typically via machine learning) that offer real-time feedback to urban decision-makers, such as architects, urban designers, and policymakers. After the decision-making has been informed, we employ high-fidelity, physics-based simulations to validate our results and to produce final numbers.&lt;/p&gt; &lt;p&gt;Our goal is to seamlessly integrate sustainability considerations into every step of urban decision-making processes by integrating our models with industry-leading CAD tools such as &lt;code&gt;Rhino&lt;/code&gt; and &lt;code&gt;Revit&lt;/code&gt;, &lt;code&gt;GIS&lt;/code&gt;, and making them usable even in the browser.&lt;/p&gt; &lt;h2 id=&#34;prerequisites&#34;&gt;✅ Prerequisites&lt;/h2&gt; &lt;p&gt;We seek an interdisciplinary team of highly motivated students. Experience with &lt;code&gt;Python&lt;/code&gt;, &lt;code&gt;C#&lt;/code&gt;, &lt;code&gt;JavaScript&lt;/code&gt;, &lt;code&gt;machine learning&lt;/code&gt;, and &lt;code&gt;simulation modeling&lt;/code&gt; will be advantageous. Our sub-teams typically are interdisciplinary and consist of students from:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Computer Science / Engineering (Civil, Environmental, Mechanical, etc.)&lt;/li&gt; &lt;li&gt;(Applied) Industrial and Systems Engineering&lt;/li&gt; &lt;li&gt;Architecture &amp;amp; Urban Design&lt;/li&gt; &lt;li&gt;City &amp;amp; Regional Planning&lt;/li&gt; &lt;li&gt;Applied Math &amp;amp; Physics&lt;/li&gt; &lt;li&gt;Public Policy&lt;/li&gt; &lt;li&gt;Etc.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If your major is not mentioned, please &lt;a href=&#34;mailto:patrick.kastner@gatech.edu&#34;&gt;contact us&lt;/a&gt; to see if your background might be a good fit. We&#39;re happy to help!&lt;/p&gt; &lt;h2 id=&#34;project-overview&#34;&gt;📊 Project Overview&lt;/h2&gt; &lt;p&gt;Our &lt;a href=&#34;https://vip-smur.github.io/projects/&#34;&gt;current and previous projects&lt;/a&gt; include topics on:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Energy in Buildings&lt;/li&gt; &lt;li&gt;Urban Microclimate&lt;/li&gt; &lt;li&gt;Mobility and Walkability&lt;/li&gt; &lt;li&gt;Game Theory and Neighborhood Processes&lt;/li&gt; &lt;li&gt;The Intersection of Neuroscience, Architecture &amp;amp; Urbanism&lt;/li&gt; &lt;/ol&gt; &lt;!--- Include Markdowm from https://github.com/VIP-SMUR/.github/blob/main/profile/README.md --&gt; &lt;h2 id=&#34;get-involved&#34;&gt;🤝 Get Involved&lt;/h2&gt; &lt;p&gt;Join our team and make a lasting impact on urban environments!&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&#34;https://vip.gatech.edu/prospective-students/&#34;&gt;Prospective Students&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://vip.gatech.edu/request-a-permit/&#34;&gt;Returning Students&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;mailto:patrick.kastner@gatech.edu&#34;&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&#34;project-wiki&#34;&gt;📄 Project Wiki&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;📁 &amp;nbsp; &lt;strong&gt;Current and previous projects&lt;/strong&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;→ &amp;nbsp; &lt;a href=&#34;https://vip-smur.github.io/projects/&#34;&gt;Learn more&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;hr /&gt;</description> <link>https://vip-smur.github.io/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Thu, 11 Dec 2025 15:59:33 -0500</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/index.png" type="image/png" length="39330" /> </item> <item> <title>Projects</title> <description>&lt;h1 id=&#34;fall-2025&#34;&gt;Fall 2025&lt;/h1&gt; &lt;hr /&gt; &lt;div class=&#34;grid cards&#34;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;m14 4 2.29 2.29-2.88 2.88 1.42 1.42 2.88-2.88L20 10V4M10 4H4v6l2.29-2.29 4.71 4.7V20h2v-8.41l-5.29-5.3&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Medial Axis Transformation&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Computational methods for medial axis transformation of building geometries.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Kavya Lalith, Jessica Hernandez, Gonzalo Vegas&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25fa-medialaxis/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13 3v8h8V3zM3 21h8v-8H3zM3 3v8h8V3zm10 13h3v-3h2v3h3v2h-3v3h-2v-3h-3z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;MPONC&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Multi-agent game theoretical approaches to simulating neighborhood processes.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Matthew Lim, Justin Xu, Devam Mondal, Nithish Sabapathy, Ian Baracskay, Jason Tran&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25fa-mponc/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M5 3v18h6v-3.5h2V21h6V3zm2 2h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zM7 9h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm8 0h2v2h-2z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Energy in Buildings&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Modeling energy demand in buildings.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Hang Xu, Jiayi Li, Aryan Bolakond, Breno Veiga, Nishanth Giridharan, Sameer Jain&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25fa-energyinbuildings/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Microclimate-ML&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Continues work on surrogate models estimating urban heat island effects.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Thanasarn Changnawa, Han-Syun Shih, Edzel Sutanto, Roshan Cerejo, Vikram Renganathan, Yupeng Tang, Ze Yu Jiang&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25fa-microclimate-ml/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M19 9V7a2 2 0 0 0-2-2h-1V2h-2v3h-1a2 2 0 0 0-2 2v2a2 2 0 0 0-2 2v1H5a2 2 0 0 0-2 2v8h3v-2h2v2h4v-2h2v2h2v-2h2v2h3V11a2 2 0 0 0-2-2M8 18H6v-2h2zm6 0h-2v-2h2zm0-4h-2v-2h2zm-1-5V7h4v2zm5 9h-2v-2h2zm0-4h-2v-2h2z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Microclimate-Outdoor+&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Rhino &amp;amp; Grasshopper workflows for urban microclimate modeling.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Marcelo Álvarez, Mallika Champaneria, Shaiba Bano, Nitiksha Mota, Sina Rahimi&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25Fa-Microclimate-OutdoorPlus/README.md&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 384 512&#34;&gt;&lt;!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--&gt;&lt;path d=&#34;M192 80a56 56 0 1 0 0-112 56 56 0 1 0 0 112m-86.6 147.9 22.6-22.6v69.3c0 28 12.2 54.7 33.5 72.9l71.4 61.2c5.9 5.1 9.8 12.1 10.9 19.8l12.6 88.1c2.5 17.5 18.7 29.7 36.2 27.2s29.7-18.7 27.2-36.2l-12.6-88.1c-3.3-23.1-14.9-44.1-32.6-59.3l-34.5-29.6V215.4l3.8 4.7c18.2 22.8 45.8 36 75 36h33.2c17.7 0 32-14.3 32-32s-14.3-32-32-32h-33.2c-9.7 0-18.9-4.4-25-12L276 157.7c-23-28.8-57.9-45.6-94.8-45.6-32.2 0-63.1 12.8-85.8 35.6l-35.3 34.9c-18 18-28.1 42.4-28.1 67.9V288c0 17.7 14.3 32 32 32s32-14.3 32-32v-37.5c0-8.5 3.4-16.6 9.4-22.6m12.4 179.4c-1.5 5.2-4.3 10-8.1 13.8l-68.3 68.3c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l68.3-68.3c11.5-11.5 19.9-25.8 24.4-41.5l2.2-7.6-46-39.4c-2.5-2.2-5-4.4-7.4-6.8z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Mobility (PEI)&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Improvements on the PEI methodology, a composite metric of walkability using key subindices.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Atharva Beesen, Mason Dewitt, Katherine Davis, Lucy Chai&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../25fa-mobility-pei/README.md&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;</description> <link>https://vip-smur.github.io/projects/25fa/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Wed, 10 Dec 2025 17:15:10 -0500</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/projects/25fa/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/projects/25fa/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/projects/25fa/README.png" type="image/png" length="None" /> </item> <item> <title>25-Fall</title> <description>&lt;h1 id=&#34;fall-2025&#34;&gt;Fall 2025&lt;/h1&gt; &lt;figure&gt; &lt;img alt=&#34;Fall 2025 Group Picture at Tech Green&#34; src=&#34;../25-Fa_Classphoto.jpg&#34; /&gt; &lt;br /&gt; &lt;figcaption&gt;SMUR Fall 2025 Team Picture (some folks are missing)&lt;/figcaption&gt; &lt;/figure&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Seniority&lt;/th&gt; &lt;th&gt;Major&lt;/th&gt; &lt;th&gt;School&lt;/th&gt; &lt;th&gt;# Semesters&lt;/th&gt; &lt;th&gt;GitHub Handle&lt;/th&gt; &lt;th&gt;Topic Area&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Matthew Lim&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mlim70&#34;&gt;mlim70&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Marcelo Álvarez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (DC)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/alvarezdmarch&#34;&gt;alvarezdmarch&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-outdoorplus&#34;&gt;Microclimate-UMCF&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Thanasarn Changnawa&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Thanasarn-Changnawa&#34;&gt;Thanasarn-Changnawa&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hang Xu&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/HangXXXu&#34;&gt;HangXXXu&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Justin Xu&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/JXU037&#34;&gt;JXU037&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jiayi Li&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jli3307&#34;&gt;jli3307&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Kavya Lalith&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/kavya-oop&#34;&gt;kavya-oop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-medialaxis&#34;&gt;Medial Axis Transformation&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Atharva Beesen&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AtharvaBeesen&#34;&gt;AtharvaBeesen&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mobility&#34;&gt;Mobility-PEI&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mason Dewitt&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Masonrd&#34;&gt;Masonrd&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mobility&#34;&gt;Mobility-PEI&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Devam Mondal&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Dodesimo&#34;&gt;Dodesimo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nithish Sabapathy&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nithish101&#34;&gt;nithish101&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jessica Hernandez&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/jhernandez312&#34;&gt;jhernandez312&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-medialaxis&#34;&gt;Medial Axis Transformation&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Han-Syun Shih&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture (HBP)&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Benjaminhansyun&#34;&gt;Benjaminhansyun&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Aiko Hayashi&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AnneTotoro&#34;&gt;AnneTotoro&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mobility&#34;&gt;Mobility-PEI&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Aryan Bolakond&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/AryanBolakond&#34;&gt;AryanBolakond&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Breno Veiga&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/veigab3&#34;&gt;veigab3&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Edzel Sutanto&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/Edzelandika&#34;&gt;Edzelandika&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ian Baracskay&lt;/td&gt; &lt;td&gt;Senior&lt;/td&gt; &lt;td&gt;Computer Engineering&lt;/td&gt; &lt;td&gt;ECE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/ianBaracskay&#34;&gt;ianBaracskay&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jason Tran&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/JTran86&#34;&gt;JTran86&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mponc&#34;&gt;MPONC&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Katherine Davis&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/katherine-el-davis&#34;&gt;katherine-el-davis&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mobility&#34;&gt;Mobility-PEI&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mallika Champaneria&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/mallikachampaneria&#34;&gt;mallikachampaneria&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-outdoorplus&#34;&gt;Microclimate-UMCF&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nishanth Giridharan&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/NishanthG05&#34;&gt;NishanthG05&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Roshan Cerejo&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/rcerejo&#34;&gt;rcerejo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sameer Jain&lt;/td&gt; &lt;td&gt;Sophomore&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sameerjain06&#34;&gt;sameerjain06&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-energyinbuildings&#34;&gt;Energy-In-Buildings&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Vikram Renganathan&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/viren108&#34;&gt;viren108&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Yupeng Tang&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/yupengtang&#34;&gt;yupengtang&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate-ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gonzalo Vegas&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architecture&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/gvegasol&#34;&gt;gvegasol&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-medialaxis&#34;&gt;Medial Axis Transformation&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Shaiba Bano&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Urban Design&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sshaiba3&#34;&gt;sshaiba3&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-outdoorplus&#34;&gt;Microclimate-UMCF&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Nitiksha Mota&lt;/td&gt; &lt;td&gt;Masters&lt;/td&gt; &lt;td&gt;Urban Design&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/nmota6&#34;&gt;nmota6&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-outdoorplus&#34;&gt;Microclimate-UMCF&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Lucy Chai&lt;/td&gt; &lt;td&gt;Freshman&lt;/td&gt; &lt;td&gt;Industrial Engineering&lt;/td&gt; &lt;td&gt;ISYE&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/lucymchai&#34;&gt;lucymchai&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-mobility&#34;&gt;Mobility-PEI&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sina Rahimi&lt;/td&gt; &lt;td&gt;PhD&lt;/td&gt; &lt;td&gt;Architectural Science&lt;/td&gt; &lt;td&gt;ARCH&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/sinarhm&#34;&gt;sinarahimi&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-outdoorplus&#34;&gt;Microclimate‑UMCF&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ze Yu Jiang&lt;/td&gt; &lt;td&gt;Junior&lt;/td&gt; &lt;td&gt;Computer Science&lt;/td&gt; &lt;td&gt;SCS&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;https://github.com/zeyujiang8800&#34;&gt;zeyujiang8800&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&#34;../../25fa-microclimate-ml&#34;&gt;Microclimate‑ML&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;</description> <link>https://vip-smur.github.io/team/25-Fa/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Wed, 10 Dec 2025 05:18:38 -0500</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/team/25-Fa/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/team/25-Fa/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/team/25-Fa.png" type="image/png" length="35680" /> </item> <item> <title>Projects</title> <description>&lt;h1 id=&#34;fall-2024&#34;&gt;Fall 2024&lt;/h1&gt; &lt;hr /&gt; &lt;div class=&#34;grid cards&#34;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--&gt;&lt;path d=&#34;M120 56c0-30.9 25.1-56 56-56h24c17.7 0 32 14.3 32 32v448c0 17.7-14.3 32-32 32h-32c-29.8 0-54.9-20.4-62-48h-2c-44.2 0-80-35.8-80-80 0-18 6-34.6 16-48-19.4-14.6-32-37.8-32-64 0-30.9 17.6-57.8 43.2-71.1-7.1-12-11.2-26-11.2-40.9 0-44.2 35.8-80 80-80zm272 0v24c44.2 0 80 35.8 80 80 0 15-4.1 29-11.2 40.9C486.5 214.2 504 241 504 272c0 26.2-12.6 49.4-32 64 10 13.4 16 30 16 48 0 44.2-35.8 80-80 80h-2c-7.1 27.6-32.2 48-62 48h-32c-17.7 0-32-14.3-32-32V32c0-17.7 14.3-32 32-32h24c30.9 0 56 25.1 56 56&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Neuroarchitecture&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Explores the concept of &lt;em&gt;neuroarchitecture&lt;/em&gt;, which is the intersection of neuroscience and architecture.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Changda Ma, Misha Lee, L. Q. Nhu Nguyen, Parya Monjezi&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-neuroarchitecture/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13 3v8h8V3zM3 21h8v-8H3zM3 3v8h8V3zm10 13h3v-3h2v3h3v2h-3v3h-2v-3h-3z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;MPONC&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Multi-agent game theoretical approaches to simulating neighborhood processes.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Matthew Lim, Reyli Olivo, Devam Mondal&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-mponc/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M5 3v18h6v-3.5h2V21h6V3zm2 2h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zM7 9h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm4 0h2v2h-2zm4 0h2v2h-2zm-8 4h2v2H7zm8 0h2v2h-2z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Energy in Commercial Buildings&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Modeling energy demand in commercial buildings.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Joseph M. Aerathu, Anubha Mahajan, Jessica Hernandez, Han-Syun Shih&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-energyinbuildings-com/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Energy in Residential Buildings&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Modeling energy demand in residential buildings.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Sharmista Debnath, Kiana Layam, Jiayi Li, Shivam Patel&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-energyinbuildings-res/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Geo-LSTM-Kriging&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Continues work on surrogate models estimating urban heat island effects.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Sofia Mujica, Abigail Herbas, Ze Yu Jiang, Krish Gupta, Thanasarn Changnawa&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-microclimate-lstm-kriging/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M19 9V7a2 2 0 0 0-2-2h-1V2h-2v3h-1a2 2 0 0 0-2 2v2a2 2 0 0 0-2 2v1H5a2 2 0 0 0-2 2v8h3v-2h2v2h4v-2h2v2h2v-2h2v2h3V11a2 2 0 0 0-2-2M8 18H6v-2h2zm6 0h-2v-2h2zm0-4h-2v-2h2zm-1-5V7h4v2zm5 9h-2v-2h2zm0-4h-2v-2h2z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Urban Microclimate Modeling (UMCF)&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Rhino &amp;amp; Grasshopper workflows for urban microclimate modeling.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; Marcelo Álvarez, Gonzalo Vegas, Shruti Jadhav, Rui Shen, Chinmay Rothe&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-microclimate-umcf/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;span class=&#34;twemoji lg middle&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 384 512&#34;&gt;&lt;!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--&gt;&lt;path d=&#34;M192 80a56 56 0 1 0 0-112 56 56 0 1 0 0 112m-86.6 147.9 22.6-22.6v69.3c0 28 12.2 54.7 33.5 72.9l71.4 61.2c5.9 5.1 9.8 12.1 10.9 19.8l12.6 88.1c2.5 17.5 18.7 29.7 36.2 27.2s29.7-18.7 27.2-36.2l-12.6-88.1c-3.3-23.1-14.9-44.1-32.6-59.3l-34.5-29.6V215.4l3.8 4.7c18.2 22.8 45.8 36 75 36h33.2c17.7 0 32-14.3 32-32s-14.3-32-32-32h-33.2c-9.7 0-18.9-4.4-25-12L276 157.7c-23-28.8-57.9-45.6-94.8-45.6-32.2 0-63.1 12.8-85.8 35.6l-35.3 34.9c-18 18-28.1 42.4-28.1 67.9V288c0 17.7 14.3 32 32 32s32-14.3 32-32v-37.5c0-8.5 3.4-16.6 9.4-22.6m12.4 179.4c-1.5 5.2-4.3 10-8.1 13.8l-68.3 68.3c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l68.3-68.3c11.5-11.5 19.9-25.8 24.4-41.5l2.2-7.6-46-39.4c-2.5-2.2-5-4.4-7.4-6.8z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; &lt;strong&gt;Pedestrian Environment Index (PEI)&lt;/strong&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Improvements on the PEI methodology, a composite metric of walkability using key subindices.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Team:&lt;/strong&gt; C. “Albert” Le, Chunlan Wang, Yichao Shi, Atharva Beesen&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;a href=&#34;../../24fa-mobility-pei/&#34;&gt;&lt;span class=&#34;twemoji&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path d=&#34;M13.22 19.03a.75.75 0 0 1 0-1.06L18.19 13H3.75a.75.75 0 0 1 0-1.5h14.44l-4.97-4.97a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0&#34;/&gt;&lt;/svg&gt;&lt;/span&gt; Learn more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;</description> <link>https://vip-smur.github.io/projects/24fa/?utm_source=documentation&amp;utm_medium=RSS&amp;utm_campaign=feed-syndication</link> <pubDate>Wed, 10 Dec 2025 04:11:35 -0500</pubDate> <source url="https://vip-smur.github.io/feed_rss_updated.xml">Surrogate Modeling for Urban Regeneration (SMUR)</source><comments>https://vip-smur.github.io/projects/24fa/#__comments</comments><guid isPermaLink="true">https://vip-smur.github.io/projects/24fa/</guid> <enclosure url="https://vip-smur.github.io/assets/images/social/projects/24fa/README.png" type="image/png" length="None" /> </item> </channel> </rss>