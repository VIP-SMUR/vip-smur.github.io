{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VIP-SMUR","text":"<p>Welcome to the project page of the VIP team Surrogate Modeling for Urban Regeneration (SMUR) at Georgia Tech.  This course is led by Dr. Patrick Kastner, head of the Sustainable Urban Systems Lab.</p>"},{"location":"#the-problem","title":"\ud83d\udcdd The Problem","text":"<p>Many performance-related decisions in architectural and urban design happen too late in the decision-making process to ensure they suit the clients' purposes.  We believe this hinders true urban regeneration.  This research course challenges this status quo by developing software tools that empower communities and urban decision-makers.</p> MacLeamy Curve illustrating the need for rapid performance feedback in architectural decision-making. (more info) <p>Our models will enable urban decision-making by enabling real-time testing of interventions.  By involving a multitude of urban stakeholders, we make regenerative cities tangible, actionable, and inclusive.  Our work will address:</p> <ul> <li>Air quality, pollution, natural ventilation potential</li> <li>Microclimate assessment (outdoor thermal comfort, urban heat islands)</li> <li>Flood, stormwater, water runoff</li> <li>Mobility, walkability, transportation</li> <li>Global warming, climate change (heat waves)</li> <li>Urban building energy, district energy, decarbonization modeling</li> <li>Etc.</li> </ul>"},{"location":"#goals","title":"\ud83c\udfaf Goals","text":"<p>Conventional environmental simulation approaches in urban design are time-consuming and often incompatible with fast-paced decision-making processes.  This VIP aims to address this outdated paradigm by developing surrogate models that accelerate simulations (typically via machine learning) that offer real-time feedback to urban decision-makers, such as architects, urban designers, and policymakers.</p> <p>Our goal is to seamlessly integrate sustainability considerations into every step of urban decision-making processes by integrating our models with industry-leading CAD tools such as <code>Rhino</code> and <code>Revit</code>, <code>QGIS</code>, <code>ArcGIS</code>, and making them usable even in the browser.</p>"},{"location":"#prerequisites","title":"\u2705 Prerequisites","text":"<p>We seek an interdisciplinary team of highly motivated students.  Experience with <code>Python</code>, <code>C#</code>, <code>JavaScript</code>, <code>machine learning</code>, and <code>simulation modeling</code> will be advantageous.  Our sub-teams typically are interdisciplinary and consist of students from:</p> <ul> <li>Computer Science / Engineering (Civil, Environmental, Mechanical, etc.)</li> <li>(Applied) Industrial and Systems Engineering</li> <li>Architecture &amp; Urban Design</li> <li>City &amp; Regional Planning</li> <li>Applied Math &amp; Physics</li> <li>Public Policy</li> <li>Etc.</li> </ul> <p>If your major is not mentioned, please contact us to see if your background might be a good fit.  We're happy to help!</p>"},{"location":"#project-overview","title":"\ud83d\udcca Project Overview","text":"<p>Our current and previous projects include topics on:</p> <ol> <li>Energy in Buildings</li> <li>Urban Microclimate</li> <li>Mobility and Walkability</li> <li>Game Theory and Neighborhood Processes</li> <li>The Intersection of Neuroscience, Architecture &amp; Urbanism</li> </ol>"},{"location":"#get-involved","title":"\ud83e\udd1d Get Involved","text":"<p>Click here to learn more!</p>"},{"location":"macleamy/","title":"Macleamy","text":"MacLeamy Curve illustrating the need for rapid performance feedback in architectural decision-making. (more info)"},{"location":"activities/","title":"Activities","text":"<ul> <li> <p> Class Dinners</p> <p> Learn more</p> </li> <li> <p> Conferences</p> <p> Learn more</p> </li> </ul>"},{"location":"activities/conferences/","title":"Conference Visits","text":""},{"location":"activities/conferences/#fall-2024","title":"Fall 2024","text":"Georgia Undergraduate Research Conference 2024 in Oxford, GA    Anubha Mahajan, Jessica Hernandez, Jiayi Li, Joseph Mathew Aerathu, Sharmista Debnath, Kiana-Karla Layam,  Han-Syun Shih, Hang Xu, and Patrick Kastner. Photo credits: Han-Syun Shih GNI Symposium on AI for the Built World in Munich, Germany.    Ze Yu Jiang, Sofia Mujica, Silvia Vangelova, and Patrick Kastner"},{"location":"activities/conferences/#spring-2024","title":"Spring 2024","text":"Anubha Mahajan representing VIP-SMUR at the Spring 24 BBISS Sustainability Showcase."},{"location":"activities/dinners/","title":"Class Dinner","text":""},{"location":"activities/dinners/#spring-2025","title":"Spring 2025","text":"VIP-SMUR Pizza Night 2025 in front of ARCH West"},{"location":"activities/dinners/#fall-2024","title":"Fall 2024","text":"VIP-SMUR Dinner at Boho Taco Fall 24"},{"location":"projects/","title":"Project Repository","text":""},{"location":"projects/#semester-overview","title":"Semester Overview","text":"<ul> <li> <p> Spring 2025</p> <p> Learn more</p> </li> <li> <p> Fall 2024</p> <p> Learn more</p> </li> <li> <p> Spring 2024</p> <p> Learn more</p> </li> </ul>"},{"location":"projects/24fa/","title":"Projects","text":""},{"location":"projects/24fa/#fall-2024","title":"Fall 2024","text":"<ul> <li> <p> Neuroarchitecture</p> <p>Explores the concept of neuroarchitecture, which is the intersection of neuroscience and architecture.</p> <p> Learn more</p> </li> <li> <p> MPONC</p> <p>Multi-agent game theoretical approaches to simulating neighborhood processes.</p> <p> Learn more</p> </li> <li> <p> Energy in Commercial Buildings</p> <p>Modeling energy demand in commercial buildings.</p> <p> Learn more</p> </li> <li> <p> Energy in Residential Buildings</p> <p>Modeling energy demand in residential buildings.</p> <p> Learn more</p> </li> <li> <p> Geo-LSTM-Kriging</p> <p>Continues work on surrogate models estimating urban heat island effects.</p> <p> Learn more</p> </li> <li> <p> Urban Microclimate Modeling (UMCF)</p> <p>Rhino &amp; Grasshopper workflows for urban microclimate modeling.</p> <p> Learn more</p> </li> <li> <p> Pedestrian Environment Index (PEI)</p> <p>Improvements on the PEI methodology, a composite metric of walkability using key subindices.</p> <p> Learn more</p> </li> </ul>"},{"location":"projects/24sp/","title":"Projects","text":""},{"location":"projects/24sp/#spring-2024","title":"Spring 2024","text":"<ul> <li> <p> Pedestrian Environment Index (PEI)</p> <p>Implements the PEI methodology, a composite measure of walkability using four key subindices.</p> <p> Learn more</p> </li> <li> <p> Segregation in the 15-Minute City</p> <p>Investigates segregation on a basis of mobility within the context of a 15-minute city.</p> <p> Learn more</p> </li> <li> <p> Urban Weather Generator (UWG)</p> <p>Modeling of the urban heat island effect using EnergyPlus (.epw) weather files.</p> <p> Learn more</p> </li> <li> <p> Multivariate Regression of Energy Consumption</p> <p>Machine learning approaches to model building energy demand.</p> <p> Learn more</p> </li> </ul>"},{"location":"projects/25sp/","title":"Projects","text":""},{"location":"projects/25sp/#spring-2025","title":"Spring 2025","text":"<ul> <li> <p> Neuroarchitecture</p> <p>Explores the concept of neuroarchitecture, which is the intersection of neuroscience and architecture.</p> <p> Learn more</p> </li> <li> <p> MPONC</p> <p>Multi-agent game theoretical approaches to simulating neighborhood processes.</p> <p> Learn more</p> </li> <li> <p> Energy in Buildings</p> <p>Modeling energy demand in buildings.</p> <p> Learn more</p> </li> <li> <p> Geo-LSTM-Kriging</p> <p>Continues work on surrogate models estimating urban heat island effects.</p> <p> Learn more</p> </li> <li> <p> Urban Microclimate Modeling (UMCF)</p> <p>Rhino &amp; Grasshopper workflows for urban microclimate modeling.</p> <p> Learn more</p> </li> <li> <p> Pedestrian Environment Index (PEI)</p> <p>Improvements on the PEI methodology, a composite metric of walkability using key subindices.</p> <p> Learn more</p> </li> </ul>"},{"location":"team/","title":"Team overview","text":"<ul> <li> <p>Spring 2025</p> </li> <li> <p>Fall 2024</p> </li> <li> <p>Spring 2024</p> </li> </ul>"},{"location":"team/24-Fa/","title":"Fall 2024","text":"Name Seniority Major School # Semesters GitHub Handle Topic Area Joseph M. Aerathu Masters Architecture (HPB) ARCH 1 jma1999 Energy-In-Buildings-Com Matthew Lim Sophomore Computer Science SCS 1 mlim70 MPONC Marcelo Alvarez Masters Architecture (DC) ARCH 1 alvarezdmarch Microclimate-UMCF Changda Ma Masters Architecture ARCH 1 changdama Neuroarchitecture Anubha Mahajan Senior Computer Science SCS 2 amahajan68 Energy-In-Buildings-Com Jessica Hernandez Senior Computer Science SCS 1 jhernandez312 Energy-In-Buildings-Com C. \"Albert\" Le Sophomore Computer Engineering ECE 1 balbertle Mobility-PEI Misha Lee Sophomore Civil Engineering CEE 1 memesha Neuroarchitecture Reyli Olivo Junior Civil Engineering CEE 1 Rolivo05 MPONC Sharmista Debnath Masters Architecture (HBP) ARCH 1 Myshx Energy-In-Buildings-Res Kiana Layam Masters Architecture (HBP) ARCH 1 kkvlayam Energy-In-Buildings-Res Han-Syun Shih Masters Architecture (HBP) ARCH 1 hshih38 Energy-In-Buildings-Com Sofia Mujica Junior Mechanical Engineering ME 2 sofia-mujica Microclimate-LSTM-Kriging L. Q. Nhu Nguyen Masters Architecture ARCH 1 qnguyen322 Neuroarchitecture Abigail Herbas Junior Computer Science SCS 2 aherbas3 Microclimate-LSTM-Kriging Chunlan Wang Masters Architecture (DC) ARCH 1 wang-123-xi Mobility-PEI Gonzalo Vegas PhD Architecture ARCH 2 gvegasol Microclimate-UMCF Yichao Shi PhD Architecture ARCH 1 SHIyichao98 Mobility-PEI Jiayi Li Junior Architecture ARCH 1 jli3307 Energy-In-Buildings-Res Shruti Jadhav Masters Architecture (HBP) ARCH 1 ShrutiJadhav27 Microclimate-UMCF Shivam Patel Senior Computer Science SCS 2 FlippyShivam Energy-In-Buildings-Res Atharva Beesen Junior Computer Science SCS 1 AtharvaBeesen Mobility-PEI Ze Yu Jiang Junior Computer Science SCS 2 zeyujiang8800 Microclimate-LSTM-Kriging Devam Mondal Junior Computer Science SCS 1 Dodesimo MPONC Rui Shen Masters Architecture (DC) ARCH 1 ShiRo-25 Microclimate-UMCF Krish Gupta Junior Civil Engineering CEE 1 krishgupta-CE Microclimate-LSTM-Kriging Thanasarn Changnawa PhD Architecture ARCH 1 Thanasarn-Changnawa Microclimate-LSTM-Kriging Chinmay Rothe Masters Architecture (HPB) ARCH 1 ChinmayR5 Microclimate-UMCF Hang Xu PhD Architecture ARCH 1 HangXXXu Energy-In-Buildings Parya Monjezi Masters Architecture (HBP) ARCH 1 Pmonjezi3 Neuroarchitecture"},{"location":"team/24-Sp/","title":"Spring 2024","text":"Name Seniority Major School # Semesters GitHub handle Topic Area Neha Nakirikanti Sophomore Computer Science SCS 1 nehanak Mobility-PEI Vishal Maradana Senior Computer Science SCS 1 vishal-337 Mobility-PEI Joshua R Cohen Junior Civil Engineering CEE 1 paradoxwalk Mobility-PEI Abigail Herbas Sophomore Computer Science SCS 1 aherbas3 Energy-In-Buildings Anubha Mahajan Junior Computer Science SCS 1 amahajan68 Energy-In-Buildings Aarit Gupta Sophomore Mechanical Engineering ME 1 aaritg Energy-In-Buildings Shivam Patel Junior Computer Science SCS 1 FlippyShivam Energy-In-Buildings Maryam Almaian Masters Architecture (HPB) ARCH 1 maryamalmaian Microclimate Sofia A Mujica Sophomore Mechanical Engineering ME 1 sofia-mujica Microclimate Ze Yu Jiang Sophomore Computer Science SCS 1 zeyujiang8800 Microclimate Gonzalo Vegas Ph.D. Architecture ARCH 1 gvegasol Mobility-Seg Parker Bredice Sophomore Mechanical Engineering ME 1 parkerbredice Mobility-Seg Thien-An Dang Senior Industrial Engineering ISYE 1 tdang66 Mobility-Seg Sahil Handa Junior Computer Engineering ECE 1 handasahil Mobility-Seg Silvia Vangelova Masters Online MS Analytics ISYE 1 xtearas Sp24"},{"location":"team/25-Sp/","title":"Spring 2025","text":"SMUR 2025 Team Picture Name Seniority Major School # Semesters GitHub Handle Topic Area Joseph M. Aerathu Masters Architecture (HPB) ARCH 2 jma1999 Energy-In-Buildings Matthew Lim Sophomore Computer Science SCS 2 mlim70 MPONC Marcelo \u00c1lvarez Masters Architecture (DC) ARCH 2 alvarezdmarch Microclimate-UMCF Changda Ma Masters Architecture ARCH 2 changdama Neuroarchitecture Anubha Mahajan Senior Computer Science SCS 3 amahajan68 Energy-In-Buildings Jessica Hernandez Masters Computer Science SCS 2 jhernandez312 Energy-In-Buildings Han-Syun Shih Masters Architecture (HBP) ARCH 2 Benjaminhansyun Microclimate-LSTM-Kriging Thanasarn Changnawa PhD Architecture ARCH 2 Thanasarn-Changnawa Microclimate-LSTM-Kriging Hang Xu PhD Architecture (HBP) ARCH 2 HangXXXu Energy-In-Buildings Justin Xu Sophomore Computer Science SCS 1 JXU037 MPONC Jiayi Li Junior Architecture ARCH 2 jli3307 Energy-In-Buildings Marcellus English Sophomore Civil Engineering CEE 1 mcenglish Microclimate-UMCF Kavya Lalith Sophomore Computer Engineering ECE 1 kavya-oop Energy-In-Buildings Krish Gupta Junior Civil Engineering CEE 2 krishgupta-CE Microclimate-LSTM-Kriging Victor Wang Freshman Industrial Engineering ISYE 1 vdwang Microclimate-UMCF Catherine Wallis Senior Architecture ARCH 1 cgwallis Neuroarchitecture Atharva Beesen Junior Computer Science SCS 2 AtharvaBeesen Mobility-PEI Joshua Cohen Senior Civil Engineering CEE 2 paradoxwalk Mobility-PEI Mason Dewitt Freshman Computer Engineering ECE 1 Masonrd Mobility-PEI Johnny Chen Freshman Computer Science SCS 1 jxchen21 Energy-In-Buildings Yupeng Tang Masters Computer Science SCS 1 yupengtang Microclimate-LSTM-Kriging Dayeon Song Freshman Industrial Engineering ISYE 1 daytss Microclimate-LSTM-Kriging Gonzalo Vegas PhD Architecture ARCH 3 gvegasol Microclimate-UMCF Sina Rahimi PhD Architectural Science ARCH 2 sinarahimi Microclimate-UMCF Ze Yu Jiang Junior Computer Science SCS 3 zeyujiang8800 Microclimate-LSTM-Kriging Nicholas Stone Junior Computer Science SCS 1 nstone213 Mobility-PEI Devam Mondal Junior Computer Science SCS 2 Dodesimo MPONC Nithish Sabapathy Junior Computer Science SCS 1 nithish101 MPONC Shivam Patel Junior Computer Science SCS 3 FlippyShivam Energy-In-Buildings Yao   Xiao Sophomore Computer Science SCS 1 Xyrro Mobility-PEI Yichao Shi PhD Architecture (DC) ARCH 2 SHIyichao98 Energy-In-Buildings"},{"location":"get-involved/profile/","title":"\ud83e\udd1d Get Involved","text":"<p>Join our team and make a lasting impact on urban environments!</p> <ul> <li>Learn More (undergraduate) </li> <li>Learn More (graduate) </li> <li>Contact Us</li> </ul>"},{"location":"get-involved/profile/#project-wiki","title":"\ud83d\udcc4 Project Wiki","text":"\ud83d\udcc1 \u00a0 Current and previous projects \u2192 \u00a0 Learn more"},{"location":"25sp-mponc/","title":"25Sp-MPONC","text":"<p>'Modeling Processes of Neighborhood Change'</p>"},{"location":"25sp-mponc/#reference-paper","title":"Reference paper","text":"<pre><code>@misc{mori2024modelingprocessesneighborhoodchange,\n      title={Modeling Processes of Neighborhood Change}, \n      author={J. Carlos Mart\u00ednez Mori and Zhanzhan Zhao},\n      year={2024},\n      eprint={2401.03307},\n      archivePrefix={arXiv},\n      primaryClass={cs.MA},\n      url={https://arxiv.org/abs/2401.03307}, \n}\n</code></pre>"},{"location":"25sp-mponc/#setup","title":"Setup","text":"<pre><code>cd 25Sp-MPONC/modeling_processes_of_neighborhood_change_new\nconda create -n mponc python=3.10.16\nconda activate mponc\npip install -r requirements.txt\npython main.py\n</code></pre>"},{"location":"25sp-mponc/#abstract","title":"Abstract","text":"<p>This research project simulates the impact of the Atlanta Beltline on the surrounding metropolitan area using game theory. The simulation models agent movement across census tracts within the Atlanta-Sandy Springs-Roswell metro region, with agents seeking to move optimally (seeking 'attractive' census tracts) based on various factors.</p>"},{"location":"25sp-mponc/#intro-and-description","title":"Intro and Description","text":"<p>This project is based on the reference paper created by Dr. Martinez and Dr. Zhao, which aims to address the following:  - How does the layout of transportation infrastructure affect the demographics of nearby neighborhoods? - Does the creation of these infrastructure actually benefit everyone equally; is it fair? - Can we predict the effects on surrounding communities before these structures are actually built?</p> <p>These questions are primarily motivated by the issue of gentrification, an issue prevalent in many major cities. We utilized concepts in game theory, more specifically no-regret dynamics, in order to simulate the effects of the Atlanta Beltline on gentrification. To summarize our approach with no-regret dynamics:</p> <ul> <li>People, or 'agents', randomly move from region to region. Depending the region's attributes, a 'cost' value is assigned to each action.</li> <li>'Cost' is a function of region attractiveness, affordability, and community.</li> <li>The higher the cost, the less likely an agent is to visit that census tract in the future.</li> <li>This process is repeated until the probability distribution of visting census tracts converges - an equilibrium is reached, and further actions make no difference.</li> <li>We compute the simulation convergance using the total\u2011variation distance between two sliding windows of recent agent\u2011distributions: <pre><code>\\mathrm{TV}(p,q)\\;=\\;\\tfrac12\\sum_{c}\\lvert\\,p(c)-q(c)\\rvert\\,.\n</code></pre>   If TV\u00a0\u2264\u00a0<code>EPS_CONVERGENCE</code> (default\u202f=\u202f0.005) the system is deemed converged and the run halts automatically. All thresholds are configurable in <code>config.py</code>.</li> <li>Alternatively, we can use a hardcoded runtime.</li> </ul>"},{"location":"25sp-mponc/#cost-function","title":"Cost Function","text":"<p>Every agent evaluates a tract with a cost defined as</p> <p>cost = 1\u00a0\u2013\u00a0(affordability\u00a0\u00d7\u00a0attractiveness\u00a0\u00d7\u00a0community)</p> Factor Scale Quick intuition Affordability 0\u00a0or\u00a01 1 if the tract still has room or the agent is randomly selected to be an inhabitants (weight scales with relative wealth); 0 otherwise. Attractiveness 0\u20131 How nice the tract is to live in (see sub\u2011components below). Community 0\u20131 How close the agent\u2019s income is to the local average\u2014closer \u21d2 higher score."},{"location":"25sp-mponc/#attractiveness-upkeep-amenity_access-beltline_factor","title":"Attractiveness\u00a0=\u00a0upkeep\u00a0\u00d7\u00a0amenity_access\u00a0\u00d7\u00a0beltline_factor","text":"Sub\u2011component Range What it captures Upkeep 0\u00a0or\u00a01 0 if the tract is abandoned (no residents); 1 otherwise. Amenity\u00a0access 0\u20131 Density of key POIs (restaurants, shops, transit stops, etc) weighted by distance. BeltLine factor\u202f\u03b2 \u2264\u202f1 Extra accessibility for tracts in the BeltLine zone: \u03b2\u202f=\u202f1.00 at \u2264\u202f800\u202fm, tapering linearly to \u03b2\u202f=\u202f0.917 (1.10/1.20) at 1.6\u202fkm, then \u03b2\u202f=\u202f0.833 (1.0/1.20). <p>*\u00a0Amenity list adapted from 24Sp\u2011Mobility\u2011Seg; we omit several tags such as \u201cshed\u201d, \u201cguardhouse\u201d, \u201cferry_terminal\u201d, \u201cgarages\u201d, and \u201cbridge\u201d.</p>"},{"location":"25sp-mponc/#implemented-amenities-weights-openstreetmap-labels","title":"Implemented Amenities &amp; weights (OpenStreetMap labels):","text":"<p><pre><code>AMENITY_TAGS = {\n      'amenity': (\"bus_station|cafe|college|fast_food|food_court|fuel|library|restaurant|train_station|university|parking|school|hospital\", 3),\n      'shop': (\"supermarket|food|general|department_store|mall|wholesale\", 3),\n      'landuse': (\"residential|industrial|commercial|retail\", 2)\n}\n</code></pre> * We operationalize \u03b2 by giving tracts within 800\u202fm of the BeltLine a +20\u202f% boost to their Attractiveness score (\u03b2\u202f=\u202f1.20/1.20); the boost then tapers linearly to +10\u202f% at 1.6\u202fkm, and falls to \u03b2\u202f=\u202f1.00/1.20 beyond that distance.  These concrete percentages and distance bands approximate the BeltLine\u2019s observed catchment zone and its predicted effect on nearby housing prices.</p>"},{"location":"25sp-mponc/#community-score-local-morans-i","title":"Community Score (Local Moran\u2019s I)","text":"<p>We quantify how well an agent\u2019s income matches its neighbours using Local Moran\u2019s I:</p> \\[ I_c = \\frac{(w_c - \\bar w)}{S^2}       \\sum_{j \\in N(c)} w_{cj}\\,(w_j - \\bar w), \\quad S^2 = \\frac{1}{n}\\sum_{k=1}^n (w_k - \\bar w)^2 \\] <ul> <li><code>w_c</code>     = average income in tract c  </li> <li><code>w\u0304</code>       = regional mean income  </li> <li><code>w_{cj}</code> = spatial weight (1 for adjacent tracts, 0 otherwise)  </li> <li><code>N(c)</code>   = neighbouring tracts of c  </li> </ul> <p>Each agent i with income <code>w_i</code> converts this statistic into a smooth score:</p> \\[ \\mathrm{Community}_i(c)   = \\exp\\bigl(-\\alpha\\,\\lvert w_i - I_c\\rvert\\bigr) \\] <p>where <code>\u03b1</code> is set in <code>config.py</code>. A closer match \u21d2 value near 1 \u21d2 lower cost.</p>"},{"location":"25sp-mponc/#weighting-amenity-access-vs-community","title":"Weighting amenity access vs\u202fcommunity (\u03bb)","text":"<p>A tunable parameter \u03bb\u00a0\u2208\u00a0[0,\u202f1] lets you emphasize either amenity access (high\u202f\u03bb) or community match (low\u202f\u03bb). Internally we rewrite <pre><code>cost = 1 - [[Affordability] \u00d7 [Upkeep x (\u03bb \u00d7 AmenityAccess)] \u00d7 [(1-\u03bb) \u00d7 Community]]\n</code></pre></p>"},{"location":"25sp-mponc/#the-four-step-model","title":"The Four-Step Model","text":"<p>Given that the agents move across various subregions in our simulation, one of the critical steps is determining the mode of transport of each agent. To do this in a way that accurately represents real-world distributions, we turned to the four-step model, a common trip generation algorithm: </p> <p></p> <p>The model has four components:</p> <ol> <li>Trip Generation: This part of the model estimates the number of trips originating from or destined for a specific area. It focuses on understanding how many trips are generated rather than specific travel patterns. This process usually involves some type of data pertaining to the area at hand, such as demographics, income, or land usage.</li> <li>Trip Distribution; This part of the model estimates the number of trips for routes that go from an area to another, as determined in the trip generation step. This process is typically done using the gravity model, which assumes that the number of trips are positively correlated with the attractiveness of an area and inversely correlated to distance.</li> <li>Mode Choice: This part of the model determines the mode of transporation used to make the trips. This is typically done by considering demographic data (such as the percentage of people with cars) in an area.</li> <li>Route Assignment: This part of the model determines the routes travelers take between origins and destinations. This is typically done by considering the route that takes the shorted possible time, and following that. </li> </ol> <p>Our approach closely follows these four components. We first generate trips by considering the amenity density of areas. We sum up all amenity densities, and divide each area's density by this sum to generate a probability. We then utilize a Poisson Distribution to generate the number of trips by multipling a base number of trips by the probability. We then consider trip distribution through a modified gravity model. The equation for our model is the following, given that we aim to go from area/region i to j:</p> <p></p> <p>We essentially multiply the total number of trips from area i to area j with the net amenity score for the destination j times transportation cost for that specific trip from area i to j, divided by the net amenity score for area j times the transportation cost from area i to j summed up over all destination j's. </p> <p>For our modal split, we assume that the car ownership rate is 0.7, and that the transit rate is 0.3. Each region's trips are split based on this. We then assign these routes based on the shortest possible distance.</p> <p>Through this process, we were able to have a methodical way of distributing the agents across Atlanta based on area factors such as amenity density.</p>"},{"location":"25sp-mponc/#tigerline-geodatabases-shapefiles","title":"TIGER/Line Geodatabases shapefiles:","text":""},{"location":"25sp-mponc/#project-status","title":"Project status","text":""},{"location":"25sp-mponc/#outputs-configuration","title":"Outputs &amp; configuration","text":"<p>Our code outputs a GIF to visualize agent behavior over time. Each circle represents the centroid of a census tract - green signifying those in the Atlanta Beltline - and the encircled number is the agent population. Our code also outputs a CSV file containing all the simulated data at every individual timestep.</p> <ul> <li>Data contained in CSV's: Census tract name, agent population, raw average income, average income reported by census, normalized average incomes, and amenity density.</li> <li>Note: 'Timestep' refers to a single instance agent action (relocation); 20,000 timesteps mean the agents relocate a total of 20,000 times during the simulation.</li> </ul>"},{"location":"25sp-mponc/#gif","title":"GIF","text":"<p>This GIF shows the behavior of 1,000 agents up to 20,000 timesteps, frames being captured every 400 timesteps. Rho=1, alpha=0.25. </p>"},{"location":"25sp-mponc/#runtimes","title":"Runtimes","text":"<p>(1000 agents, 349 census tracts) - Simulation (x8): ~19.6 minutes - GIF creation (x8), 50 frames: ~10 min * Graph, amenities, and centroids are cached after first build</p>"},{"location":"25sp-mponc/#census-based-approach","title":"Census-based approach","text":"<p>Our project utilizes US Census data in that: - The geographical regions our agents inhabit correspond directly to US census tracts (can correspond to any other census-defined geographic unit, i.e. zip codes, housing districts, and school districts).  - Each 'agent' is assigned a 'wealth' value in our simulation. We create this distribution of wealth using Census data (population &amp; median incomes), to represent real-world demographics.</p>"},{"location":"25sp-mponc/#atlanta-beltline-in-our-simulation","title":"Atlanta Beltline in our Simulation","text":"<p>We automate the process of labelling certain regions as 'in the Atlanta Beltline' by using commuting paths from OpenStreetMap that correspond to the Atlanta Beltline - namely, a bike trail and a railway. To experiment with a different beltline, such as a beltline that spanned across Atlanta horizontally, or simply expanded north by x miles, we would acquire the OpenStreetMap ID's of existing paths (bike trails, walking paths, roads, etc.) corresponding to our desired Beltline, and paste these into config.py. Alternatively, we can create a such path ourselves in OpenStreetMap. Then, any region containing segments of these trails would automatically be marked as \"In the Atlanta Beltline\". </p> <p>In config.py - bike trail and railroad OpenStreetMap ID's for the beltline are as follows:</p> <pre><code>\"\"\" Beltline 'relation' IDs from Open Street Map \"\"\"\nRELATION_IDS = [8408433, 13048389]\n</code></pre> Bike Trail Railroad <p>Compare with Atlanta Beltline geography:</p> <p></p>"},{"location":"25sp-mponc/#adapting-the-model-to-other-cities","title":"Adapting the Model to Other Cities","text":"<p>Although Atlanta serves as our case study, every pipeline stage\u2014census shapefiles, OSM\u2011derived amenities, cost parameters, and even the BeltLine decision\u2011agent\u2014can be swapped for a different region:</p> <ol> <li> <p>Geometry &amp; Demographics    \u2022 Replace the Fulton/DeKalb TIGER/Line shapefiles with those of your target city.    \u2022 Point the <code>MEDIAN_INCOME_URL</code> and <code>POP_URL</code> in <code>config.py</code> to that city\u2019s American Community Survey \"ACS\" tables.</p> </li> <li> <p>Transit\u2011Ring Definition    \u2022 Identify (or sketch in OSM) the planned loop / BRT corridor / rail spur you want to study, then list its OSM relation IDs in <code>config.py</code>.    \u2022 The same \u03b2\u2011taper and DecisionAgent logic will assign accessibility boosts and density bonuses around the new corridor.</p> </li> <li> <p>Policy Levers    \u2022 Tweak <code>RHO_SCALAR</code> to explore how strong the up\u2011zoning response should be for the above transit ring.</p> </li> </ol> <p>Because the simulation is purely data\u2011driven, you can rapidly prototype \u201cwhat\u2011if\u201d BeltLine analogues for anywhere with open census and OSM data while measuring potential community shifts/gentrification before shovels hit the ground. Example:  * By changing the above URL, we get the following:</p> <p></p>"},{"location":"25sp-mponc/#policy-scenarios-vertical-vs-horizontal-scaling","title":"Policy Scenarios: Vertical vs Horizontal Scaling","text":"<p>The simulation now supports two high-level policy experiments:</p>"},{"location":"25sp-mponc/#1-vertical-scaling-decision-making-agent-learns-m","title":"1. Vertical Scaling \u2014 Decision-Making Agent learns \\(m\\)","text":"<p>A dedicated <code>DecisionAgent</code> treats \u201chow aggressively should we up-zone?\u201d as a learning problem:</p> <ul> <li>Action space:</li> </ul> \\[ m \\in \\{0.00,\\,0.01,\\,\\dots,\\,1.00\\} \\] <p>sampled each timestep by multiplicative\u2011weights\u00a0(no\u2011regret).</p> <ul> <li>Base capacity curve:</li> </ul> <pre><code>U_c = 1 + \\frac{\\texttt{beltline\\_score}_c - \\texttt{BL\\_LOW}}{\\texttt{BL\\_HIGH} - \\texttt{BL\\_LOW}} \\times \\bigl(\\texttt{RHO\\_SCALAR}_{max} - 1\\bigr) \n</code></pre>"},{"location":"25sp-mponc/#effective-multiplier","title":"Effective multiplier","text":"\\[ \\rho_c  \\;\\leftarrow\\;  \\rho_c  \\times  \\bigl[1 + m\\,(U_c - 1)\\bigr] \\] <p>Two alternative utility metrics guide learning:</p> <code>UTILITY_METRIC</code> Algorithm maximises Real\u2011world analogy <code>0</code> (default) average utility (mean\u00a0well\u2011being across all agents) \u201cGreatest good for the greatest number.\u201d <code>1</code> minimum utility (well\u2011being of the worst\u2011off agent) Rawlsian / max\u2011min fairness. <p>The DecisionAgent reinforces actions that raise the chosen utility, gradually converging to an ideal m for the current policy goal.  </p> <p>These \u201cconcrete zoning\u2011bonus percentages and distance bands\u201d are the literal numbers (+20\u202f%, +10\u202f%, 800\u202fm, 1600\u202fm) encoded in <code>DecisionAgent.py</code>. Feel free to edit them in <code>config.py</code>.</p>"},{"location":"25sp-mponc/#2-horizontal-scaling-complete-beltline-from-day-0","title":"2.\u202fHorizontal\u202fScaling\u00a0(complete BeltLine from day\u202f0)","text":"<p>All census tracts whose centroids fall inside the 1.6\u202fkm BeltLine catchment zone begin with BeltLine factor \u03b2\u202f&gt;\u202f1 (default \u03b2\u202f=\u202f1.20, editable in <code>config.py</code>). Tracts outside that zone keep \u03b2\u202f=\u202f1.00.\u00a0This models an \u201call\u2011at\u2011once\u201d completion of the transit loop.</p>"},{"location":"25sp-mponc/#sobol-sensitivity-analysis","title":"Sobol Sensitivity Analysis","text":"<p>During calibration we ran a Sobol variance\u2011decomposition on six candidate features (Affordability, Attractiveness, Community, Location, BeltLine, Upkeep).</p> Feature 1<sup>st</sup>\u2011order index Total\u2011order index Affordability 0.42 0.45 Attractiveness 0.31 0.36 Community 0.18 0.22 Others &lt;\u202f0.05 &lt;\u202f0.10 <p>Because the cumulative contribution of the remaining three factors was &lt;\u202f10\u202f%, we compressed the cost function to the product Affordability\u202f\u00d7\u202fAttractiveness\u202f\u00d7\u202fCommunity. The full Jupyter notebook lives in <code>notebooks/sensitivity_sobol.ipynb</code>.</p>"},{"location":"25sp-mponc/#strengths-and-weaknesses","title":"Strengths and Weaknesses","text":""},{"location":"25sp-mponc/#strengths","title":"Strengths","text":"<p>Our approach is very modularized. For instance, our code can easily be ran on other regions, with customizable 'Beltlines' and the definitio. It simply needs lists of agents, a NetworkX graph, and other generalized parameters to operate. Furthermore, Our approach is backed by established human behavior approaches (no-regret dynamics), utilizes a distribution system that is also established (four-step model). We are able to produce dynamic visuals (GIFs).</p>"},{"location":"25sp-mponc/#weaknesses","title":"Weaknesses","text":"<p>Our simulation also assumes that there is no immigration/emigration in Atlanta, as we set a fixed number of agents. We also limit transportation choices to cars and public transportation, despite other modes of transport being popular (walking or biking) Additionally, our runtimes are relatively long due to the computationally expensive nature of the simulation. Ideally, our simulation would be ran in just a couple minutes or even seconds.</p>"},{"location":"25sp-mponc/#next-steps","title":"Next Steps","text":"<p>We hope to publish this research paper by this coming Fall semester. Most notably, we hope to improve the readability of our GIF's, improve the runtime of the simulation, validate our simulation's accuracy, and include additional visualizations of our results to better communicate our analysis during discussion. </p>"},{"location":"25sp-mponc/#presentation","title":"Presentation","text":""},{"location":"25sp-mponc/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Matthew Lim  (Lead) Junior Computer Science COC mlim70 Devam Mondal Junior Computer Science COC Dodesimo Justin Xu Junior Computer Science COC JXU037 Nithish Sabapathy Junior Computer Science COC nithish101"},{"location":"25sp-neuroarchitecture/","title":"25Sp-Neuroarchitecture","text":"<p>## Description ## During the COVID-19 pandemic, lockdown measures like home isolation, online learning, and public space closures helped control the virus but also increased social isolation, loneliness, and mental health issues such as depression and anxiety. These challenges, including restricted freedom, limited mental health access, and financial stress, underscored the urgent need to address mental well-being.</p> <p>Neuroarchitecture is an interdisciplinary field that combines principles of neuroscience with architecture and urban design. It studies how the built environment influences human behavior, emotions, and cognitive functions</p> <ul> <li>Current studies in \"Neuroarchitecture\"  mainly emphasize physical health rather than mental health</li> <li>\"Neuroarchitecture\" research remains at a conceptual level</li> <li>The relationship between mental health and the urban built environment is nearly never explored across different age groups.</li> <li>Many studies rely on subjective survey-based data collection instead of data-driven</li> </ul> <p></p> <p>## Spring 2025 Neuroarchitecture Plan ##   Since In Fall 2024, we have already filtered papers which are aligned with our eligibility criteria, so we focused on the data extraction and text mining in this semester.</p> <p></p> <p>## Data Extraction ##  Based on the Prisma we concluded last semester, we have 69 papers for data extraction continually(). We divided our data extraction templete into 4 part: Study Characteristics, Exposures, Outcomes, and main findings.Each section has corresponding subtopics. We allocate for extracting, Changda is responsible for 1-35, Sydney is reponsible for 36-69, Catherine odd studies, and Sam even studyies After we finished out part, we compare and conclude each of them into our final extraction to prepare for the next step of summarizing and reviewing.</p> <p>Data extraction template link:</p> <p>1-35:https://docs.google.com/spreadsheets/d/1dmjwXb4HLyvpfUUZywa7am7V2aKzJbMcyEQSukTinsg/edit?usp=sharing</p> <p>36-69\uff1ahttps://docs.google.com/spreadsheets/d/1ZH4K2hzg9c5WXQHB95zIHeHFIp6cPviqGr89F73DKlU/edit?usp=sharing</p> <p>Odd studies: https://docs.google.com/spreadsheets/d/1QcBIreRME7fBgll861OODxGawknsswH9EIXd4c0AnFA/edit?usp=sharing</p> <p>Even studies: https://docs.google.com/spreadsheets/d/1W7AGIvFBVuOaBzlWEwXGdXNMYHH14X3dbDm6qOQqFyE/edit?usp=sharing</p>"},{"location":"25sp-neuroarchitecture/#study-characteristics","title":"Study Characteristics ###","text":"<pre><code>study_metadata\n\u251c\u2500\u2500 basic_info\n\u2502   \u251c\u2500\u2500 Study ID (first author last name_year of publication\n\u2502   \u251c\u2500\u2500 Full study title\n\u2502   \u251c\u2500\u2500 List of authors\n\u2502   \u251c\u2500\u2500 Year the study was published\n\u2502   \u251c\u2500\u2500 ournal or source of publication\n\u2502\n\u251c\u2500\u2500 study_design\n\u2502   \u251c\u2500\u2500 options\n\u2502   \u2502   \u251c\u2500\u2500 analytical_cross_sectional\n\u2502   \u2502   \u251c\u2500\u2500 case_report\n\u2502   \u2502   \u251c\u2500\u2500 case_series\n\u2502   \u2502   \u251c\u2500\u2500 case_control\n\u2502   \u2502   \u251c\u2500\u2500 cohort_observational\n\u2502   \u2502   \u251c\u2500\u2500 prevalence\n\u2502   \u2502   \u251c\u2500\u2500 qualitative\n\u2502   \u2502   \u251c\u2500\u2500 quasi_experimental\n\u2502   \u2502   \u251c\u2500\u2500 randomized_controlled_trial\n\u2502   \u2502   \u2514\u2500\u2500 longitudinal\n\u2502\n\u251c\u2500\u2500 participant_info\n\u2502   \u251c\u2500\u2500 age_range(16-60, Age eligibility criteria)\n\u2502   \u251c\u2500\u2500 Mean (SD) of age\n\u2502   \u251c\u2500\u2500  Number and percentage male/female\n\u2502\n\u251c\u2500\u2500 setting_and_context\n\u2502   \u251c\u2500\u2500 Study population and setting\n\u2502   \u251c\u2500\u2500 geographic_location(Country, city, region)\n\u2502   \u2514\u2500\u2500 Socioeconomic_factors\n</code></pre> <p>  A Brief Summary: 40 papers use cross sectional studies, most papers are from Asia, Europe, and North America, as well as virtual enviroment, for participant, most are university students and public.</p>"},{"location":"25sp-neuroarchitecture/#exposures","title":"Exposures","text":"<pre><code>Exposures_metadata\n\u251c\u2500\u2500 Exposure Type\n\u2502   \u251c\u2500\u2500 Green &amp; Blue Spaces\n\u2502   \u251c\u2500\u2500 Public Spaces\n\u2502   \u251c\u2500\u2500 Transportation and Mobility\n\u2502   \u251c\u2500\u2500 Programmatic Function\n\u2502   \u251c\u2500\u2500 Other\n\u2502\n\u251c\u2500\u2500 Categories\n\u251c\u2500\u2500 Mesures\n\u251c\u2500\u2500 Metrics\n</code></pre> <p>As for urban built environment, we divided into four categories: urban &amp; blue space, public space, transportation and program function. There are 40 papers discussing green &amp;blue space. Therefore, in this category, Park/Nature Reserve are mainly talking aboot, and most of them are meaured by survey, image(view analysis), and GIS method, in this case, the metric of vegetation percentage/density are used most among all the papers.</p>"},{"location":"25sp-neuroarchitecture/#outcomes","title":"Outcomes","text":"<p><pre><code>Mental health or Well-Being \n\u251c\u2500\u2500 Subcategories\n\u2502   \u251c\u2500\u2500 Mental Health\n\u2502   \u2502   \u251c\u2500\u2500 Depression\n\u2502   \u2502   \u251c\u2500\u2500 Anxiety\n\u2502   \u2502   \u251c\u2500\u2500 PTSD\n\u2502   \u251c\u2500\u2500 Well-Being\n\u2502   \u2502   \u251c\u2500\u2500 Psychological\n\u2502   \u2502   \u251c\u2500\u2500 Social\n\u2502   \u2502   \u251c\u2500\u2500 Physical\n\u2502   \u2502   \u251c\u2500\u2500 Life satisfaction\n\u2502   \u2502   \u251c\u2500\u2500 Other\n\u2502\n\u251c\u2500\u2500 Measures\n\u2502   \u251c\u2500\u2500 Mental Health\n\u2502   \u2502   \u251c\u2500\u2500 Diagnoses\n\u2502   \u2502   \u251c\u2500\u2500 Symptoms\n\u2502   \u2502   \u251c\u2500\u2500 Others\n\u2502   \u251c\u2500\u2500 Well-Being\n\u2502   \u2502   \u251c\u2500\u2500 Interview\n\u2502   \u2502   \u251c\u2500\u2500 Questionare\n\u2502   \u2502   \u251c\u2500\u2500 Survey\n\u2502   \u2502   \u251c\u2500\u2500 Other\n\u2502\n\u251c\u2500\u2500 Specific Measures\n</code></pre> </p> <p>We begin by identifying whether each paper addresses mental health, well-being, or both. We then categorize them into specific subdomains: for mental health, the categories include depression, anxiety, and PTSD; for well-being, the categories cover psychological, social, physical well-being, and life satisfaction. Following this, we identify the instruments used to assess these outcomes\u2014such as questionnaires or surveys\u2014and specify the exact measurement tools applied. Among the reviewed studies, 37 focus exclusively on well-being, 16 exclusively on mental health, and 9 address both.</p>"},{"location":"25sp-neuroarchitecture/#main-findings","title":"Main Findings","text":"<p><pre><code>Main Findings\n\u251c\u2500\u2500 Aims/Research Questions\n\u251c\u2500\u2500 Main Findings\n\u251c\u2500\u2500 Statistical methods used\n\u251c\u2500\u2500 Effect Size (if reported)\n\u251c\u2500\u2500 Strengths\n\u251c\u2500\u2500 Limitations\n\u251c\u2500\u2500 Policy Implications\n</code></pre> </p> <p>Finally, we extract the \u201cmain findings\u201d section from each study, focusing on the research aim, statistical methods, effect sizes, strengths, limitations, and policy implications. Given the complexity of statistical findings, a detailed summary will be provided at a later stage. For now, we visualized the types of statistical methods used across the 69 studies. Among these, Structural Equation Modeling (SEM) emerged as one of the most common techniques.</p> <p>## Text Mining ##  ### PDF Inititial Collecting and Cleaning ###</p> <pre><code>mistral_workflow\n\u251c\u2500\u2500 call_mistral_api             # Step 1: Call the Mistral API\n\u251c\u2500\u2500 generate_json_output         # Step 2: Generate JSON output(Using OCR Scanning)\n\u2502   \u2514\u2500\u2500 table_characteristic     # If JSON is tabular, it's convenient to clean\n\u251c\u2500\u2500 reindex_json_sections        # Step 3: Re-index JSON sections\n\u251c\u2500\u2500 remove_unwanted_sections     # Step 4: Remove unnecessary sections\n\u2514\u2500\u2500 Initial Cleanin Details      # Step 5: Initial Cleanin Details\n</code></pre>"},{"location":"25sp-neuroarchitecture/#pdf-initial-cleaning-results-paper-json-after-initial-cleaning","title":"PDF Initial Cleaning Results: \ud83d\udcc1 <code>paper json after initial cleaning</code>","text":""},{"location":"25sp-neuroarchitecture/#using-nltk-filtering-wanted-and-unwanted-tokens","title":"Using NLTK Filtering wanted and unwanted tokens","text":"<p>FLow Chart</p> <pre><code>flowchart TD\n    A[Tokenize and preprocess text: lowercase, clean symbols url,etc, keep collocations]\n    B[Filter unnecessary symbols: remove degree, ampersand, percent, hash, at, exclam]\n    C[Count word frequencies and delete common content]\n    D[Remove text in parentheses]\n    E[Ignore numbered lists like 1-dot item, 2-dot item]\n    F[Handle compound words: keep phrases like machine learning together]\n\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F</code></pre> <p>Code <pre><code>import nltk\nfrom nltk.corpus import names, stopwords\nfrom nltk.tokenize import word_tokenize\nimport re\n\n# Download required resources\nnltk.download(\"punkt\")\nnltk.download(\"averaged_perceptron_tagger\")\nnltk.download(\"names\")\nnltk.download(\"stopwords\")\n\n# Load resources\nall_names = set(names.words())\ncustom_stopwords = set(stopwords.words(\"english\"))\n\n# Define custom collocations\ncustom_collocations = {\n    \"machine learning\", \"deep learning\", \"artificial intelligence\", \"neural network\",\n    \"natural language processing\", \"computer vision\", \"data science\", \"big data\",\n    \"number theory\", \"complex analysis\", \"linear algebra\", \"gradient descent\",\n    \"support vector machine\", \"random forest\", \"decision tree\", \"reinforcement learning\",\n    \"urban planning\", \"photo simulation\", \"green spaces\", \"climate change\",\n    \"pedestrian streets\", \"traffic congestion\", \"sustainability policies\"\n}\n\n# Text cleaning and tokenization\ndef clean_and_tokenize(text):\n    text = text.lower()\n    text = re.sub(r\"\\bwww\\.|\\S+\\.\\w{2,3}\\b\", \" \", text)\n    text = re.sub(r\"\\b(et|et\\s+al|et\\sal)\\b\", \" \", text)\n    text = re.sub(r\"\\b\\d+(st|nd|rd|th)\\b\", \" \", text)\n    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n    text = re.sub(r\"\\b[a-z]{1,2}\\b\", \" \", text)\n    return word_tokenize(text)\n</code></pre></p>"},{"location":"25sp-neuroarchitecture/#bigrams-and-colocations-compound-words-and-solutions-to-getting-them","title":"Bigrams and Colocations: Compound words and solutions to getting them","text":"<p>Code <pre><code># Define a threshold for frequent bigrams\nfrequent_bigrams = {\n    \"_\".join(bg) for bg, freq in bigram_freq.items()\n    if freq &gt; 5 and is_valid_bigram(bg)\n}\n\n# Merge detected bigrams + predefined collocations\nall_collocations = frequent_bigrams.union(custom_collocations)\n\n# Reconstruct tokens with collocations\ni = 0\nmerged_tokens = []\n\nwhile i &lt; len(tokens) - 1:\n    bigram = f\"{tokens[i]}_{tokens[i+1]}\"\n    if bigram in all_collocations:\n        merged_tokens.append(bigram)\n        i += 2\n    else:\n        merged_tokens.append(tokens[i])\n        i += 1\n\n# Append the last token if it wasn't part of a bigram\nif i == len(tokens) - 1:\n    merged_tokens.append(tokens[i])\n</code></pre> Bigrams: pairs of consecutive words. If the bigrams are used often, chances are they are legitimate compound words. Therefore, we merge those with high frequencies. Essentially, we check the current iteration and its next element. If the frequency Ex: [\"Machine\", \"Learning\", \"is\", \"fun\" ], the output is : [\"Machine_Learning\", \"is\", \"fun\" ]!</p>"},{"location":"25sp-neuroarchitecture/#convert-to-dictionary-token-count-file","title":"Convert to Dictionary {Token : Count} File","text":"<p>After we cleaning, we convert all the words we get into dictionary, also count the frequency of each word, Here are the top 20 word frequencies, and top 20 compound words frequencies.</p> <p> </p>"},{"location":"25sp-neuroarchitecture/#labeling-keys-with-respective-category","title":"Labeling Keys with Respective Category","text":"<p>We utilize pre-trained Hugging Face NLP model and manual labeling\u00a0to classify the words from the pdf cleaning into 4 category: - Urban Built Environment - Environment Factors - Mental Health and Well-Being - Measure</p> <p>Based on the relationship between each categories, we explore: - In neuroarchitecture, the association between different environmental factors and different urban built environments. - Which urban built environment or environment factors are popular in mental health and well-being and which one are less affected.</p>"},{"location":"25sp-neuroarchitecture/#visualization","title":"Visualization ###","text":""},{"location":"25sp-neuroarchitecture/#method-flow-chart","title":"Method Flow Chart","text":"<p>After cleaning the PDFs, the resulting word dictionary is sorted in descending order of term frequency and saved as voc.txt. This vocabulary file is then fed into a Word2Vec model to train the word embeddings, producing embedding_vec.emb. The high\u2011dimensional embeddings are further reduced with PCA, UMAP, and t\u2011SNE, and the low\u2011dimensional coordinates are stored in bookmark.json.</p> <p>For visualization, we generates:</p> <ul> <li> <p>N\u2011gram similarity matrix heat map</p> </li> <li> <p>Correlation matrix heat map</p> </li> <li> <p>Hierarchical agglomerative clustering dendrogram</p> </li> <li> <p>Cross\u2011correlation matrix</p> </li> <li> <p>Distance\u2011threshold projection</p> </li> <li> <p>2D relation\u2011projection clusters using  Louvain community detection.</p> </li> </ul>"},{"location":"25sp-neuroarchitecture/#ngram-similarity-matrix-heat-map","title":"N\u2011gram similarity matrix heat map","text":"<p>1.First ,whwn we input embedding_vec.emb\uff0cWe use N-gram Co\u2011occurrence Frequency, which is shown as below, in order to counts how many times each adjacent word pair appear. When frequency is greater than 5, both of two words will be the compound words(bigram), which are included in the row and column with other words we collected. (Check for missing compond words)</p> \\[ \\text{freq}(W_a,W_b)   \\;=\\   \\sum_{t=1}^{T-1}   \\mathbf{1}\\bigl[w_t = W_a\\land\\ w_{t+1} = W_b\\bigr]&gt;5 \\] <p>2.Second, using the embedding vectors of each word, we compute the cosine similarity between every row word and every column word to obtain the similarity scores. When a similarity score exceeds 0.05, the corresponding word pair is treated as  related, and the score is recorded as the cell value and color intensity in the heat\u2011map; scores below the threshold are left blank.</p> \\[ \\cos(\\mathbf v_{W_a}\\, \\mathbf v_{W_b}) \\=\\ \\frac{\\mathbf v_{W_a}\\cdot \\mathbf v_{W_b}}      {\\lVert \\mathbf v_{W_a}\\rVert\\lVert \\mathbf v_{W_b}\\rVert} \\&gt;0.05 \\] <ol> <li>Finally, the resulting similarity matrix is rendered as a heat map, (the relation between urban built environment and mental health or well-being shown below),and generate *.csv fileof each relationship</li> </ol> <p></p>"},{"location":"25sp-neuroarchitecture/#hierarchical-agglomerative-clustering-and-corelation-matrix","title":"Hierarchical Agglomerative Clustering and Corelation Matrix ####","text":"<ol> <li>First, extract all nodes from the N\u2011gram similarity matrix heat map and write their 300\u2011dimensional word vectors to embedding_matrix.tsv, then read*.csv fileof each relationship retrieve the 300 D vector for every column word, and perform hierarchical clustering with Ward\u2019s method and Euclidean distance (minimizing within\u2011cluster variance). The resulting dendrogram groups semantically similar words into clusters and automatically assigns a distinct colour to each branch for the legend.</li> </ol> <p>Euclidean distance\u00a0\u2013 input to Ward\u2019s algorithm\uff1a For any two 300\u2011dimensional word embeddings \\(\\(\\(\\mathbf{x}_i\\)\\)\\) and \\(\\(\\(\\mathbf{x}_j\\)\\)\\),</p> \\[ d(\\mathbf x_i,\\mathbf x_j)   = \\lVert \\mathbf x_i - \\mathbf x_j \\rVert_{2} \\] <p>Ward linkage cost (extra within\u2011cluster sum\u2011of\u2011squares created by merging clusters\u00a0(A) and\u00a0(B))</p> \\[ \\Delta(A,B)   = \\frac{|A||B|}{|A|+|B|}    \\bigl\\lVert \\boldsymbol\\mu_A - \\boldsymbol\\mu_B \\bigr\\rVert_2^{2} \\] <p>where \\(\\(\\( \\boldsymbol{\\mu}_A \\)\\)\\) and analogously \\(\\(\\( \\boldsymbol{\\mu}_B \\))\\)\\) is the centroid of cluster\u00a0(A).</p> <p>2.Second, reorder the rows and columns according to the dendrogram\u2019s leaf order, then compute the column\u2011wise Pearson correlation coefficients and display them in a red scale heat map, exporting the reordered original matrix to a CSV file.</p> <p>Pearson correlation coefficient (heat\u2011map cell value)</p> <p>For two column vectors \\(\\(\\(X_i\\)\\)\\) and \\(\\(\\(X_j\\)\\)\\):</p> \\[ r_{ij}\\=\\ \\frac{\\displaystyle\\sum_{k=1}^{n}(X_{ik}-\\bar X_i)(X_{jk}-\\bar X_j)}      {\\sqrt{\\displaystyle\\sum_{k=1}^{n}(X_{ik}-\\bar X_i)^2}\\       \\sqrt{\\displaystyle\\sum_{k=1}^{n}(X_{jk}-\\bar X_j)^2}} \\in[-1,1] \\] <p>The script maps each \\(\\(\\(r_{ij}\\)\\)\\) onto a red colour scale in the range (0-1): 0\u00a0= white (weak correlation), 1\u00a0= dark red (strong correlation).</p> <p>Take the correlation matrix map (urban_built_environment)as an example: </p>"},{"location":"25sp-neuroarchitecture/#cross-correlation-matrix-heat-map","title":"Cross-correlation matrix heat map","text":"<p>For each cross\u2011category correlation CSV, the script reorders the matrix according to the specified relationships, recomputes the cosine similarity, maps the resulting values to a red gradient scale from 0\u202f(white) to\u202f1\u202f(dark red), and produces a cross\u2011correlation heat map that visualizes the strength of the relationships between different categories.</p> <p>Take the cross correlationship heatmap of mental health-urban built environment with dendrogram_groups as an example: </p>"},{"location":"25sp-neuroarchitecture/#2d-relationprojection-clusters-and-distancethreshold-projection","title":"2D relation\u2011projection clusters and Distance\u2011threshold projection ####","text":"<p>1.Distance thresold:Write the 300\u2011dimensional word vectors to embedding_matrix.tsv, classify them into our predefined categories to create labels.tsv, and use these two files\u2014together with bookmark.json\u2014as the input data for generating the 2\u2011D distance\u2011threshold projection.Each word is assigned a fixed position, a colour that reflects its predefined category, and a node size  to its graph degree.\u202fNetworkX then builds a fully connected graph on these nodes, and Matplotlib draws a distance\u2011threshold projection: colored nodes are plotted at their 2D positions, the four main vocabularies are labelled, and overlapping labels are automatically nudged apart.\u202fThe resulting cluster map is exported as graph_embeddings_projection, providing a visual overview of how the classified word embeddings distribute across the reduced dimensional space.</p> <p></p> <p>2.Louvain Cluster:The Louvain algorithm (community_louvain.best_partition) to network, iteratively maximizing the modularity Q and thus determining the number of communities k automatically. Each community is then assigned a distinct color, producing node_colors. Next,Fruchterman\u2011Reingold computes the final node coordinates, pulling nodes within the same community closer together. Only words from the four main relationships are labelled, and adjust text is used to prevent label overlap.</p> <p>The Louvain algorithm iteratively maximises the modularity\u202f\\(Q\\):</p> \\[ Q =\\frac{1}{2m} \\sum_{i,j} \\Bigl(A_{ij} - \\frac{k_i k_j}{2m}\\Bigr)\\ \\delta(c_i, c_j) \\] <p>where \\(A_{ij}\\) is the adjacency\u2011matrix element, \\(k_i\\) is the degree of node\u202f\\(i\\), \\(m\\) is the total number of edges, and \\(\\delta(c_i,c_j)\\) is\u00a01 if nodes\u202f\\(i\\) and\u202f\\(j\\) are in the same community and\u00a00 otherwise.</p> <p>Fruchterman\u2013Reingold spring layout Iterative force model:</p> \\[ F_{\\text{rep}}(r)=\\frac{k^{2}}{r} \\qquad F_{\\text{att}}(r)=\\frac{r^{2}}{k} \\qquad k = c\\sqrt{\\frac{A}{n}} \\] <p>'nx.spring_layout' embeds the graph in\u00a02\u2011D, iterating until the attractive force \\(F_{\\text{att}}\\) balances the repulsive force \\(F_{\\text{rep}}\\), thereby keeping each community visually compact while forcing distinct communities apart.</p> <p></p>"},{"location":"25sp-neuroarchitecture/#repository-structure","title":"Repository Structure","text":"<pre><code>\ud83d\udce6 &lt;repo\u2011root&gt;\n\u251c\u2500\u2500 paper_json_after_initial_cleaning/     # JSON dictionaries produced after the initial PDF cleaning\n\u2502   \u2514\u2500\u2500 *.json\n\u2502\n\u251c\u2500\u2500 Visualization_input_data/              # Visualization Input Data\n\u2502   \u251c\u2500\u2500 sorted_final_combined_dict.emb     # Transfer dictionary after cleaning to word\u2011embedding vectors\n\u2502   \u251c\u2500\u2500 sorted_final_combined_dict.txt     # dictionary after cleaning and sorting\n\u251c   \u251c\u2500\u2500 final_combined_dict.txt            # dictionary after cleaning but unsorting\n\u2502   \u2514\u2500\u2500 sorted_final_combined_dict.json    # PCA/UMAP/t\u2011SNE low\u2011dimensional coordinates\n\u2502\n\u251c\u2500\u2500 N\u2011gram_similarity_matrix/              # Per\u2011topic similarity heat maps and raw tables\n\u2502   \u251c\u2500\u2500 csv/                               # Original similarity matrices\n\u2502   \u2502   \u2514\u2500\u2500 &lt;topic&gt;.csv\n\u2502   \u2514\u2500\u2500 heatmap/                           # Corresponding heat\u2011map plots\n\u2502       \u2514\u2500\u2500 &lt;topic&gt;_clusterd.svg\n\u2502\n\u251c\u2500\u2500 Hierarchical_Agglomerative_Clustering_and_Correlation_Matrix/\n\u2502   \u251c\u2500\u2500 dendrogram_groups/                 # Word\u2011vector dendrograms with colour legends\n\u2502   \u2502   \u2514\u2500\u2500 &lt;topic&gt;_clusterd_with_legend.svg\n\u2502   \u251c\u2500\u2500 csv/                               # Matrices reordered by cluster order\n\u2502   \u2502   \u2514\u2500\u2500 &lt;topic&gt;.csv\n\u2502   \u251c\u2500\u2500 embedding_matrix.tsv               # 300\u2011dimensional word\u2011embedding matrix\n\u2502   \u2514\u2500\u2500 Corelation_heatmap/                # Pearson\u2011correlation heat maps\n\u2502       \u2514\u2500\u2500 &lt;topic&gt;.svg\n\u2502\n\u251c\u2500\u2500 Cross_relation_matrix/                 # Cross\u2011category similarity heat map                       \n\u2502   \u2514\u2500\u2500 svg/                               # Cross\u2011relation heat\u2011map plots\n\u2502       \u2514\u2500\u2500 &lt;A\u2011B&gt;_cross_rel.svg\n\u2502\n\u251c\u2500\u2500 2d_projection/                         # 2\u2011D projection and distance\u2011threshold graphs\n\u2502   \u251c\u2500\u2500 graph_embeddings_projection-with_edges.svg\n\u2502   \u251c\u2500\u2500 labels.tsv                         # Mapping from word to predefined category\n\u2502   \u2514\u2500\u2500 graph_embeddings_projection_with_communities.svg\n\u2502\n\u251c\u2500\u2500 Figure/                                # Figures collected for readme\n\u2502\n\u251c\u2500\u2500 code/                                   # Main scripts\n\u2502   \u251c\u2500\u2500 clean_pdf.py\n\u2502   \u251c\u2500\u2500 build_ngram_matrix.py\n\u2502   \u251c\u2500\u2500 cluster_and_heatmap.py\n\u2502   \u2514\u2500\u2500 projection_and_louvain.py\n\u2502\n\u2514\u2500\u2500 README.md                              # Project overview (method, formulas, sample plots)\n</code></pre>"},{"location":"25sp-neuroarchitecture/#plan","title":"Plan","text":""},{"location":"25sp-neuroarchitecture/#paper-publish","title":"Paper Publish","text":"<ul> <li>Compare the data extraction template from each member and summarize into one data extraction template .</li> <li>Analyze the different categories in the data extraction and the literature summary, and conduct a review</li> <li>Draft it into the \u201cfinding\u201d part of the paper draft</li> </ul>"},{"location":"25sp-neuroarchitecture/#text-mining","title":"Text Mining","text":"<ul> <li>Continue to manually filter the words in each category to ensure that they are concise and accurate.</li> <li>Analyze the visualization data and explore research questions</li> <li>Paper draft</li> </ul>"},{"location":"25sp-neuroarchitecture/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Changda Ma Masters Architecture ARCH changdama Catherine Wallis Senior Architecture ARCH cgwallis Sydney Dai Freshman Industrial Engineering ISYE SydneyGT Ze Yu Jiang Junior Computer Science SCS zeyujiang8800 Sam Edwards RA sedwards42 Bailey Todtfeld RA"},{"location":"25sp-energyinbuildings/","title":"25-Sp-Energy","text":""},{"location":"25sp-energyinbuildings/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Rhino Energy Prediction Plugin</li> <li>Energy Map</li> <li>Extracting Vegetation Data</li> </ul>"},{"location":"25sp-energyinbuildings/#rhino-energy-prediction-plugin","title":"Rhino Energy Prediction Plugin","text":""},{"location":"25sp-energyinbuildings/#overview","title":"Overview","text":"<p>Rhino Energy Prediction Plugin is designed to support architects in making energy-informed design decisions early in the building process. The plugin enables users to create or modify building models and receive predictions for heating and cooling loads using a machine learning (ML) model. Architects can gauge building energy performance early (concept stage) using the Rhino Energy Prediction Plugin. The plugin embeds a self-contained ONNX runtime directly in Grasshopper.</p>"},{"location":"25sp-energyinbuildings/#features","title":"Features","text":"<ul> <li> <p>Model Initialization   Reads an ONNX model file path and sets up an <code>InferenceSession</code> that exposes each input tensor\u2019s name, datatype, and shape.</p> </li> <li> <p>Real-Time Inference   Packs Grasshopper inputs into dense tensors, executes the ONNX model, and returns the first element of the output array as an energy load estimate.</p> </li> <li> <p>Automatic Feature Extraction   Companion Python script reads 3D building geometry and computes features such as roof area, window-to-wall ratio, floor area, and number of stories.</p> </li> <li> <p>Pure C# Runtime   Runs entirely in .NET via Microsoft\u2019s ONNX Runtime\u2014no Python interpreter required at inference time.</p> </li> </ul>"},{"location":"25sp-energyinbuildings/#architecture","title":"Architecture","text":"<ol> <li> <p>Component Initialization    The plugin reads the ONNX model path from the Grasshopper input.    It then creates an <code>InferenceSession</code> and retrieves input tensor metadata.</p> </li> <li> <p>Input Packing    Grasshopper values are loaded into dense tensors that match the ONNX input shapes.</p> </li> <li> <p>Model Inference    The plugin runs the ONNX model with the packed inputs and receives an output array.    The first element of that array is sent to the Grasshopper output.</p> </li> <li> <p>Feature Extraction Script    A Python helper extracts building features automatically by classifying layers named <code>Wall</code>, <code>Slab</code>, <code>Window</code>, and <code>Roof</code>.</p> </li> </ol>"},{"location":"25sp-energyinbuildings/#installation","title":"Installation","text":"<ol> <li>Download the <code>VIP_Energy_Plugin</code> folder.  </li> <li>Copy it to your Grasshopper Libraries folder:    <pre><code>C:\\Users\\YourUserName\\AppData\\Roaming\\Grasshopper\\Libraries\n</code></pre></li> <li>Launch Rhino and open Grasshopper.  </li> <li>Drag the VIPPlugin component from the Params tab onto the canvas.  </li> <li>Provide the ONNX model file path to the component input.  </li> <li>View the energy load prediction on the second output parameter.</li> </ol>"},{"location":"25sp-energyinbuildings/#workflow","title":"Workflow","text":"<ol> <li>Open Rhino and start Grasshopper.  </li> <li>Place the VIPPlugin component and connect the ONNX model path.  </li> <li>Sketch or import a building mass in Rhino.  </li> <li>Run the feature extraction script to compute geometry parameters.  </li> <li>Grasshopper packs the inputs and runs the ONNX model.  </li> <li>Inspect the real-time energy load estimate.</li> </ol>"},{"location":"25sp-energyinbuildings/#requirements","title":"Requirements","text":"<ul> <li>Rhino 7+ \u2013 Plugin host environment  </li> <li>Windows OS \u2013 .NET and Rhino SDK compatibility  </li> <li>.NET Framework 4.8+ \u2013 ONNX Runtime support  </li> <li>Python 3.8+ \u2013 Feature extraction and model conversion scripts  </li> <li>ONNX model file \u2013 Trained energy prediction model  </li> </ul>"},{"location":"25sp-energyinbuildings/#tech-stack","title":"Tech Stack","text":"<ul> <li>Rhino SDK (C#) \u2013 Core plugin development and geometry handling  </li> <li>Grasshopper (C#) \u2013 Dynamic component architecture  </li> <li>Microsoft ONNX Runtime \u2013 High-performance model inference  </li> <li>Python \u2013 Building feature extraction and <code>.joblib</code> \u2192 <code>.onnx</code> conversion  </li> <li>scikit-learn / sklearn-onnx \u2013 Model training and conversion  </li> </ul>"},{"location":"25sp-energyinbuildings/#roadmap","title":"Roadmap","text":"<ul> <li> <p>Real-Time EUI Feedback   Provide energy use intensity updates as users modify height, WWR, and story count.</p> </li> <li> <p>Flexible Model Inputs   Detect parameter names and types automatically to support multiple climates and typologies.</p> </li> <li> <p>Multi-Format Support   Add seamless handling of both <code>.onnx</code> and <code>.joblib</code> models with built-in feature mapping.</p> </li> <li> <p>Map Integration   Link with an energy prediction map to import existing building geometry and simulate retrofits.</p> </li> <li> <p>Custom Tab   Give PlugIn standalone VIPEnergy tab so that future energy related plugins that work in the Rhino/GH environment may be added to this parent group.</p> </li> </ul>"},{"location":"25sp-energyinbuildings/#energy-map","title":"Energy Map","text":""},{"location":"25sp-energyinbuildings/#overview_1","title":"Overview","text":"<p>The energy map provides visualizations of predicted building energy loads (heating and cooling) across an urban environment. Users can click on individual buildings to inspect specific feature details such as building height and estimated energy loads.</p> <p>Given a GeoJSON file, the application calculates various building features, including height, shape (e.g., L-shaped, H-shaped), number of stories, building type (residential, commercial, etc.), energy code classification, HVAC category, roof area, rotation, wall area, and window area. These extracted features are then fed into a machine learning model, as described here.</p>"},{"location":"25sp-energyinbuildings/#repository-structure","title":"Repository Structure","text":"<pre><code>energy map\n\u251c\u2500 api \n|  \u251c\u2500 calculate_building_features # Scripts to calculate building-level features like height, area, rotation \n|  \u2514\u2500 route.ts # API routing configuration for feature calculations\n|  \n\u251c\u2500 flask-api # Backend Flask server \n|  \n\u251c\u2500 node_modules # Dependency libraries (auto-generated)\n\u251c\u2500 public # Static public assets\n\u251c\u2500 src \n|  \u251c\u2500 assets # Static files such as icons or images\n|  \u251c\u2500 App.tsx # Main application file\n|  \u251c\u2500 App.css # Application-level styling\n|  \u251c\u2500 index.css # Global styles\n|  \u251c\u2500 main.tsx # Application bootstrap and render entry\n|  \u2514\u2500 components # React components for UI (buttons, feature displays, map container, map view) \n|     \u251c\u2500 ButtonComponent.tsx\n|     |  \u251c\u2500 FeatureDisplay.tsx\n|     |  \u251c\u2500 MapContainer.tsx\n|     |  \u251c\u2500 MapView.tsx\n|     \u2514\u2500 utils\n|        \u2514\u2500 building.ts # Utility functions for parsing and handling building feature data\n\u2514\u2500 ...\n</code></pre>"},{"location":"25sp-energyinbuildings/#getting-started","title":"Getting Started","text":""},{"location":"25sp-energyinbuildings/#requirements_1","title":"Requirements","text":"<ol> <li> <p>Run with Python 3.12.5 (otherwise there are issues with the .pkl files)</p> </li> <li> <p>Install node.js</p> </li> </ol>"},{"location":"25sp-energyinbuildings/#set-up-to-run-locally","title":"Set up to run locally","text":"<ol> <li>Clone the repository using    <pre><code>git clone https://github.com/VIP-SMUR/25Sp-EnergyInBuildings-Com.git\n</code></pre></li> <li>Navigate to the project folder    <pre><code>cd energy_map\n</code></pre></li> <li>Run front end locally using    <pre><code>npm run dev\n</code></pre></li> <li>To run the flask backend, open a new terminal and navigate to the energy_map/app/flask-api folder. Make sure to have the required python libraries. You can then run app.py without any errors    <pre><code>pip install -r /path/to/requirements.txt\n\npython app.py\n</code></pre></li> </ol>"},{"location":"25sp-energyinbuildings/#map-information","title":"Map Information","text":""},{"location":"25sp-energyinbuildings/#datasets","title":"Datasets","text":"<p>The dataset is derived from the Overture Maps Foundation building footprints, provided in GeoJSON</p>"},{"location":"25sp-energyinbuildings/#extracting-vegetation-data","title":"Extracting Vegetation Data","text":""},{"location":"25sp-energyinbuildings/#overview_2","title":"Overview","text":"<p>We examined various methods of extracting vegetation data for use with the models due to the effect of shading on the heating and cooling load of nearby buildings.</p>"},{"location":"25sp-energyinbuildings/#ndvi-analysis","title":"NDVI Analysis","text":"<p>NDVI (Normalized Difference Vegetation Index) is a metric used to quantify the health and density of vegetation from satellite imagery. Seemed promising at first, but does  not provide any way of estimating vegetation height, which is likely needed as a metric for the model to be trained on.</p>"},{"location":"25sp-energyinbuildings/#treecountsegheight","title":"TreeCountSegHeight","text":"<p>A recently developed model called TreeCountSegHeight was also examined for potential integration with the model. It seemed to fit our purposes quite well, returning an estimate of tree height from input satellite imagery, but was found to be very computationally intensive. It may have potential to yield results given sufficient hardware, but this was a stumbling point in the workflow. </p>"},{"location":"25sp-energyinbuildings/#next-steps","title":"Next Steps","text":"<p>Continue searching for a lightweight/efficient way to extract vegetation height from satellite imagery.</p>"},{"location":"25sp-microclimate-lstm-kriging/","title":"VIP-Sp25-Urban-Microclimate-Prediction-Hybrid-LSTM-Transformer-Kriging","text":""},{"location":"25sp-microclimate-lstm-kriging/#microclimate-prediction-model","title":"\ud83c\udf26\ufe0f Microclimate Prediction Model","text":""},{"location":"25sp-microclimate-lstm-kriging/#overview","title":"\ud83e\udded Overview","text":"<p> This project introduces a hybrid machine learning approach for urban microclimate prediction. It integrates time series forecasting (using LSTM and Transformer architecture) with spatial interpolation (Kriging) to model environmental conditions across the urban canopy layer.</p> <p>Key inputs include: - Meteorological data: temperature, humidity, dew point - Urban features: land cover, 3D elevation, surface materials, shadow coverage, sun angle</p>"},{"location":"25sp-microclimate-lstm-kriging/#work-distribution","title":"Work Distribution","text":"<p>We\u2019d like to share a quick update on what the team has been working on. For our convenience in tracking files, please see the suggested file naming guide below. If possible, kindly consider revising your file names accordingly. However, if the file name cannot be changed for any reason, please feel free to let me know.</p> <p>1_ExtractUrbanFeatures.ipynb -- /krishgupta-CE /Thanasarn-Changnawa</p> <p>1_1_ExtractBuildings.ipynb -- /krishgupta-CE /Thanasarn-Changnawa</p> <p>1_2_ExtractShadows.ipynb -- /daytss /Thanasarn-Changnawa</p> <p>1_3_ExtractSurfaceMaterials.ipnb -- /BenjaminHansyun</p> <p>2_TrainModel.ipynb -- /yupengtang /zeyujiang8800 /Thanasarn-Changnawa</p> <p>2_1_LSTM_Model_Eval.ipynb</p> <p>2_2_(Model Name)</p> <p>3_Inference.ipynb -- /zeyujiang8800 /Thanasarn-Changnawa</p> <p></p>"},{"location":"25sp-microclimate-lstm-kriging/#geospatial-feature-engineering","title":"\ud83c\udf10 Geospatial Feature Engineering","text":""},{"location":"25sp-microclimate-lstm-kriging/#2d-spatial-data","title":"2D Spatial Data","text":"<ul> <li>12 distance vectors per grid point to features such as buildings, parks, libraries, parking, footways, grass, fitness centers, woods, and wetlands</li> <li>Data sourced from OSMnx and GT Tree Viewer</li> <li>Returns .csv file: grid_analysis.csv  </li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#building-elevation","title":"Building Elevation","text":"<ul> <li>Derived from DSM and DTM to compute building heights</li> <li>Digital Terrain Model (DTM) for GT\u2019s campus (.tif file) obtained through USGS EarthExplorer</li> <li>Digital Surface Model (DSM) for GT\u2019s campus (.tif file) obtained through OpenTopography</li> <li>Returns .csv file: grid_with_ground_and_building_elevation.csv  </li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#building-area-density","title":"Building Area Density","text":"<ul> <li>Utilizes osmnx to find total building footprint per spatial unit</li> <li>Returns .csv file: squares_with_building_areas.csv </li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#surface-materials","title":"Surface Materials","text":"<ul> <li>OSM map tiles converted to material categories by pixel color</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#shadow-coverage","title":"Shadow Coverage","text":"<ul> <li>Calculated using Pybdshadow and Astral for sunlight/shadow estimation</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#sun-angle-dynamics","title":"Sun Angle Dynamics","text":"<ul> <li>Sun angle included as a physical feature for seasonal generalization</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#project-structure","title":"\ud83d\udcc1 Project Structure","text":"<ul> <li>Data Collection: Automated via Selenium</li> <li>Feature Engineering: Spatial and environmental attributes</li> <li>Modeling: Temporal Fusion Transformer with LSTM-Attention Encoder (TFT-LAE)</li> <li>Training: Adam optimizer + MSE loss + early stopping</li> <li>Evaluation: RMSE, MAPE, R\u00b2, residual tracking</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#model-architecture-tft-lae","title":"\ud83e\udde0 Model Architecture: TFT-LAE","text":"<ul> <li>VSN: Variable Selection Network</li> <li>Time2Vec: Temporal embedding module</li> <li>LSTM + Attention: Captures time dependencies</li> <li>GRN Decoder: Multi-step forecast generation</li> </ul> <p>Workflow: Input \u2192 VSN \u2192 Time2Vec \u2192 LSTM+Attention \u2192 GRN \u2192 Output</p>"},{"location":"25sp-microclimate-lstm-kriging/#feature-engineering-selection","title":"\ud83e\uddee Feature Engineering &amp; Selection","text":"<p>Selected Features: - Meteorological: RH, DewPt, Azimuth, Altitude, \u0394Temp - Temporal: hour_sin, hour_cos - Scaled with MinMaxScaler to ensure consistency</p>"},{"location":"25sp-microclimate-lstm-kriging/#training-process","title":"\ud83c\udfcb\ufe0f\u200d\u2642\ufe0f Training Process","text":"<ul> <li>Loss: MSE</li> <li>Optimizer: Adam with weight decay</li> <li>Early stopping: Prevents overfitting</li> <li>Logging: tqdm + best model saving</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#evaluation-process","title":"\ud83c\udf0d Evaluation Process","text":""},{"location":"25sp-microclimate-lstm-kriging/#data-sources","title":"Data Sources","text":"Source Use Location Atlanta Weather Train time series Atlanta, GA Singapore Grid Train spatial Kriging Singapore GT Campus Final test Georgia Tech"},{"location":"25sp-microclimate-lstm-kriging/#tools","title":"Tools","text":"<ul> <li>Selenium for data scraping</li> <li>Python for processing</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#workflow","title":"Workflow","text":"<ol> <li>Scrape and clean data</li> <li>Train time series model (Atlanta)</li> <li>Train spatial interpolation (Singapore)</li> <li>Apply both to Georgia Tech data</li> <li>Evaluate with real measurements</li> </ol>"},{"location":"25sp-microclimate-lstm-kriging/#evaluation-and-prediction","title":"\ud83d\udcca Evaluation and Prediction","text":"<p>Functions: - <code>predict_and_plot</code>, <code>plot_full_sequence</code></p> <p>Metrics: - RMSE, MAPE, R\u00b2</p> <p>Residuals: - Histogram and time-series plots to detect bias</p> <p>Overfitting: - Train/test error comparison</p>"},{"location":"25sp-microclimate-lstm-kriging/#problem-outlier-distortion","title":"\ud83d\udc1e Problem: Outlier Distortion","text":"<p>Initial training data contained extreme values: - -51\u00b0C to 174\u00b0C</p> <p>Distorted MinMaxScaler and flattened predictions.</p>"},{"location":"25sp-microclimate-lstm-kriging/#solution","title":"Solution","text":"<ul> <li>Filtered to -15\u00b0C to 40\u00b0C</li> <li>Result: Better scaling, more generalization</li> </ul> <p>Lesson: Always validate input ranges before normalization.</p>"},{"location":"25sp-microclimate-lstm-kriging/#post-fix-evaluation","title":"\ud83d\udcc9 Post-Fix Evaluation","text":"<ul> <li>Residuals became balanced and centered</li> <li>Predictions improved but remained smooth</li> <li>Future work: increase expressiveness and precision</li> </ul>"},{"location":"25sp-microclimate-lstm-kriging/#summary","title":"\u2705 Summary","text":"<p>This workflow combines spatial and temporal modeling for urban microclimate forecasting using: - Deep learning (TFT-LAE) - Spatial Kriging interpolation - Automated feature extraction and evaluation</p> <p>It provides a framework for scalable, data-driven urban climate resilience solutions.</p>"},{"location":"25sp-microclimate-umcf/","title":"25-Sp-Microclimate-UMCF","text":"<p>\ud83d\udd25</p>"},{"location":"25sp-mobility-pei/","title":"Pedestrian Environment Index (PEI) Documentation - Spring 2025","text":"<p>This project implements the Pedestrian Environment Index (PEI) methodology as developed at the University of Illinois Chicago (see the research paper: https://www.sciencedirect.com/science/article/pii/S0966692314001343). The PEI provides a composite measure of the walkability of an environment, incorporating the following subindices:</p> <ul> <li>Population Density Index (PDI)</li> <li>Commercial Density Index (CDI)</li> <li>Intersection Density Index (IDI)</li> <li>Land-use Diversity Index (LDI)</li> </ul>"},{"location":"25sp-mobility-pei/#1-motivation-and-introduction","title":"1. Motivation and Introduction","text":"<p>The Pedestrian Environment Index (PEI) is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments. This implementation of the PEI is useful for researchers aiming to:</p> <ul> <li>Assess the current walkability of neighborhoods or regions.</li> <li>Compare walkability across different areas.</li> <li>Identify areas with potential for improvement.</li> </ul>"},{"location":"25sp-mobility-pei/#2-getting-started","title":"2. Getting Started","text":""},{"location":"25sp-mobility-pei/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Python 3.x:    Ensure Python is installed and available in your system path. Check using:    <pre><code>python --version\n</code></pre></p> </li> <li> <p>Required Libraries:    Install the following Python libraries:</p> </li> <li>osmnx</li> <li>pandas</li> <li>numpy</li> <li>matplotlib.pyplot</li> <li>csv</li> <li> <p>census</p> </li> <li> <p>Census API Key:    Obtain a Census API key from Census API Key Signup.    Save the key in a text file named <code>census_api_key.txt</code> in the same directory as <code>PDI_generator.ipynb</code>.</p> </li> </ol>"},{"location":"25sp-mobility-pei/#installation","title":"Installation","text":"<p>Install the required libraries using pip: <pre><code>pip install osmnx pandas numpy matplotlib csv census\n</code></pre></p>"},{"location":"25sp-mobility-pei/#3-core-subindices","title":"3. Core Subindices","text":""},{"location":"25sp-mobility-pei/#population-density-index-pdi","title":"Population Density Index (PDI)","text":"<ul> <li>Definition: Measures residential population density within defined areas.</li> <li>Data Source: Population and area data are downloaded from the Missouri Census Data Center.</li> <li> <p>Calculation:</p> <p>\\(\\text{Population Density} = \\frac{\\text{Total Population}}{\\text{Total Area (Square Miles)}}\\)   - PDI: Percentile rank of Population Density across all years and cities.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#commercial-density-index-cdi","title":"Commercial Density Index (CDI)","text":"<ul> <li>Definition: Evaluates the density of commercial establishments per block group.</li> <li>Data Source: Data is sourced using the Overpass API.</li> <li>Method:</li> <li>Tags used include shops, restaurants, cafes, banks, schools, cinemas, parks, sports centers, and stadiums.</li> <li> <p>Area is derived from census tracts in the US Census GeoJSON files.</p> <p>\\(\\text{Commercial Density} = \\frac{\\text{Count of Commercial POIs}}{\\text{Total Land Area (Square Miles)}}\\)   - CDI: Percentile rank of Commercial Density across all years and cities.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#intersection-density-index-idi","title":"Intersection Density Index (IDI)","text":"<ul> <li>Definition: Quantifies the density of intersections in a given area.</li> <li>Data Source: Retrieved using the Overpass API.</li> <li>Method: \\(\\text{Intersection Density} = \\frac{\\text{Number of Nodes Part of More than One Way (Intersections)}}{\\text{Area (Square Miles)}}\\) </li> <li>IDI: Percentile rank of Intersection Densities across all years and cities.</li> </ul>"},{"location":"25sp-mobility-pei/#land-use-diversity-index-ldi","title":"Land-use Diversity Index (LDI)","text":"<ul> <li>Definition: Analyzes the diversity of land-use types within an area.</li> <li>Data Source: Land-use data is retrieved from OpenStreetMap using the Overpass API with the \"landuse\" tag.</li> <li>Method: \\(\\text{Entropy} = \\sum \\left( \\frac{\\text{Area of Land Use Type}}{\\text{Total Area}} \\cdot \\ln \\left( \\frac{\\text{Area of Land Use Type}}{\\text{Total Area}} \\right) \\right)\\) (for all land-use types with non-zero area).     <ul> <li>Normalized by: \\(\\frac{\\text{Entropy}}{\\ln(\\text{Number of Land Use Types with Non-Zero Area})}\\) </li> <li>LDI: Percentile rank of Entropies across all years and cities.</li> </ul> </li> </ul>"},{"location":"25sp-mobility-pei/#4-pei-formula","title":"4. PEI Formula","text":"<p>The PEI is calculated using the following formula:</p> \\[ PEI = \\frac{{(1 + PDI) \\cdot (1 + IDI) \\cdot (1 + LDI) \\cdot (1 + CDI)}}{16} \\]"},{"location":"25sp-mobility-pei/#5-implementation-workflow","title":"5. Implementation Workflow","text":""},{"location":"25sp-mobility-pei/#step-1-files","title":"Step 1: Files","text":"<ul> <li>Download population data files from the Missouri Census Data Center (MCDC) for each required year.</li> <li>Download block group and census tract files from the US Census Bureau website.</li> </ul>"},{"location":"25sp-mobility-pei/#step-2-subindex-calculation","title":"Step 2: Subindex Calculation","text":"<ul> <li>Run individual generator scripts (e.g., <code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.ipynb</code>) for each subindex.</li> <li>Outputs include CSV and GeoJSON files with fields for block group, year, and the \"raw subindex\" values:</li> <li>Population Density</li> <li>Commercial Density</li> <li>Intersection Density</li> <li>Entropy</li> <li>Append all results to master files (<code>all_PDI</code>, <code>all_CDI</code>, <code>all_IDI</code>, <code>all_LDI</code>) for comprehensive cross-year/city comparison.</li> </ul>"},{"location":"25sp-mobility-pei/#step-3-normalization","title":"Step 3: Normalization","text":"<ul> <li>Normalize raw subindex data - between 1 and 0:</li> <li>This normalization is done by taking each block group/tract's percentile rank for each \"raw subindex\" versus every other city and every other year:</li> <li>Because we normalize across all cities and years, our subindex values can be compared seamlessly against any other block group regardless of time/location.</li> <li>We are able to normalize across all cities and years thanks to these aforementioned 4 files - <code>all_PDI.csv</code>, <code>all_CDI.csv</code>, <code>all_IDI.csv</code>, <code>all_LDI.csv</code> - which contain raw data for all years/cities.</li> <li>Once we normalize the raw subindex we can now call it an actual subindex - e.g. the normalized <code>Commercial Density</code> becomes <code>CDI</code>, normalized <code>Entropy</code> becomes <code>LDI</code>, etc.</li> <li> <p>The file also updates the CSV &amp; GeoJSON files for each subindex and city with a new field - one of <code>CDI</code>, <code>LDI</code>, <code>PDI</code>, <code>IDI</code>.</p> </li> <li> <p>Now we finally have finalized CSV and GeoJSON files for the 4 subindexes:</p> <ul> <li><code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.csv/geojson</code></li> </ul> </li> </ul>"},{"location":"25sp-mobility-pei/#step-4-pei-calculation","title":"Step 4: PEI Calculation","text":"<ul> <li>Combine normalized subindices using the PEI formula for each block group/tract.</li> <li>Generate CSV and GeoJSON files (<code>PEI_&lt;city&gt;_&lt;year&gt;.csv/geojson</code>).</li> </ul>"},{"location":"25sp-mobility-pei/#step-5-web-app-integration","title":"Step 5: Web App Integration","text":"<ul> <li>Upload finalized GeoJSON files to AWS S3 buckets.</li> <li>Implement and visualize data on the web app.</li> </ul>"},{"location":"25sp-mobility-pei/#6-usage","title":"6. Usage","text":""},{"location":"25sp-mobility-pei/#inside-the-fall24-folder-you-will-find-3-folders","title":"Inside the Fall24 folder you will find 3 folders:","text":"<ul> <li>Tract_Files - we mainly used this folder for testing:</li> <li>This contains the relevant <code>ipynb</code> files for creating the subindexes.</li> <li> <p>It also contains <code>tracts.geojson</code> which has the first 10 rows of tracts in the US - useful for testing.         - Please download full tract files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</p> </li> <li> <p>BlockGroup_Files:</p> </li> <li>This contains the relevant <code>ipynb</code> files for creating the subindexes. (In the PDI file, only run code blocks after the <code>#NEW</code> comment).</li> <li>It also contains <code>block_groups.geojson</code> which has the first 10 rows of blockgroups in Atlanta - useful for testing.         - Please create the full files using the <code>./Spring24/Blockgroup GeoJSON Generator</code> folder (you need to rename the output of this to <code>block_groups.geojson</code>), downlaod the full files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</li> </ul>"},{"location":"25sp-mobility-pei/#step-1-data-download","title":"Step 1: Data Download","text":"<p>Download the required data files from the following sources: - Population Data: Obtain CSV files from Missouri Census Data Center (MCDC). - Census Block Groups/Tract GeoJSON: Retrieve the required GeoJSON files from the US Census Bureau or relevant sources:      - As described above, download files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</p>"},{"location":"25sp-mobility-pei/#step-2-update-generator-scripts","title":"Step 2: Update Generator Scripts","text":"<p>Modify the generator scripts (<code>PDI_Generator.ipynb</code>, <code>CDI_Generator.ipynb</code>, <code>LDI_Generator.ipynb</code>, <code>IDI_Generator.ipynb</code>) to include your specific file paths and input parameters. For all the subindex files, they will have a portion like the code shown below. This is the only part you must update as required:</p> <pre><code>calculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2013,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n\ncalculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2017,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n\ncalculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2022,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n</code></pre>"},{"location":"25sp-mobility-pei/#step-3-run-scripts-in-the-following-order","title":"Step 3: Run Scripts in the Following Order","text":"<ol> <li>Run the Subindex Generators:    Execute the following scripts to calculate raw subindices:</li> <li><code>CDI_Generator.ipynb</code></li> <li><code>LDI_Generator.ipynb</code></li> <li> <p><code>IDI_Generator.ipynb</code>    These can be run in any order.</p> </li> <li> <p>Run PDI</p> </li> <li>For small input files (not many tracts or geojsons), run our current <code>PDI_Generator.ipynb</code>.</li> <li> <p>For larger files, a custom approach using CSV files from Missouri Census Data Center (MCDC) is requied:         - For this, please contact cnguyen369@gatech.edu</p> </li> <li> <p>Normalize Subindices:    Run <code>Normalizer.ipynb</code> to normalize the raw subindices across all years and cities.</p> </li> <li> <p>Generate PEI:    Finally, run <code>PEI_Generator.ipynb</code> to calculate the Pedestrian Environment Index.</p> </li> </ol>"},{"location":"25sp-mobility-pei/#step-4-output","title":"Step 4: Output","text":"<ul> <li>This process will output normalized subindex files and the final PEI results as CSV and GeoJSON files.</li> <li>The file format will be:<ul> <li><code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.csv/geojson</code></li> </ul> </li> <li>Utilize the <code>Subindex_Visualizer.ipynb</code> file to visualize your geojson file output!</li> </ul>"},{"location":"25sp-mobility-pei/#7-challenges","title":"7. Challenges","text":""},{"location":"25sp-mobility-pei/#the-biggest-challege-in-our-statistic-generators-was-developing-the-pdi-generator","title":"The biggest challege in our statistic generators was developing the PDI Generator.","text":"<ul> <li> <p>While most of our subindexes - <code>CDI</code>, <code>LDI</code>, <code>IDI</code> - use the <code>Overpass API (OSM data)</code> to gather data, this is not possible for the <code>PDI</code> as population data is not provided by OSM.</p> </li> <li> <p>Because of this, we were forced to utilize the <code>Census API</code>, which had 2 main issues:</p> <ul> <li>It often returned simply the latest data i.e. 2024 data - even when we requested historical population data.</li> <li>On large geoJSONs, where we have to make hundreds and thousands of API calls, the Census API frequently errored due to API call limits.<ul> <li>This became a considerable problem when running our files using <code>PACE</code> to generate Census Tract data for Dr Ku. Our code would run for 10 or so hours and then fail - as we would run out of API tokens.</li> </ul> </li> </ul> </li> <li> <p>We got over this challenge by downloading population data by tract/block group directly - from Missouri Census Data Center (MCDC)</p> </li> <li>We could then easily calculate <code>Population Density</code> and hence <code>PDI</code> by block_group/tract by merging this data with our block_groups/tracts geoJSON files - which contain an area column.</li> </ul>"},{"location":"25sp-mobility-pei/#8-spring-2025-aditions-pei-dynamic-adjustment-documentation","title":"8. Spring 2025 Aditions - PEI Dynamic Adjustment Documentation","text":"<p>The purpose of this tool is to load block groups sequentially with their individual and combined subindex scores and change a subindex value at a specified block group to observe trends and distinguishing factors from adjacent block groups. This proffers insight into how adjacent block groups can become more cohesive and bolster existing infrastructure to create a more pedestrian-friendly environment.</p> <ul> <li> <p>Input:   The tool takes in a GeoDataFrame with GEOID'd block groups, along with the four subindices and its composite PEI, plus user-provided selections for block group, subindex, and new value.</p> </li> <li> <p>Output:   The output is a live-updated GeoDataFrame where the specified subindex value is modified for the chosen block group, enabling visualization of the resulting changes to the map and overall infrastructure.</p> </li> <li> <p>Challenges:   Key challenges included maintaining data integrity after edits, and beginning the design of the function for seamless integration with interactive visualization tools on the web app.</p> </li> <li> <p>Future Work:   Future improvements include adding functionality to adjust multiple subindices at once, creating a user-friendly and non-terminal application to the web app to visualize theoretical metropolitan PEI changes, and integrating model-based recalculations of PEI rather than direct manual edits.</p> </li> <li> <p>Conclusion:   The PEI slider tool provides an intuitive way to experiment with subindex values and better understand the sensitivity of walkability metrics at a granular level, paving the way for more informed urban planning discussions.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#9-spring-2025-aditions-public-transport-accessibility-level-ptal","title":"9. Spring 2025 Aditions - Public Transport Accessibility Level (PTAL)","text":"<p>This project also implements the Public Transport Accessibility Level (PTAL) methodology, adapted from Transport for London\u2019s (TfL) standard practices (Reference: PTAL Methodology, Transport for London, April 2010). PTAL measures the accessibility of locations to public transit services based on walking distance and service frequency.</p>"},{"location":"25sp-mobility-pei/#1-motivation-and-introduction_1","title":"1. Motivation and Introduction","text":"<p>The PTAL score quantifies how easily a location is served by public transit. This project adapts the PTAL method for U.S. cities like Atlanta, enabling:</p> <ul> <li>Quantitative assessments of transit accessibility.</li> <li>Cross-region comparison of transit service quality.</li> <li>Identification of underserved and well-served areas for urban planning.</li> </ul>"},{"location":"25sp-mobility-pei/#2-getting-started_1","title":"2. Getting Started","text":"<ul> <li>Prerequisites:</li> <li>Python 3.x</li> <li>Libraries: <code>geopandas</code>, <code>pandas</code>, <code>numpy</code>, <code>shapely</code>, <code>math</code></li> <li>Public Transit Stop Data (GeoJSON) with service frequency information (data pulled from UrbanFootprint and Mobility Database).</li> </ul>"},{"location":"25sp-mobility-pei/#3-core-components","title":"3. Core Components","text":"<ul> <li>Walk Access Time:   Time taken to walk from a Point-of-Interest (POI) to a Service Access Point (SAP) like a bus stop or rail station.</li> <li>Walk speed: 80 meters/minute (4.8 km/hr).</li> <li> <p>Max distances: 640m for buses, 960m for rail.</p> </li> <li> <p>Service Frequency and Reliability:   Number of transit services per hour.</p> </li> <li>Add 2 minutes reliability penalty for buses.</li> <li> <p>Add 0.75 minutes reliability penalty for rail.</p> </li> <li> <p>Equivalent Doorstep Frequency (EDF):</p> </li> <li> <p>Formula:     $$     EDF = \\frac{30}{\\text{Walk Time} + \\text{Average Waiting Time}}     $$</p> </li> <li> <p>Accessibility Index (AI):</p> </li> <li> <p>Calculation: Sum of EDFs, with secondary routes discounted by 50% to avoid overrepresentation.</p> </li> <li> <p>PTAL Level Assignment:</p> </li> <li>Accessibility Index values are normalized similar to other subindices.</li> </ul>"},{"location":"25sp-mobility-pei/#4-ptal-calculation-workflow","title":"4. PTAL Calculation Workflow","text":"<ul> <li>Data Preparation:</li> <li>Load POIs (e.g., block groups).</li> <li> <p>Load Transit Stops with service frequency attributes.</p> </li> <li> <p>Walk Access Calculation:</p> </li> <li> <p>Filter stops within the walking thresholds.</p> </li> <li> <p>Access Time and EDF Calculation:</p> </li> <li>Compute walk time and average waiting time.</li> <li> <p>Calculate EDF for each nearby route.</p> </li> <li> <p>Accessibility Index Computation:</p> </li> <li> <p>Sum EDFs, applying 50% discount to non-dominant routes per transport mode.</p> </li> <li> <p>PTAL Assignment:</p> </li> <li>Assign final PTAL levels based on AI bands.</li> </ul>"},{"location":"25sp-mobility-pei/#5-outputs","title":"5. Outputs","text":"<ul> <li>Final outputs are available as CSV and GeoJSON files with PTAL scores for each geographic unit.</li> </ul>"},{"location":"25sp-mobility-pei/#6-challenges","title":"6. Challenges","text":"<ul> <li>Limited transit stop data coverage in non-dense areas.</li> <li>Incomplete GTFS feeds for certain systems.</li> <li>Simplified pedestrian network modeling.</li> </ul>"},{"location":"25sp-mobility-pei/#6-limitations","title":"6. Limitations","text":"<ul> <li> <p>Data Quality and Completeness:   PEI heavily relies on OpenStreetMap (OSM) data and census datasets, which may have missing or outdated entries, especially outside major urban centers.</p> </li> <li> <p>Simplified Walkability:   Current PEI calculations assume basic walk access without modeling detailed pedestrian barriers (e.g., highways, rivers, unsafe crossings).</p> </li> <li> <p>Transit Data Challenges:   PTAL relies on accurate service frequency data, which is often incomplete, inconsistent, or missing for certain cities or transit providers.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#7-future-work","title":"7. Future Work","text":"<ul> <li>Integrate complete GTFS schedule data for previous years.</li> <li>Merge with walkability indices like PEI for a full mobility landscape.</li> </ul>"},{"location":"25sp-mobility-pei/#10-spring-2025-aditions-nationwide-data-generation-for-dr-ku","title":"10. Spring 2025 Aditions - Nationwide Data Generation for Dr Ku.","text":"<p>We also created a nationwide data dataset using the PEI methodologies we described above. We simple ran the relevant PEI files in the aforementioned way (see 6. Usage), but with a <code>national_tracts.geojson</code> file. - This dataset containts CDI, LDI, IDI, PDI, and PEI files as a CSV. - We created the files on both a Tract and County level (County Level data is new to Spring 2025).</p> <p>In order to access raw files, please contact: abeesen3@gatech.edu</p>"},{"location":"25sp-mobility-pei/#nationwide-dataset-examples","title":"Nationwide dataset examples:","text":"Boston Chicago Miami New York San Francisco Washington, DC"},{"location":"25sp-mobility-pei/#11-spring-2025-aditions-pei-documentation","title":"11. Spring 2025 Aditions - PEI Documentation.","text":"<p>We also created an easy-to-share pdf file that summarizes our PEI methodologies to be used for exposure, funding, etc. This can be found in this repository as <code>VIP_PEI_Documentation.pdf</code>.</p>"},{"location":"25sp-mobility-pei/#12-overall-future-work","title":"12. Overall Future Work","text":"<p>To improve the comprehensiveness of the Public Infrastructure Environment (PIE) framework, a major future goal is to expand the number of subindices beyond the current set. If we were to do this, we also want to make sure that they are properly integrated into PEI.</p> <p>Planned improvements include:</p> <ul> <li> <p>Support for New Subindices:   Add visualization options for future subindices.</p> </li> <li> <p>Expansion to More Cities:   Make additional cities available for viewing.</p> </li> <li> <p>Official Publication:   Publish our research officially and publicly to help advance urban sustainability.</p> </li> <li> <p>Verification via Overpass API:   Fully integrate data checking against Overpass API to verify the accuracy of inputted data.</p> </li> <li> <p>Ground-Truthing:   Conduct surveys and other research to validate PEI accuracy and compare with other walkability models.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#13-contributing","title":"13. Contributing","text":"<p>We welcome contributions to this project.  </p>"},{"location":"25sp-mobility-pei/#steps-to-contribute","title":"Steps to Contribute:","text":"<ol> <li>Fork the repository.</li> <li>Create a feature branch:    <pre><code>git checkout -b feature/new-feature\n</code></pre></li> <li>Push your changes and submit a pull request.</li> </ol>"},{"location":"25sp-mobility-pei/#14-license","title":"14. License","text":"<p>This project is shared for research and educational purposes. Please do not redistribute for commercial use.</p>"},{"location":"25sp-mobility-pei/#web-app-documentation","title":"Web App Documentation","text":"<p>The web app is currently deployed at this link: https://vip-pei-app-2.onrender.com/ \ud83d\ude0a</p> <p>This deployment is dynamic and so any updates to our codebase (https://github.com/AtharvaBeesen/vip-pei-app-2) will automatically be displayed.</p>"},{"location":"25sp-mobility-pei/#1-introduction","title":"1. Introduction","text":"<ul> <li>App Name: VIP SMUR PEI Proof of Concept</li> <li>Purpose: Visualize the work we have done in creating the aforementioned subindexes. We also wanted to allow the data we generate to be available online in a visually appealing, paletable, and easy-to-download way.</li> </ul>"},{"location":"25sp-mobility-pei/#key-features","title":"Key Features:","text":"<ul> <li>Interactive map with GeoJSON visualization for the subindexes - PDI, IDI, CDI, LDI, PEI - across different cities and years.</li> <li>Dynamic city, statistic, and year selection.</li> <li>Ability to download CSV and GeoJSON files for selected data.</li> </ul>"},{"location":"25sp-mobility-pei/#technology-stack","title":"Technology Stack:","text":"<ul> <li>Frontend: React, JavaScript, HTML, CSS</li> <li>Backend: All functionality contained within JavaScript</li> <li>Mapping Library: Leaflet</li> <li>Data Source: Amazon S3 Buckets</li> </ul>"},{"location":"25sp-mobility-pei/#2-getting-started_2","title":"2. Getting Started","text":""},{"location":"25sp-mobility-pei/#prerequisites_1","title":"Prerequisites","text":"<ol> <li> <p>Node.js and npm/yarn:    Ensure Node.js and npm (or yarn) are installed on your system. You can check this by running:    <pre><code>node -v\nnpm -v\n</code></pre>    If not installed, download them from Node.js official site.</p> </li> <li> <p>Code Editor (Optional):    Install a code editor like Visual Studio Code.</p> </li> <li> <p>Browser:    A modern browser like Chrome, Firefox, or Edge to test your app.</p> </li> <li> <p>Git:    Install Git for cloning the repository. Check installation by running:    <pre><code>git --version\n</code></pre></p> </li> <li> <p>Leaflet Library Dependencies:    The app uses Leaflet for maps, which requires:</p> </li> <li>A valid internet connection to download Leaflet assets via npm or yarn.</li> <li>Ensure the browser supports Leaflet.</li> </ol>"},{"location":"25sp-mobility-pei/#installation_1","title":"Installation","text":"<ol> <li>Clone the repository:    <pre><code>git clone https://github.com/AtharvaBeesen/vip-pei-app-2.git\n</code></pre></li> <li>Install dependencies:    <pre><code>npm install\n</code></pre></li> <li>Ensure Leaflet is installed:    <pre><code>npm install leaflet\n</code></pre></li> <li>Run the application:    <pre><code>npm start\n</code></pre></li> <li>Access the app at <code>http://localhost:3000</code>.</li> </ol>"},{"location":"25sp-mobility-pei/#deployment","title":"Deployment","text":"<ul> <li>Already deployed! We deployed using <code>Render</code>: https://vip-pei-app-2.onrender.com/ </li> </ul>"},{"location":"25sp-mobility-pei/#3-features","title":"3. Features","text":""},{"location":"25sp-mobility-pei/#31-interactive-map","title":"3.1 Interactive Map","text":"<ul> <li>Displays GeoJSON data visualized on a Leaflet map.</li> <li>Map dynamically updates based on city, statistic, and year selections.</li> </ul>"},{"location":"25sp-mobility-pei/#32-city-statistic-and-year-selection","title":"3.2 City, Statistic, and Year Selection","text":"<ul> <li>Dropdown menus for users to select:</li> <li>Cities: Atlanta, New York, Los Angeles.</li> <li>Statistics: IDI, PDI, CDI, LDI, PEI.</li> <li>Years: 2022, 2013.</li> </ul>"},{"location":"25sp-mobility-pei/#33-file-downloads","title":"3.3 File Downloads","text":"<ul> <li>CSV and GeoJSON files for the selected data can be downloaded with a single click.</li> </ul>"},{"location":"25sp-mobility-pei/#4-components","title":"4. Components","text":""},{"location":"25sp-mobility-pei/#41-appjs","title":"4.1 App.js","text":"<ul> <li>The main entry point for the application.</li> <li>Manages state for selected city, statistic, and year.</li> <li>Renders <code>CitySelector</code>, <code>DownloadButton</code>, and <code>MapComponent</code>.</li> </ul>"},{"location":"25sp-mobility-pei/#42-cityselectorjs","title":"4.2 CitySelector.js","text":"<ul> <li>Dropdown menus for selecting city, statistic, and year.</li> <li>Capitalizes city names and statistics for user-friendly display.</li> </ul>"},{"location":"25sp-mobility-pei/#43-mapcomponentjs","title":"4.3 MapComponent.js","text":"<ul> <li>Displays the Leaflet map and GeoJSON data.</li> <li>Dynamically fetches data from S3 Buckets based on user selections (more on this below).</li> <li>Highlights GeoJSON features with a color-coded scheme based on statistic values.</li> </ul>"},{"location":"25sp-mobility-pei/#44-downloadbuttonjs","title":"4.4 DownloadButton.js","text":"<ul> <li>Provides buttons to download CSV and GeoJSON files from S3.</li> <li>Dynamically constructs download URLs based on user selections.</li> </ul>"},{"location":"25sp-mobility-pei/#5-api-integration","title":"5. API Integration","text":"<p>The app dynamically fetches GeoJSON data from an Amazon S3 bucket: - URL format: <code>https://vip-censusdata.s3.us-east-2.amazonaws.com/{city}_blockgroup_{statistic}_{year}.geojson</code></p>"},{"location":"25sp-mobility-pei/#example","title":"Example:","text":"<p>For Atlanta, IDI, and 2022: <code>https://vip-censusdata.s3.us-east-2.amazonaws.com/atlanta_blockgroup_IDI_2022.geojson</code></p>"},{"location":"25sp-mobility-pei/#5-city-comparison-tool-spring-2025","title":"5. City Comparison Tool (Spring 2025)","text":""},{"location":"25sp-mobility-pei/#1-overview","title":"1. Overview","text":"<p>We created a City Comparison Tool MVP to allow users to dynamically compare changes in walkability-related subindices (IDI, PDI, CDI, LDI, PEI) between two different years for a selected city.</p> <p>This tool calculates and visualizes the percentage change in the selected statistic for each census block group, helping to identify areas that have improved or declined over time.</p>"},{"location":"25sp-mobility-pei/#2-key-features","title":"2. Key Features","text":"<ul> <li> <p>City Selection:   Compare changes for Atlanta, New York, or Los Angeles.</p> </li> <li> <p>Statistic Selection:   Choose one of the following subindices to analyze:</p> </li> <li>Intersection Density Index (IDI)</li> <li>Population Density Index (PDI)</li> <li>Commercial Density Index (CDI)</li> <li>Land-use Diversity Index (LDI)</li> <li> <p>Pedestrian Environment Index (PEI)</p> </li> <li> <p>Year Selection:   Select two different years to calculate the percent change.</p> </li> <li> <p>Dynamic GeoJSON Visualization:   The map displays block groups color-coded by the percentage change in the selected statistic.</p> </li> <li> <p>Interactive Tooltips:   Hovering over a block group shows its GEOID and computed percent change.</p> </li> <li> <p>Custom Color Scale:   The visualization uses a diverging color scheme to easily distinguish between positive and negative changes.</p> </li> </ul>"},{"location":"25sp-mobility-pei/#3-technical-workflow","title":"3. Technical Workflow","text":"<ul> <li> <p>Data Fetching:   The tool fetches the respective city's GeoJSON files for both selected years from the Amazon S3 bucket.</p> </li> <li> <p>Difference Calculation:  </p> </li> <li>For most subindices (IDI, PDI, CDI, PEI), block groups are matched by GEOID.</li> <li> <p>For LDI (which currently lacks GEOIDs), features are temporarily matched by their array index.</p> </li> <li> <p>Percent Change Computation:   The percent change for each block group is calculated as:</p> </li> </ul> \\[ \\text{Percent Change} = \\frac{(\\text{After Value} - \\text{Before Value})}{\\text{Before Value}} \\times 100 \\] <ul> <li>Visualization:</li> <li>Block groups are shaded according to the magnitude of their percent change.</li> <li> <p>Tooltips display the block group ID and the exact percent change.</p> </li> <li> <p>Robust Edge Case Handling:</p> </li> <li>If both before and after values are zero, the percent change is set to 0.</li> <li>If a before value is zero and after is nonzero, the block group is highlighted accordingly without division errors.</li> </ul>"},{"location":"25sp-mobility-pei/#4-known-limitations","title":"4. Known Limitations","text":"<ul> <li>LDI currently matches features by array index due to missing GEOIDs (planned to be fixed in future data versions).</li> <li>Only a few cities and years are currently available.</li> <li>No smoothing or statistical aggregation (e.g., at the neighborhood level) yet applied \u2014 purely block group level.</li> </ul>"},{"location":"25sp-mobility-pei/#5-future-work","title":"5. Future Work","text":"<ul> <li>Add more cities and historical years to expand the tool\u2019s coverage.</li> <li>Improve LDI data quality by assigning proper GEOIDs.</li> <li>Integrate this comparison tool directly into the main PEI web app navigation.</li> <li>Add multi-year trend graphs and regional aggregation for deeper urban insights.</li> <li>Allow users to select multiple subindices at once for richer comparisons.</li> </ul>"},{"location":"25sp-mobility-pei/#6-future-work","title":"6. Future Work","text":""},{"location":"25sp-mobility-pei/#there-are-3-key-goals-we-hope-to-achieve","title":"There are 3 key goals we hope to achieve:","text":"<ol> <li> <p>Increase the number of cities and years supported:    This would simply require us to continue running our subindex generators over the course of the next semester(s) in order to continue to grow the size of our database.</p> </li> <li> <p>Seek Collaboration/Monetization Opportunities:    As we grow the site and our footprint in the space, we could seek to replicate WalkScore's monetization and collaboration business model:</p> </li> <li> <p>Collaborate with products/sites:       Work with products or sites that require walkability statistics (e.g., Zillow and City Planning Companies) to create customized statistics at a cost.</p> </li> <li> <p>Direct collaboration with local government:       Assist local governments in achieving their goals of improving walkability in urban areas.</p> </li> <li> <p>Developing a for-cost API:       Create an API that allows third-party researchers to use our data.  </p> <ul> <li>For Example: Collaborating with researchers like Dr. Ku, who uses our data to enhance his psychology research.</li> </ul> </li> <li> <p>Improve the UI:    This goal is less essential and is more about improving user-experience in the case that we decide to push towards becoming a standalone software for third-parties to gather walkability data on different urban areas.</p> </li> </ol>"},{"location":"25sp-mobility-pei/#7-contributing","title":"7. Contributing","text":"<ul> <li>Please contact abeesen3@gatech.edu before doing so.</li> <li>Example of how to contribute:</li> <li>Fork the repository (https://github.com/AtharvaBeesen/vip-pei-app-2)</li> <li>Create a feature branch:      <pre><code>git checkout -b feature/new-feature\n</code></pre></li> <li>Push your changes and submit a pull request.</li> </ul>"},{"location":"25sp-mobility-pei/#8-license","title":"8. License","text":"<p>This project is shared for research and educational purposes. Please do not redistribute for commercial use.</p>"},{"location":"25sp-mobility-pei/#presentation-currently-from-fall-2024-link-will-be-updated-once-the-new-presentation-is-uploaded","title":"Presentation (currently from Fall 2024, link will be updated once the new presentation is uploaded).","text":""},{"location":"25sp-mobility-pei/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Yao Xiao Sophomore Computer Science COC Xyrro Mason DeWitt Freshman Electrical Engineering ECE Masonrd Joshua Cohen Senior Civil Engineering paradoxwalk Nicholas Stone Sophomore Computer Science COC nstone213 Atharva Beesen Junior Computer Science COC AtharvaBeesen"},{"location":"24fa-mponc/","title":"24Fa-MPONC","text":"Modeling Processes of Neighborhood Change <p>Abstract</p> <p>This research project simulates the impact of the Atlanta Beltline on neighborhood gentrification using game theory and no-regret dynamics. The simulation models agent movement across census tracts, with agents seeking to minimize costs based on factors like amenity density. The methodology incorporates the four-step model for trip generation and leverages US Census data for population and income distributions. Census tract regions are mapped using TIGER/Line shapefiles, while the Beltline area is defined using OpenStreetMap data. The simulation outputs include dynamic visualizations and CSV data tracking population and income changes across census tracts, providing insights into urban development patterns.</p>"},{"location":"24fa-mponc/#setup","title":"Setup","text":"<pre><code>cd modeling_processes_of_neighborhood_change_new\nconda create -n mponc python=3.12\nconda activate mponc\npip install -r requirements.txt\npython main.py\n</code></pre>"},{"location":"24fa-mponc/#reference-paper","title":"Reference paper","text":"<pre><code>@misc{mori2024modelingprocessesneighborhoodchange,\n      title={Modeling Processes of Neighborhood Change}, \n      author={J. Carlos Mart\u00ednez Mori and Zhanzhan Zhao},\n      year={2024},\n      eprint={2401.03307},\n      archivePrefix={arXiv},\n      primaryClass={cs.MA},\n      url={https://arxiv.org/abs/2401.03307}, \n}\n</code></pre>"},{"location":"24fa-mponc/#intro-and-description","title":"Intro and Description","text":"<p>This project is based on the reference paper created by Dr. Martinez and Dr. Zhao, which aims to address the following:  - How does the layout of transportation infrastructure affect the demographics of nearby neighborhoods? - Does the creation of these infrastructure actually benefit everyone equally; is it fair? - Can we predict the effects on surrounding communities before these structures are actually built?</p> <p>These questions are primarily motivated by the issue of gentrification, an issue prevalent in many major cities. This semester, we utilized concepts in game theory, more specifically no-regret dynamics, in order to simulate the effects of the Atlanta Beltline on gentrification. Throughout this semester we followed the main ideas provided by this lecture from Stanford University: \"CS364A: Algorithmic Game Theory Lecture #17: No-Regret Dynamics\". To summarize our approach with no-regret dynamics:</p> <ul> <li>People, or 'agents', randomly move from region to region. Depending the region's attributes, a 'cost' value is assigned to each action.</li> <li>'Cost' is a function of centroid proximity, number of amenities, average income, mode of transportation, and more.</li> <li>The higher the cost, the less likely an agent is to visit that centroid in the future.</li> <li>This process is repeated until the probability distribution of visting centroids converges - an equilibrium is reached, and further actions make no difference. </li> </ul>"},{"location":"24fa-mponc/#cost-function","title":"Cost Function","text":"<p>Our current cost function takes into account a region's affordability, site upkeep, access to the Atlanta Beltline, location, community ties, and access to desirable amenities:</p> <p>cost = 1 - (affordability * upkeep * beltline * location_cost * community_cost * accessibility)</p> <ul> <li>Affordability [0 or 1]: Affordability score is [0] if 'unaffordable'; a region is 'unaffordable' if its housing capacity has been reached AND all of its inhabitants have a higher income than an Agent.</li> <li>Upkeep [0 or 1]: Upkeep score is [1] if the population is not zero.</li> <li>Access to Beltline [0 or 1]: Beltline score is [1] if the region contains part of the Atlanta Beltline.</li> <li>Location [0.0 to 1.0]: Location score is a function of* region proximity and an Agent's mode choice *(car vs. transit).</li> <li>'Transit' just adds a 1.5x multiplier to the raw distance cost.</li> <li>Community [0.0 to 1.0]: Community score is the similarity between a region's average income and an Agent's average income.</li> <li>Accessibility [0.0 to 1.0]: Accessibility score is the normalized amenity density of a region.</li> <li>Considered amenities are derived from 24Sp-Mobility-Seg, another Georgia Tech research team, in which they investigated which features of a city are most important to residents.</li> <li>We excluded certain amenities at our own discretion, such as 'shed', 'guardhouse', 'ferry_terminal', 'garages', and 'bridge' (labels as they appear on OpenStreetMap).</li> </ul>"},{"location":"24fa-mponc/#implemented-amenities-openstreetmap-labels","title":"Implemented Amenities (OpenStreetMap labels):","text":""},{"location":"24fa-mponc/#case-study","title":"Case study","text":"<p>We decided to apply the above to Atlanta and the Atlanta Beltline, as our case study for this semester. Key changes we have made to accommodate this implementation include: Incorporating the Four-Step Transportation Model, to determine mode of transportation for our agents, and an \"in Beltline\" attribute so our agents can differentiate between regions containing the Atlanta Beltline, and those outside of it. </p>"},{"location":"24fa-mponc/#the-four-step-model","title":"The Four-Step Model","text":"<p>Given that the agents move across various subregions of the Atlanta area in our simulation, one of the critical steps of the simulation is figuring out what subregion the agents go to. To do this in a way that accurately represents real-world distributions, we turned to the four-step model, a common trip generation algorithm: </p> <p></p> <p>The model has four components:</p> <ol> <li>Trip Generation: This part of the model estimates the number of trips originating from or destined for a specific area. It focuses on understanding how many trips are generated rather than specific travel patterns. This process usually involves some type of data pertaining to the area at hand, such as demographics, income, or land usage.</li> <li>Trip Distribution; This part of the model estimates the number of trips for routes that go from an area to another, as determined in the trip generation step. This process is typically done using the gravity model, which assumes that the number of trips are positively correlated with the attractiveness of an area and inversely correlated to distance.</li> <li>Mode Choice: This part of the model determines the mode of transporation used to make the trips. This is typically done by considering demographic data (such as the percentage of people with cars) in an area.</li> <li>Route Assignment: This part of the model determines the routes travelers take between origins and destinations. This is typically done by considering the route that takes the shorted possible time, and following that. </li> </ol> <p>Our approach closely follows these four components. We first generate trips by considering the amenity density of areas. We sum up all amenity densities, and divide each area's density by this sum to generate a probability. We then utilize a Poisson Distribution to generate the number of trips by multipling a base number of trips by the probability. We then consider trip distribution through a modified gravity model. The equation for our model is the following, given that we aim to go from area/region i to j:</p> <p></p> <p>We essentially multiply the total number of trips from area i to area j with the net amenity score for the destination j times transportation cost for that specific trip from area i to j, divided by the net amenity score for area j times the transportation cost from area i to j summed up over all destination j's. </p> <p>For our modal split, we assume that the car ownership rate is 0.7, and that the transit rate is 0.3. Each region's trips are split based on this. We then assign these routes based on the shortest possible distance.</p> <p>Through this process, we were able to have a methodical way of distributing the agents across Atlanta based on area factors such as amenity density.</p>"},{"location":"24fa-mponc/#census-based-approach","title":"Census-based approach","text":"<p>Our project utilizes data from the US census wherever possible. Notably, the graphical regions our agents inhabit correspond directly to US census tracts. Consequently, we can compare the economic and population data obtained from our simulation to actual census data for each census tract. Furthermore, since the US Census TIGER/Line Geodatabases contain publicly available shapefiles of all geographic regions it reports on, our simulation can likewise operate utilizing any other census-reported regions, including zip codes, housing districts, school districts, etc. </p> <p>Additionally, each 'agent' has a unique wealth attribute as one of the factors influencing decision-making. Instead of assigning these wealths arbitrarily, we create this distribution of wealth using census population and median income data, so that our agents are representative of actual Fulton and Dekalb county resident demographics. Namely, we use the following tables from the Census website: \"S1903 | Median Income In The Past 12 Months (In 2010 Inflation-adjusted Dollars) - ACS 5-Year Estimates Subject Tables\" and \"B01003 | Total Population - 2010: ACS 5-Year Estimates Detailed Tables\". By changing the hyperlinks in our code, our simulation can run with different distributions; for example, those from different years. * Note: For the median income and population tables, the hyperlinks in the code won't be 'activated', or functional, until a request is made directly on the Census website - navigate to those links and use the 'Download' button for the appropriate graphs, then run the code; no other action needed. [Fix incoming]</p>"},{"location":"24fa-mponc/#tigerline-geodatabases-shapefiles","title":"TIGER/Line Geodatabases shapefiles:","text":""},{"location":"24fa-mponc/#income-distribution-tables","title":"Income distribution tables:","text":""},{"location":"24fa-mponc/#example-simulating-a-different-geographic-region-close-up-of-atlanta","title":"[Example] Simulating a different geographic region (close-up of Atlanta):","text":""},{"location":"24fa-mponc/#project-status","title":"Project status","text":""},{"location":"24fa-mponc/#outputs-configuration","title":"Outputs &amp; configuration","text":"<p>Our code outputs a GIF to visualize agent behavior over time. Each circle represents the centroid of a census tract - green signifying those in the Atlanta Beltline - and the encircled number is the agent population. Our code also outputs a CSV file containing all the simulated data at every individual timestep.</p> <ul> <li>Data contained in CSV's: Census tract name, agent population, raw average income, average income reported by census, normalized average incomes, and amenity density.         * TODO: Include raw amenity counts, census tract geographic area (sqkm).</li> <li>Note: 'Timestep' refers to a single instance agent action (relocation); 20,000 timesteps mean the agents relocate a total of 20,000 times during the simulation.</li> </ul>"},{"location":"24fa-mponc/#gif","title":"GIF","text":"<p>This GIF shows the behavior of 1,000 agents up to 20,000 timesteps, frames being captured every 400 timesteps. Rho=1, alpha=0.25. </p>"},{"location":"24fa-mponc/#configuration","title":"Configuration","text":"<p>In configuration.py, the user can specify various settings of the simulation. Changing graph settings is a matter of changing the hyperlinks in configuration.py.</p> <p>Simulation settings:  * Total timesteps run in the simulation * Timestep interval at which to capture the GIF's frames * Number of agents * Variables affect agent behavior Graph settings: * Regions to simulate * Economic distribution data * Regions to mark as 'in the Atlanta Beltline'</p> <p>Simulation and graph settings:</p> <p></p> <p></p>"},{"location":"24fa-mponc/#runtimes","title":"Runtimes","text":"<p>(1000 agents, 530 census tracts)</p> <p>Run on a laptop...</p> <p>Fetching amenities from OpenStreetMap via OSMnx: ~37 minutes Computing centroid distances: ~18 minutes Simulation (x8): ~45 minutes GIF creation (x1), 50 frames: ~19 min * Everything except 'Simulation' and 'GIF creation' is cached, making their runtimes negligible in subsequent runs</p>"},{"location":"24fa-mponc/#atlanta-beltline-in-our-simulation","title":"Atlanta Beltline in our Simulation","text":"<p>We automate the process of labelling certain regions as 'in the Atlanta Beltline' by using commuting paths from OpenStreetMap that correspond to the Atlanta Beltline - namely, a bike trail and a railway. To experiment with a different beltline, such as a beltline that spanned across Atlanta horizontally, or simply expanded north by x miles, we would acquire the OpenStreetMap ID's of existing paths (bike trails, walking paths, roads, etc.) corresponding to our desired Beltline, and paste these into configuration.py. Alternatively, we can create a such path ourselves in OpenStreetMap. Then, any region containing segments of these trails would automatically be marked as \"In the Atlanta Beltline\". </p> <ul> <li>Note: our current code only works if these trails are labelled as \"Relations\" in OpenStreetMap         * TODO: make this dynamic</li> </ul> <p>In configuration.py - bike trail and railroad OpenStreetMap ID's:</p> <p></p> Bike Trail Railroad <p>Compare with Atlanta Beltline geography:</p> <p></p>"},{"location":"24fa-mponc/#strengths-and-weaknesses","title":"Strengths and Weaknesses","text":""},{"location":"24fa-mponc/#strengths","title":"Strengths","text":"<p>Our approach is very modularized. For instance, the four-step model created can be used in any other simulation of any other region. It simply needs lists of agents, a NetworkX graph, and other generalized parameters to operate. Furthermore, Our approach is backed by established human behavior approaches (no-regret dynamics), utilizes a distribution system that is also established (four-step model). We are able to produce dynamic visuals (GIFs).</p>"},{"location":"24fa-mponc/#weaknesses","title":"Weaknesses","text":"<p>Our approach is only limited to the 2010 Census data for \u201ctraining purposes.\u201d This may cause our model to overfit and be unable to reliably extrapolate to 2022 Census Data. Additionally, it is very time-consuming to run the simulation, as 37 minutes are currently needed to generate centroids. We aimed to solve this issue with multithreading, but API calls caused this to fail (we kept running into buffering issues). Our simulation also assumes that there is no immigration/emigration in Atlanta, as we have a set, fixed number of agents. We also limit transportation choices to cars and public transportation, even though there are other mediums. </p>"},{"location":"24fa-mponc/#next-steps","title":"Next Steps","text":"<p>This coming Spring semester, we hope to make the GIFs more clearer (currently, there is a lot of regions and it is hard to read which regions the agents are in). We additionally want to add weights to certain amenities, as realistically, some amenities are more valuable than others in driving agent decisions (for example, schools may play a more important than bike stands in driving what regions agents go to). Additionally, this coming semester, we hope to get the necessary parameters from the 2010 data and try to reproduce the 2020 demographics. </p>"},{"location":"24fa-mponc/#presentation","title":"Presentation","text":""},{"location":"24fa-mponc/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Matthew Lim Sophomore Computer Science COC mlim70 Reyli Olivo Junior Civil Engineering CEE Rolivo05 Devam Mondal Junior Computer Science COC Dodesimo"},{"location":"24fa-neuroarchitecture/","title":"Neuroarchitecture","text":""},{"location":"24fa-neuroarchitecture/#description","title":"Description","text":"<p>The isolation measures of the Coronavirus Disease 2019 (COVID-19) pandemic, like remote work and lockdowns, have negatively impacted mental health, causing loneliness, depression, and financial stress. Addressing these challenges, it's necessary to study the effects of urban built environment related to mental health and well-being, which align with SDG3 and SDG11 of the United Nations Sustainable Development Goals (SDGs).</p> <p>Neuroarchitecture is an emerging interdisciplinary field that bridges neuroscience, architecture, and urban design to create spaces that positively impact mental health and well-being. However, there is a lack of systematic literature review related to the urban built environment, mental health and well-being. Such research is critical for guiding urban planners and architects in developing strategies like designing resilient public spaces, moderating urban density to reduce stress, and developing solutions of social isolation.</p> <p>Our team aims to produce a systematic literature review that explores these connections, offering actionable insights for urban planners, designers, researchers, government agencies, and students in architecture and urban planning.</p>"},{"location":"24fa-neuroarchitecture/#tools","title":"Tools","text":""},{"location":"24fa-neuroarchitecture/#methodology","title":"Methodology","text":""},{"location":"24fa-neuroarchitecture/#search-terms-selected","title":"Search terms selected","text":"<ul> <li>Process</li> </ul> <p>Seleted Terms and Interests.xlsx</p> <ul> <li> <p>Selected Terms <pre><code>| Category            | Selected Terms                                         |\n|---------------------|--------------------------------------------------------|\n| Mental Health       | Mental Health or Mental-Health                         |\n|                     | Well-being or Well Being or wellbeing                  |\n|---------------------|--------------------------------------------------------|\n| Urban               | Built Environment                                      |\n|                     | Building Architecture                                  |\n|                     | Architectural Design                                   |\n|                     | Building Design                                        |\n|                     | Environmental Design                                   |\n|                     | Urban Architecture                                     |\n|                     | Urban Environment                                      |\n|                     | Sustainable Architecture                               |\n</code></pre></p> </li> <li> <p>Definition</p> </li> <li>Well-being<ul> <li>Definition: Well-being refers to the quality of life experienced by individuals, encompassing both physical and psychological aspects. It includes emotional, mental, and social health, as well as satisfaction in life and the                ability to function effectively in society.</li> <li>In Neuroarchitecture: Well-being is influenced by how environments (urban spaces, buildings, and natural surroundings) are designed to promote comfort, mental balance, and overall health.</li> </ul> </li> <li>Mental Health<ul> <li>Definition: Mental health is the state of well-being, where individuals can cope with stress, work productively, and contribute to their community. It is not merely the absence of mental illness but includes positive attributes                like psychological resilience and cognitive function.</li> <li>In Neuroarchitecture: Mental health is enhanced through the design of spaces that reduce stress, foster positive emotional experiences.</li> </ul> </li> <li>Built Environment<ul> <li>Definition: The built environment encompasses all human-made or modified spaces that facilitate human activity. This includes structures such as buildings, roads, bridges, parks, and other infrastructure elements. Essentially, it   comprises the physical surroundings crafted by people to support living, working, and recreational activities. We focus on outdoor built environments.</li> </ul> </li> </ul>"},{"location":"24fa-neuroarchitecture/#search-stragetgy","title":"Search stragetgy","text":"<ul> <li>Boolean Formula of different databases we use:</li> </ul> <ul> <li>Search Result</li> </ul> <p>666 references imported for screening as 666 studies   - 23 duplicates identified manually   - 101 duplicates identified by Covidence</p>"},{"location":"24fa-neuroarchitecture/#eligibility-criteria","title":"Eligibility Criteria","text":"<ul> <li>Process </li> </ul> <p>Eligibility criteria Sheet_selected_process.csv</p> <ul> <li>Eligibility Criteria</li> </ul> Eligibility Criteria Include Exclude Population Adults (16\u201360) Children &lt;16 If the average age of participants aged \u226460 is higher than those aged &gt;60  (Articles where the average age of participants aged 60 or younger is higher than the average age of participants over 60) If the average age of participants aged &gt;60 exceeds those aged \u226460  (Articles where the average age of participants over 60 is higher than the average age of participants aged 60 or younger) Elderly 60+ Animal Studies Intervention / Exposure Built environment Doesn\u2019t mention built environment Comparator / Context Urban or suburban environment Prison Exterior and semi-exterior spaces Airports Interior-only Spaces Outcome Mental health/well-being Doesn\u2019t mention mental health/well-being Physical health Violence, Crime and Peer Victimization Other Published 2014\u20132024 Not English Letters, editorials, essays, or other non-peer-reviewed material Reviews, meta-analyses, case reports, books, conference abstracts, dissertation Doesn\u2019t Published 2014\u20132024"},{"location":"24fa-neuroarchitecture/#screening-title-and-abstract","title":"Screening \u201cTitle and Abstract\u201d","text":"<ul> <li>Result</li> </ul> <p>542 studies screened against title and abstract, 362 studies excluded</p> <ul> <li> <p>Problem</p> </li> <li> <p>Some are without Abstract</p> <ul> <li>Abstracts of some doc type can\u2019t be imported: letters, editorials, essays or other non-peer-reviewed material, reviews, meta-analysis, case-reports, books, conference abstracts, dissertation.</li> <li>Abstracts have other language.</li> <li>Some article have limited access.</li> <li>For some abstracts, Google Scholar does not have permission to export the abstracts, so\u00a0we must search again in other databases.</li> </ul> </li> <li> <p>Some title and abstract mention both mental health and physical health</p> </li> <li> <p>As for mental health/wellbeing outcomes, some terms like \u201csatisfaction\u201d, \u201cstress\u201d be classified under wellbeing without specifically mentioning the term \u201cwellbeing\u201d.</p> </li> <li> <p>Some Transportation (Reducing stress from commuting or causing traffic-related stress).</p> </li> </ul>"},{"location":"24fa-neuroarchitecture/#screening-full-text-review","title":"Screening \u201cFull-text Review\u201d","text":"<ul> <li>Result</li> </ul> <p>158 studies assessed for full-text eligibility, 91 studies excluded.</p> <ul> <li>36\u00a0 Wrong population (not within 16-60)</li> <li>19\u00a0 letters, editorials, essays or other non-peer-  reviewed material, reviews, meta-analysis, case-reports, books, conference abstracts, dissertation</li> <li>13\u00a0 Wrong outcomes (does not mention mental health/well-being)</li> <li>10\u00a0 Wrong intervention (does not mention elements of built environment)</li> <li>8\u00a0 Wrong setting (not urban or suburban environment)</li> <li>4\u00a0 Interior-only spaces</li> <li> <p>1\u00a0 Not English (full text in another language besides English)</p> </li> <li> <p>Problem</p> </li> <li> <p>Age Problem</p> <ul> <li>Some of the literature does not specifically describe the age distribution of the study subjects.</li> <li>The age and demographic characteristics of the study subjects were not described in sufficient detail.</li> <li>The study subjects included very few children or elderly people, meaning that the majority of subjects were aged 16-60.</li> </ul> </li> <li> <p>Built Environment</p> <ul> <li>Exclude papers that discuss only indoor environments, and if the article discusses both outdoor built environments and indoor built environments, include them.</li> </ul> </li> <li> <p>Soluton of Age Problem</p> </li> <li>For documents in which a very small number of children or elderly\u00a0 are included in the research subjects, the current solution is to retain these documents, but the criteria for handling such cases need to be further clarified.(mean of ages reported as exclusion criteria)</li> <li>When writing the system literature review, it was pointed out that research in the field of architecture is relatively loose in terms of describing the research population and standardizing data compared to fields such as psychology or psychiatry, and calls for stricter standards      in the field.</li> </ul>"},{"location":"24fa-neuroarchitecture/#data-extraction","title":"Data Extraction","text":"<p>Data Extraction Draft </p>"},{"location":"24fa-neuroarchitecture/#results","title":"Results","text":""},{"location":"24fa-neuroarchitecture/#plan","title":"Plan","text":"<ul> <li>Reading list</li> </ul> <ul> <li>Publish</li> </ul> <ul> <li>Text Mining</li> </ul>"},{"location":"24fa-neuroarchitecture/#presentation","title":"Presentation","text":""},{"location":"24fa-neuroarchitecture/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Changda Ma Masters Architecture ARCH changdama Misha Lee Sophomore Civil Engineering CEE memesha L. Q. Nhu Nguyen Masters Architecture ARCH qnguyen322 Parya Monjezi Masters Architecture  (HBP) ARCH Pmonjezi3"},{"location":"24fa-neuroarchitecture/selecting_process/Data%20Extraction/","title":"Data Extraction","text":"<p>Data Extraction</p> <p>Identification</p> <ul> <li>Title  </li> <li>Author  </li> <li>Country in which the study conducted</li> </ul> <p>Methods</p> <ul> <li>Study design  </li> <li>A Survey-based study  </li> <li>Randomised controlled trial  </li> <li>Case-control study  </li> <li>Historically controlled trial  </li> <li>Prospective cohort study  </li> <li>Retrospective cohort study  </li> <li>Hypothesis study  </li> <li>Cross-sectional observational study  </li> <li>K-means cluster analyses  </li> <li>Others</li> </ul> <p>Population</p> <ul> <li>Population description  </li> <li>Inclusion Criteria  </li> <li>Exclusion Criteria (because some of the participants in the articles do not meet the  include  criteria, but the proportion is very small)  </li> <li>Group difference  </li> <li>Method of recruitment of participants  </li> <li>Population data  </li> <li>Total number of participants  </li> <li>Number of withdrawals  </li> <li>Reason for withdrawals  </li> <li>Other  </li> <li>Population Characteristics  </li> <li>Mean age (years) \u00b1 SD  </li> <li>Age Category(Range)  </li> <li>Gender Distribution  </li> <li>Identity  </li> <li>Educational level  </li> <li>Ethnic Background  </li> <li>Language Proficiency  </li> <li>Physical Ability  </li> <li>Nationality   </li> <li>Marital Status   </li> <li>Residency or Migrant(e.g Participants must have lived in the city for at least six months.)  </li> <li>Household income  </li> <li>Job  </li> <li>Health  </li> <li>Family composition  </li> <li>Others</li> </ul> <p>Intervention / Exposure </p> <ul> <li>Intervention categories  </li> <li>Outdoor Built environment  <ul> <li>Urban environment  </li> <li>Public open space  </li> <li>Plazas and square  </li> <li>Urban green space  </li> <li>Sports and Recreation Areas  </li> <li>Accessibility to transportation  </li> <li>Proximity to city center  </li> <li>Visual appeal  </li> <li>Walkable accessibility/distances/ pedestrian walkway  </li> <li>Sub-urban environment  </li> </ul> </li> <li>Environmental factors  <ul> <li>Air pollution  </li> <li>Sunlight  </li> <li>Temperature  </li> <li>Humidity  </li> <li>Noise  </li> </ul> </li> <li>Intervention characteristics  </li> <li>Number of participants allocated  </li> <li>Frequency  </li> <li>Percentages  </li> <li>Other</li> </ul> <p>Outcome</p> <ul> <li>Outcome categories  </li> <li>Mental health   </li> <li>Well-being  <ul> <li>Subjective Well Being (SWB)  </li> <li>Comfort  </li> <li>Satisfaction  </li> </ul> </li> <li> <p>Outcome Type  </p> <ul> <li>continuous(e.g data,score)  </li> <li>dichotomous(e.g true or false)</li> </ul> </li> <li> <p>Outcome details </p> </li> <li> <p>CR:Composite Reliability  </p> </li> <li>C\u03b1: Cronbach's Alpha  </li> <li>SFL: standardized factor loading  </li> <li>AVE:average variance extracted  </li> <li>VIF:variance inflation factor.  </li> <li>Fornell\u2013Larcker(F-L)criteria  </li> <li>heterotrait\u2013monotrait(HTMT)ratio  </li> <li>T Value  </li> <li>beta coefficients(\u03b2)  </li> <li>95% CI  </li> <li>P-value</li> </ul> <p>Result</p> <ul> <li> </li> <li> <p>Mean  </p> </li> <li>Sum  </li> <li>Median  </li> <li>IQR(Interquartile Range)  </li> <li>Range  </li> <li>P-value  </li> <li>beta coefficients(\u03b2)  </li> <li>95% confidence intervals(95%CI)  </li> <li> <p>Others</p> </li> <li> </li> <li> <p>Ratio</p> </li> </ul>"},{"location":"24fa-neuroarchitecture/selecting_process/Data%20Extraction/#continuous-data","title":"Continuous data","text":""},{"location":"24fa-neuroarchitecture/selecting_process/Data%20Extraction/#dichotomous-data","title":"Dichotomous data","text":""},{"location":"24fa-energyinbuildings-res/","title":"24Fa-EnergyInBuildings-Res","text":"<p>Energy in Buildings - Residential</p>"},{"location":"24fa-energyinbuildings-res/#introduction","title":"Introduction","text":"<p>This project intends to build and research upon a surrogate model that could help predict the heating and cooling demands of residential homes specifically in Georgia. The model researched here is very similair to the one used by the sister team Energy in Buildings - Commercial. Whilst the models are similair at first, some differences were applied in our research as some variables are more preferable to Residential Buildings rather than their Commercial counterparts. </p>"},{"location":"24fa-energyinbuildings-res/#about-the-model","title":"About the model","text":"<p>The machine learning model is based on this notebook on Optimization of building energy consumption. The version here is pretty light as of now, and it consists of 3 main python files, where at the end it should give out a SAV file that can be used to make predictions given certain inputs for whichever program they are needed for. </p> <p>Before the model is ran, the proper Dataset to train the model must be created. We sourced our dataset from NREL-ResStock. We chose the variables we thought would be most important specifically for residnetial buildings and also combined information to create our own independent columns as seen below. </p>"},{"location":"24fa-energyinbuildings-res/#encoderpy","title":"Encoder.py","text":"<p>After the dataset is finalized, it is ran through the Encoder.py file. Since the model relies on numerical data, it is imperative to find ways to convert categorical data to be usable. Specific to this, our inputs for BuildingType and Orientation were simply label encoded. This file must be updated if other categorical or non-numerical data values are inputted for a new dataset. The file also creates a mapping csv to show what the numbers means after the data is encoded.</p>"},{"location":"24fa-energyinbuildings-res/#mainpy","title":"Main.py","text":"<p>This file is similair to the notebook 1B, except updated to account fo two output variables and specific to the dataset. As the groups later merged into one, a lot of updated research was done so the model currently is not updated. As of now, similair to 1B Notebook, the file creates various plots whoch showcase statistics, such as the correlation in the heatmap shown below.  </p> <p>The file then gives relational data on various ML models and then chooses Random Forest to then show predicted input and outputs. The model is then saved to a SAV file. </p>"},{"location":"24fa-energyinbuildings-res/#predictorpy","title":"Predictor.py","text":"<p>This file is a barebones program that takes in the model via the previously saved SAV and asks the user to give the value of the respective inputs. From here it runs the model and gives out the prediction on the potential residential buildings heating and cooling load. </p> <p></p>"},{"location":"24fa-energyinbuildings-res/#presentation","title":"Presentation","text":""},{"location":"24fa-energyinbuildings-res/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Sharmista Debnath Masters Architecture (HBP) ARCH Myshx Kiana Layam Masters Architecture (HBP) ARCH kkvlayam Jiayi Li Junior Architecture ARCH jli3307 Shivam Patel Senior Computer Science COC FlippyShivam Hang Xu PhD Architecture ARCH HangXXXu"},{"location":"24fa-energyinbuildings-com/","title":"24-Fa-Energy-Com","text":"<p>24Fa-EnergyInBuildings-Com</p>"},{"location":"24fa-energyinbuildings-com/#about-the-project","title":"About the Project","text":""},{"location":"24fa-energyinbuildings-com/#built-with","title":"Built with","text":""},{"location":"24fa-energyinbuildings-com/#introduction","title":"Introduction","text":"<p>This project reviews various machine learning models to predict the heating and cooling demand of commercial buildings in Georgia state. To ensure the diversity of potential features, we include both numerical and categorical feature as independent variable. </p> <p>Watch the Video Demo </p> <p></p> <p></p>"},{"location":"24fa-energyinbuildings-com/#repository-structure","title":"Repository Structure","text":"<p>The repository follows the structure below:</p> <p>Note that 'Model Training Workflow' is the main body of model training in this project, whereas 'Multivariate Regression Model' and 'energy_game' show a sample pipeline from model training to deployment application. </p> <pre><code>\u251c\u2500 Model Training Workflow\n\u251c\u2500 Multivariate Regression Model\n\u251c\u2500 energy_game\n\u2514\u2500 README.md\n</code></pre>"},{"location":"24fa-energyinbuildings-com/#frontend","title":"Frontend","text":"<p>The frontend of energy_game follows the structure below: <pre><code>energy_game\n\u251c\u2500 ...\n\u251c\u2500 app                   \n|  \u251c\u2500 api/predict         ## forwards frontend to a Flask API for prediction, and returns prediction\n|  \u251c\u2500 components          ## frontend components and corresponding css files\n|  \u251c\u2500 data                ## defaultBuilding.json\n|  \u251c\u2500 flask-api           ## flask backend\n|  \u251c\u2500 fonts               ## fonts \n|  \u251c\u2500 favicon.ico         ## website icon\n|  \u251c\u2500 globals.css         ## global styles\n|  \u251c\u2500 layout.tsx          ## layout of Next.js app\n|  \u251c\u2500 page.tsx            ## main page with frontend components\n|  \u2514\u2500 three-types.d.ts    ## GLTFLoader for previewer\n\u2514\u2500 ...\n</code></pre></p>"},{"location":"24fa-energyinbuildings-com/#backend","title":"Backend","text":"<p>The backend of energy_game follows the structure below: <pre><code>energy_game\n\u251c\u2500 ...\n\u251c\u2500 app                   \n|  \u251c\u2500 flask-api\n|  |  \u251c\u2500 Model_Cooling_1104    ## desc\n|  |  |  \u251c\u2500 X13_EnergyCode_encoder.pkl   ## \n|  |  |  \u251c\u2500 X14_HVAC_encoder.pkl         ## \n|  |  |  \u251c\u2500 X1_Type_encoder.pkl          ## \n|  |  |  \u251c\u2500 X3_Shape_encoder.pkl         ## \n|  |  |  \u251c\u2500 gbr_best_Y2.sav              ## \n|  |  |  \u2514\u2500 gbr_best_Y2_compat.joblib    ## \n|  |  |\n|  |  \u251c\u2500 Model_Heating_1104    ## contains similar files as Model_Cooling_1104\n|  |  \u251c\u2500 app.py                ## desc\n|  |  \u2514\u2500 requirements.txt      ## desc\n\u2514\u2500 ...\n</code></pre></p>"},{"location":"24fa-energyinbuildings-com/#getting-started","title":"Getting Started","text":""},{"location":"24fa-energyinbuildings-com/#requirements","title":"Requirements","text":"<ol> <li> <p>Run with Python 3.12.5 (otherwise there are issues with the .pkl files)</p> </li> <li> <p>Install node.js</p> </li> </ol>"},{"location":"24fa-energyinbuildings-com/#setup-to-run-locally","title":"Setup to run locally","text":"<ol> <li>Clone the repository using    <pre><code>git clone https://github.com/VIP-SMUR/24Fa-EnergyInBuildings-Com.git\n</code></pre></li> <li>Navigate to the project folder    <pre><code>cd energy_game\n</code></pre></li> <li>Run front end locally using    <pre><code>npm run dev\n</code></pre></li> <li>To run the flask backend, open a new terminal and navigate to the energy_game/app/flask-api folder. Make sure to have the required python libraries. You can then run app.py without any errors    <pre><code>pip install -r /path/to/requirements.txt\n\npython app.py\n</code></pre></li> </ol>"},{"location":"24fa-energyinbuildings-com/#model-information","title":"Model Information","text":""},{"location":"24fa-energyinbuildings-com/#datasets","title":"Datasets","text":"<p>We collected all of the necessary data for training from ComStock - NREL. </p> <p>Our refined and merged datasets can be found here</p> <p>Below is a screenshot of all variables (both input and output):</p> <p></p> <p>Summary of the datasets is as follows:</p> <p></p>"},{"location":"24fa-energyinbuildings-com/#methodology","title":"Methodology","text":"<p>We reviewed several popular machine learning models, systematically categorized into Parametric Regression, Non-Parametric Regression, and Ensemble Learning.</p>"},{"location":"24fa-energyinbuildings-com/#parametric-regression","title":"Parametric Regression","text":"<ul> <li>Multiple Linear Regression</li> </ul>"},{"location":"24fa-energyinbuildings-com/#non-parametric-regression","title":"Non-Parametric Regression","text":"<ul> <li>Support Vector Regression</li> <li>K-Nearest Neighbor Regression</li> </ul>"},{"location":"24fa-energyinbuildings-com/#ensemble-learning","title":"Ensemble Learning","text":"<ul> <li>Extreme Gradient Boosting</li> <li>Categorical Boosting</li> <li>Light Gradient Boosting</li> <li>Gradient Boosting</li> <li>Extra Trees</li> <li>Random Forest</li> </ul>"},{"location":"24fa-energyinbuildings-com/#performance","title":"Performance","text":"<p>The following graphs represent the model's performance on training and testing datasets</p> <p> </p>"},{"location":"24fa-energyinbuildings-com/#deployment","title":"Deployment","text":"<p>Currently, the game is deployed at: https://surrogate-model-game.vercel.app/</p> <p>We used two web deployment services: Vercel and Render. For the frontend, we used Vercel, and for the backend we used Render</p>"},{"location":"24fa-energyinbuildings-com/#presentation","title":"Presentation","text":""},{"location":"24fa-energyinbuildings-com/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Joseph M. Aerathu Masters Architecture (HPB) ARCH jma1999 Anubha Mahajan Senior Computer Science COC amahajan68 Jessica Hernandez Senior Computer Science COC jhernandez312 Han-Syun Shih Masters Architecture (HBP) ARCH hshih38 Hang Xu PhD Architecture ARCH HangXXXu"},{"location":"24fa-microclimate-lstm-kriging/","title":"24Fa-Microclimate-Geo-LSTM-Kriging","text":"<p>Urban Weather Generator Deep Learning: LSTM-Kriging Model</p>"},{"location":"24fa-microclimate-lstm-kriging/#description","title":"Description","text":"<p>This project aims to understand and reproduce data published by the National University of Singapore's (NUS) approach for microclimate prediction, the Geo-LSTM-Kriging Model. This model meshes three key layers to provide accurate microclimate predictions using local weatherstation data. The model takes together LULC data, historical data, and spatial distance information to learn from previous data and apply such learnings to present data. This combination is a novel combination of the strengths of LSTM's time series predictions and Kriging's spatial data dependencies.</p> <p>This team spent work cleaning up the open-source code from NUS to understand the model's inputs better. Having improved legibility, the adapatability of the model was clear to the team and allowed them to integrate campus-specific data. The team's work this semester was focused to replicate the NUS's model for Georgia Tech campus. The team used real weather data collected on GT campus coupled with Tech's Tree Viewer App to improve the accuracy of results for the campus. </p>"},{"location":"24fa-microclimate-lstm-kriging/#requirements","title":"Requirements","text":"<ol> <li>Python</li> <li>Pandas</li> <li>Numpy</li> <li>OSMNX</li> <li>Scikit-Learn</li> <li>Pytorch</li> <li>Pykrige</li> </ol> <p>In addition this program requires that you provide a dataframe for the features you want to measure, as well as gridpoint data for the Kriging Regression. We\u2019ve provided test dataframes that you can find within the \u201cweather_station_5min\u201d and \u201cweather_station_60min\u201d folders. </p>"},{"location":"24fa-microclimate-lstm-kriging/#repository-structure","title":"Repository Structure","text":"<p>This repo contains the aspects needed to replicate the Geo-Kriging LSTM Model. Inside the \u201cpython\u201d folder, you will find the necessary notebook files to execute it. The main ones to focus on are \u201cOrganized_Model_Eval.ipynb\u201d and \u201cosmnx 2.ipynb\u201d. The latter is used to gather the necessary gridpoint data for the kriging aspect and the former is utilized for execution of the models onto the data.</p>"},{"location":"24fa-microclimate-lstm-kriging/#installation","title":"Installation","text":"<p>Each of the required libraries can be easily installed with pip. For OSMNX, a separate process is required. You can find it at this link. Once installed, run the \u201cosmnx 2.ipynb\u201d with the OX kernel.</p>"},{"location":"24fa-microclimate-lstm-kriging/#methodology","title":"Methodology","text":"<p>For the methodology, the team used three wokflows: pre-processing, machine learning (ML) training, &amp; prediction and plotting. Pre-processing involves cleaning up the data and making it usable for the ML training workflow. For the spatial method that the team incorporated into the model, the OpenStreetMap Python library osmnx, and using the library, a map of Georgia Tech's campus was used as a basis. Overlayed on top of the map is system of equally spaced out points forming a grid. For each of the equidistant points, 12 distance vectors were obtained. Theses distances are from each point on the grid to the nearest centers of various variables; these various variables are buildings, libraries, parks, parking, footways, grass, fitness centers, woods, wetlands, trees on campus, and trees in Atlanta off Tech's campus. The tree data was not easily accessible through osmnx, so the team utilized Georgia Tech's Tree Viewer App for the tree location data and distances. In the Geo-LSTM-Kriging model that our team followed, Kriging is a statistical method for spacial interpolation, predicting unknown values at locations that don\u2019t have measured values by using spatial correlations. These spatial correlations, the 12 distance vectors for each x,y point, are based off of relationships between variables. Dr. Brian Stone's weather data obtained from the several weather stations he set up a year ago on Tech's campus was used as an input for pre-processing as well, and it mainly provided information on temperatures, dew point, and relative humidity. This is the data that our group tried to find out and this data will be used as a means for comparison and training the machine learning model. The weather data from Dr. Stone's weather stations were quite messy and required cleaning. The coordinates for each of the weather stations were obtained and separated into folders. Within each of the weather station files, the averages of the data columns, namely the temperatures, dew point, and relative humidities columns, were obtained. This normalization of data to a value of zero to one ensures that during training, there will not be any errors that come up when predicting new values. Each of the normalized values were then appended into a dictionary for machine learning training. Originally, our team tried to train the weather station files in one single large data set, however it was too much for a computer to handle, so splitting it up to dictionaries ensure that it was able to run very smoothly. The outputs of the pre-processing workflow are the CSV file for the grid distances and a CSV for the normalized weather station values. </p> <p> </p> <p>Using PyTorch, the team set the main target for the prediction as the temperature and main features as relative humidity and dew point. A sequence for the LSTM was created and set as default the 10 time steps. The team did not change the parameter values too much, as the team followed the documentation's recommendations. The hidden size was changed to about 8 layers and 200 epochs, which are how many iterations one wants the program to run through the training and ensures that the program is decently trained and not too overfitted. After training each of the weather station files independently, they are all appended into one single data frame to obtain the average prediction results for each of the stations.</p> <p> </p> <p>The distance vectors obtained from each of the approximately 1300 different grid points mentioned earlier were used for the actual Geo-Kriging part of the project. The model is based off the random forest regression because random forest typically works well with a lot of different types of parameters, especially if the data turns out to be non linear.</p> <p> </p> <p>The team finally fit the model with these parameters to obtain a temperature graph displaying the heat distribution of Georgia Tech's campus. </p> <p></p>"},{"location":"24fa-microclimate-lstm-kriging/#future-work","title":"Future Work","text":"<p>The team would like to run further validation studies on the model to ensure its functionality in different climates and with consistent data. As the NUS ran their model using a month's data, given steady annual temperature data, and our weather station data is inconsistent, the model should be continute to be validated before considered for further application.</p> <p>To enhance the robustness and applicability of the LSTM-Kriging Model for urban weather generation, the following future developments are proposed: 1.  Accuracy Validation</p> <p>A critical next step is to rigorously test the accuracy of the model under various scenarios. Comparative analysis with existing models and observations will help assess the reliability and identify potential areas for refinement, including:</p> <p>\u2022   Assessing the model's predictions across various time scales, such as hourly, daily, and seasonal trends, to identify performance consistency over short- and long-term periods. </p> <p>\u2022   Performing a detailed breakdown of prediction errors to uncover biases or patterns associated with specific weather variables (temperature, humidity, wind speed) and urban contexts.</p> <ol> <li>Handling Missing Data</li> </ol> <p>Addressing missing data in weather and spatial datasets remains a key challenge. Future work will focus on integrating advanced imputation techniques or machine learning methods to fill data gaps effectively without compromising the model's performance, including:</p> <p>\u2022   Using diffusion models to reconstruct missing data patterns.</p> <ol> <li>Generalizability Testing</li> </ol> <p>The model will be tested on additional university campuses with contexts similar to Georgia Tech, particularly those featuring comparable weather station setups and spatial characteristics. This will help evaluate the model's adaptability to different urban microclimates and provide insights for broader applications. </p>"},{"location":"24fa-microclimate-lstm-kriging/#reference","title":"Reference","text":"<p>Jintong Han, Adrian Chong, Joie Lim, Savitha Ramasamy, Nyuk Hien Wong, Filip Biljecki, (2024). Microclimate spatio-temporal prediction using deep learning and land use data. Building and Environment. https://doi.org/10.1016/j.buildenv.2024.111358</p>"},{"location":"24fa-microclimate-lstm-kriging/#presentation","title":"Presentation","text":""},{"location":"24fa-microclimate-lstm-kriging/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle Sofia Mujica Junior Mechanical Engineering ME sofia-mujica Ze Yu Jiang Junior Computer Science COC zeyujiang8800 Krish Gupta Sophomore Civil Engineering CEE krishgupta-CE Thanasarn Changnawa PhD Architecture ARCH Thanasarn-Changnawa"},{"location":"24fa-microclimate-umcf/","title":"24Fa-Microclimate-UMCF","text":""},{"location":"24fa-microclimate-umcf/#a-grasshopper-plugin-for-microclimate-simulations","title":"A Grasshopper plugin for microclimate simulations","text":"<p>The plugin is based on the <code>urbanMicroclimateFoam</code> open-source solver based on OpenFOAM, developed by the Chair of Building Physics at ETH Z\u00fcrich. </p> <ul> <li>Github repository: https://github.com/OpenFOAM-BuildingPhysics/urbanMicroclimateFoam</li> <li>Gitlab repository: https://gitlab.ethz.ch/openfoam-cbp/solvers/urbanmicroclimatefoam</li> </ul>"},{"location":"24fa-microclimate-umcf/#_1","title":"24-Fa-Microclimate-UMCF","text":""},{"location":"24fa-microclimate-umcf/#overview","title":"Overview","text":"<p>UMCF (<code>urbanMicroclimateFoam</code>) is an open-source solver for coupled physical processes modeling urban microclimate based on <code>OpenFOAM</code>. </p>"},{"location":"24fa-microclimate-umcf/#key-features","title":"Key Features","text":"<p>\ud83c\udf0a CFD - Computational fluid dynamics model </p> <ul> <li>Solves turbulent, convective airflow</li> <li>Handles heat and moisture transport in the <code>air</code> subdomain</li> </ul> <p>\ud83c\udfd7\ufe0f HAM - Heat moisture transport model</p> <ul> <li>Manages absorption and transport</li> <li>Controls storage of heat and moisture in porous building materials</li> </ul> <p>\u2600\ufe0f RAD - Radiation model</p> <ul> <li>Calculates net longwave and shortwave radiative heat fluxes</li> <li>Uses view factor approach</li> </ul> <p>\ud83c\udf33 VEG - Vegetation model</p> <ul> <li>Solves heat balance for urban trees</li> <li>Handles green surfaces</li> </ul>"},{"location":"24fa-microclimate-umcf/#installation","title":"Installation","text":""},{"location":"24fa-microclimate-umcf/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>bluecfd core 2020</code></li> <li><code>UMCF</code> plugin from <code>PackageManager</code></li> <li><code>CheckInstallation</code> component</li> </ul>"},{"location":"24fa-microclimate-umcf/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Install blueCFD-Core</li> <li>Download <code>blueCFD-Core-2020-1-win64-setup.exe</code> from bluecfd.github.io</li> <li> <p>This provides <code>OpenFOAM 8</code></p> </li> <li> <p>Install UMCF Plugin</p> </li> <li>In <code>Rhinoceros</code>, execute <code>PackageManager</code> command</li> <li>Search for <code>UMCF</code> and click Install (View on RhinoPackages)</li> <li>Optional: Check <code>Include pre-releases</code> for all versions</li> <li>Restart <code>Rhinoceros</code> to complete installation</li> </ol> <p></p> <ol> <li>Verify Installation</li> <li>Navigate to <code>UMCF</code> tab in <code>Grasshopper</code> ribbon</li> <li>Find <code>Check Installation</code> under <code>Meta</code> subcategory</li> <li>Set <code>Check</code> input to <code>True</code></li> <li>This verifies integrity of <code>blueCDF-Core 2020</code> and <code>urbanMicroclimateFoam</code> files</li> </ol> <p></p>"},{"location":"24fa-microclimate-umcf/#features-workflow","title":"Features &amp; Workflow","text":""},{"location":"24fa-microclimate-umcf/#1-simulation-domain-configuration","title":"1. Simulation Domain Configuration","text":"<ul> <li>The simulation domain consists of three regions:</li> <li><code>air</code> region</li> <li><code>solid</code> region</li> <li><code>vegetation</code> region</li> </ul>"},{"location":"24fa-microclimate-umcf/#2-air-region-setup","title":"2. Air Region Setup","text":"<ul> <li>Managed by <code>UMCF.AirRegion</code> class</li> <li>Determined by <code>Box Domain Dimensions</code></li> <li>Includes <code>Atmospheric Boundary Layer</code> (<code>ABL</code>) condition:</li> <li><code>Wind Speed</code></li> <li><code>Height</code></li> <li><code>Wind Direction</code></li> </ul>"},{"location":"24fa-microclimate-umcf/#3-solid-region-setup","title":"3. Solid Region Setup","text":"<ul> <li>Managed by <code>UMCF.SolidRegion</code> class</li> <li>Requires <code>mesh</code> geometry input</li> <li>Stores:</li> <li><code>region name</code></li> <li><code>material</code></li> <li>Optional <code>thickness</code> value</li> <li><code>mesh parameters</code></li> <li><code>building temperature</code></li> </ul>"},{"location":"24fa-microclimate-umcf/#4-vegetation-region-configuration","title":"4. Vegetation Region Configuration","text":"<ul> <li>Managed by <code>UMCF.VegetationRegion</code></li> <li>Requirements:</li> <li><code>mesh</code> geometry input</li> <li><code>Leaf Area Density</code> (<code>LAD</code>)</li> <li><code>vegetation properties</code></li> <li><code>mesh parameters</code></li> </ul>"},{"location":"24fa-microclimate-umcf/#5-timing-parameters","title":"5. Timing Parameters","text":"<ul> <li>Uses <code>EnergyPlus Weather</code> file (<code>.EPW</code>)</li> <li>Requires:</li> <li><code>Start Day</code> (365-day based)</li> <li><code>start time</code></li> <li><code>duration</code></li> <li><code>end time</code> is calculated by adding the <code>start time</code> and <code>duration</code></li> </ul>"},{"location":"24fa-microclimate-umcf/#6-simulation-settings","title":"6. Simulation Settings","text":"<ul> <li>Key parameters include:  </li> <li><code>Number of CPUs</code> (<code>N</code>)  </li> <li><code>maxFluidIterations</code> (<code>F</code>)  </li> <li><code>Write Interval</code> (<code>W</code>)  </li> <li><code>Initial Solid Timestep Factor</code> (<code>I</code>)  </li> <li><code>minDeltaT</code> (<code>T</code>)  </li> <li><code>maxDeltaT</code> (<code>T</code>)  </li> <li><code>minFluidIteration</code> (<code>F</code>)  </li> <li><code>pcEqnForm</code> (<code>p</code>)  </li> <li><code>dampingThickness</code> (<code>d</code>)  </li> <li><code>alphaCoefU</code> (<code>U</code>)  </li> <li><code>alphaCoefT</code> (<code>T</code>)  </li> </ul>"},{"location":"24fa-microclimate-umcf/#7-case-generation","title":"7. Case Generation","text":"<ul> <li>Connect all configured components</li> <li>Set <code>Write Case</code> to <code>True</code></li> <li>Outputs <code>UMCF.UMCFCase</code> which must be connected to the <code>Case Run</code> component</li> </ul>"},{"location":"24fa-microclimate-umcf/#8-simulation-execution","title":"8. Simulation Execution","text":"<ul> <li>Two-step process:</li> <li>Prepare simulation<ul> <li>Set <code>Prepare Simulation</code> or <code>Prepare Simulation in Parallel</code> to <code>True</code></li> </ul> </li> <li>Run simulation<ul> <li>Set <code>Run Simulation</code> or <code>Run Simulation in Parallel</code> to <code>True</code></li> </ul> </li> </ul> <p>Note: Use consistent parallel settings for preparation and execution</p> <p></p>"},{"location":"24fa-microclimate-umcf/#9-analysis-visualization","title":"9. Analysis &amp; Visualization","text":"<ul> <li>Uses <code>probing</code> component</li> <li>Samples field values at point locations</li> <li>Writes results to file using input fields</li> <li>Enables value analysis and visualization by running the <code>probes</code> function</li> </ul>"},{"location":"24fa-microclimate-umcf/#documentation","title":"Documentation","text":"<p>\ud83d\udcda Visit docs.eddy3d.com for detailed documentation (Work in Progress)</p>"},{"location":"24fa-microclimate-umcf/#presentation","title":"Presentation","text":""},{"location":"24fa-microclimate-umcf/#team","title":"Team","text":"Name Seniority Major Department GitHub Marcelo Alvarez Masters Architecture (DC) ARCH @alvarezdmarch Gonzalo Vegas PhD Architecture ARCH @gvegasol Shruti Jadhav Masters Architecture (HBP) ARCH @ShrutiJadhav27 Rui Shen Masters Architecture (DC) ARCH @ShiRo-25 Chinmay Rothe Masters Architecture (HPB) ARCH @ChinmayR5"},{"location":"24fa-mobility-pei/","title":"Pedestrian Environment Index (PEI) Documentation","text":"<p>This project implements the Pedestrian Environment Index (PEI) methodology as developed at the University of Illinois Chicago (see the research paper: https://www.sciencedirect.com/science/article/pii/S0966692314001343). The PEI provides a composite measure of the walkability of an environment, incorporating the following subindices:</p> <ul> <li>Population Density Index (PDI)</li> <li>Commercial Density Index (CDI)</li> <li>Intersection Density Index (IDI)</li> <li>Land-use Diversity Index (LDI)</li> </ul>"},{"location":"24fa-mobility-pei/#1-motivation-and-introduction","title":"1. Motivation and Introduction","text":"<p>The Pedestrian Environment Index (PEI) is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments. This implementation of the PEI is useful for researchers aiming to:</p> <ul> <li>Assess the current walkability of neighborhoods or regions.</li> <li>Compare walkability across different areas.</li> <li>Identify areas with potential for improvement.</li> </ul>"},{"location":"24fa-mobility-pei/#2-getting-started","title":"2. Getting Started","text":""},{"location":"24fa-mobility-pei/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Python 3.x:    Ensure Python is installed and available in your system path. Check using:    <pre><code>python --version\n</code></pre></p> </li> <li> <p>Required Libraries:    Install the following Python libraries:</p> </li> <li>osmnx</li> <li>pandas</li> <li>numpy</li> <li>matplotlib.pyplot</li> <li>csv</li> <li> <p>census</p> </li> <li> <p>Census API Key:    Obtain a Census API key from Census API Key Signup.    Save the key in a text file named <code>census_api_key.txt</code> in the same directory as <code>PDI_generator.ipynb</code>.</p> </li> </ol>"},{"location":"24fa-mobility-pei/#installation","title":"Installation","text":"<p>Install the required libraries using pip: <pre><code>pip install osmnx pandas numpy matplotlib csv census\n</code></pre></p>"},{"location":"24fa-mobility-pei/#3-core-subindices","title":"3. Core Subindices","text":""},{"location":"24fa-mobility-pei/#population-density-index-pdi","title":"Population Density Index (PDI)","text":"<ul> <li>Definition: Measures residential population density within defined areas.</li> <li>Data Source: Population and area data are downloaded from the Missouri Census Data Center.</li> <li> <p>Calculation:</p> <p>\\(\\text{Population Density} = \\frac{\\text{Total Population}}{\\text{Total Area (Square Miles)}}\\)   - PDI: Percentile rank of Population Density across all years and cities.</p> </li> </ul>"},{"location":"24fa-mobility-pei/#commercial-density-index-cdi","title":"Commercial Density Index (CDI)","text":"<ul> <li>Definition: Evaluates the density of commercial establishments per block group.</li> <li>Data Source: Data is sourced using the Overpass API.</li> <li>Method:</li> <li>Tags used include shops, restaurants, cafes, banks, schools, cinemas, parks, sports centers, and stadiums.</li> <li> <p>Area is derived from census tracts in the US Census GeoJSON files.</p> <p>\\(\\text{Commercial Density} = \\frac{\\text{Count of Commercial POIs}}{\\text{Total Land Area (Square Miles)}}\\)   - CDI: Percentile rank of Commercial Density across all years and cities.</p> </li> </ul>"},{"location":"24fa-mobility-pei/#intersection-density-index-idi","title":"Intersection Density Index (IDI)","text":"<ul> <li>Definition: Quantifies the density of intersections in a given area.</li> <li>Data Source: Retrieved using the Overpass API.</li> <li>Method: \\(\\text{Intersection Density} = \\frac{\\text{Number of Nodes Part of More than One Way (Intersections)}}{\\text{Area (Square Miles)}}\\) </li> <li>IDI: Percentile rank of Intersection Densities across all years and cities.</li> </ul>"},{"location":"24fa-mobility-pei/#land-use-diversity-index-ldi","title":"Land-use Diversity Index (LDI)","text":"<ul> <li>Definition: Analyzes the diversity of land-use types within an area.</li> <li>Data Source: Land-use data is retrieved from OpenStreetMap using the Overpass API with the \"landuse\" tag.</li> <li>Method: \\(\\text{Entropy} = \\sum \\left( \\frac{\\text{Area of Land Use Type}}{\\text{Total Area}} \\cdot \\ln \\left( \\frac{\\text{Area of Land Use Type}}{\\text{Total Area}} \\right) \\right)\\) (for all land-use types with non-zero area).     <ul> <li>Normalized by: \\(\\frac{\\text{Entropy}}{\\ln(\\text{Number of Land Use Types with Non-Zero Area})}\\) </li> <li>LDI: Percentile rank of Entropies across all years and cities.</li> </ul> </li> </ul>"},{"location":"24fa-mobility-pei/#4-pei-formula","title":"4. PEI Formula","text":"<p>The PEI is calculated using the following formula:</p> \\[ PEI = \\frac{{(1 + PDI) \\cdot (1 + IDI) \\cdot (1 + LDI) \\cdot (1 + CDI)}}{16} \\]"},{"location":"24fa-mobility-pei/#5-implementation-workflow","title":"5. Implementation Workflow","text":""},{"location":"24fa-mobility-pei/#step-1-files","title":"Step 1: Files","text":"<ul> <li>Download population data files from the Missouri Census Data Center (MCDC) for each required year.</li> <li>Download block group and census tract files from the US Census Bureau website.</li> </ul>"},{"location":"24fa-mobility-pei/#step-2-subindex-calculation","title":"Step 2: Subindex Calculation","text":"<ul> <li>Run individual generator scripts (e.g., <code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.ipynb</code>) for each subindex.</li> <li>Outputs include CSV and GeoJSON files with fields for block group, year, and the \"raw subindex\" values:</li> <li>Population Density</li> <li>Commercial Density</li> <li>Intersection Density</li> <li>Entropy</li> <li>Append all results to master files (<code>all_PDI</code>, <code>all_CDI</code>, <code>all_IDI</code>, <code>all_LDI</code>) for comprehensive cross-year/city comparison.</li> </ul>"},{"location":"24fa-mobility-pei/#step-3-normalization","title":"Step 3: Normalization","text":"<ul> <li>Normalize raw subindex data - between 1 and 0:</li> <li>This normalization is done by taking each block group/tract's percentile rank for each \"raw subindex\" versus every other city and every other year:</li> <li>Because we normalize across all cities and years, our subindex values can be compared seamlessly against any other block group regardless of time/location.</li> <li>We are able to normalize across all cities and years thanks to these aforementioned 4 files - <code>all_PDI.csv</code>, <code>all_CDI.csv</code>, <code>all_IDI.csv</code>, <code>all_LDI.csv</code> - which contain raw data for all years/cities.</li> <li>Once we normalize the raw subindex we can now call it an actual subindex - e.g. the normalized <code>Commercial Density</code> becomes <code>CDI</code>, normalized <code>Entropy</code> becomes <code>LDI</code>, etc.</li> <li> <p>The file also updates the CSV &amp; GeoJSON files for each subindex and city with a new field - one of <code>CDI</code>, <code>LDI</code>, <code>PDI</code>, <code>IDI</code>.</p> </li> <li> <p>Now we finally have finalized CSV and GeoJSON files for the 4 subindexes:</p> <ul> <li><code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.csv/geojson</code></li> </ul> </li> </ul>"},{"location":"24fa-mobility-pei/#step-4-pei-calculation","title":"Step 4: PEI Calculation","text":"<ul> <li>Combine normalized subindices using the PEI formula for each block group/tract.</li> <li>Generate CSV and GeoJSON files (<code>PEI_&lt;city&gt;_&lt;year&gt;.csv/geojson</code>).</li> </ul>"},{"location":"24fa-mobility-pei/#step-5-web-app-integration","title":"Step 5: Web App Integration","text":"<ul> <li>Upload finalized GeoJSON files to AWS S3 buckets.</li> <li>Implement and visualize data on the web app.</li> </ul>"},{"location":"24fa-mobility-pei/#6-usage","title":"6. Usage","text":""},{"location":"24fa-mobility-pei/#inside-the-fall24-folder-you-will-find-3-folders","title":"Inside the Fall24 folder you will find 3 folders:","text":"<ul> <li>Tract_Files - we mainly used this folder for testing:</li> <li>This contains the relevant <code>ipynb</code> files for creating the subindexes.</li> <li> <p>It also contains <code>tracts.geojson</code> which has the first 10 rows of tracts in the US - useful for testing.         - Please download full tract files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</p> </li> <li> <p>BlockGroup_Files:</p> </li> <li>This contains the relevant <code>ipynb</code> files for creating the subindexes. (In the PDI file, only run code blocks after the <code>#NEW</code> comment).</li> <li>It also contains <code>block_groups.geojson</code> which has the first 10 rows of blockgroups in Atlanta - useful for testing.         - Please create the full files using the <code>./Spring24/Blockgroup GeoJSON Generator</code> folder (you need to rename the output of this to <code>block_groups.geojson</code>), downlaod the full files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</li> </ul>"},{"location":"24fa-mobility-pei/#step-1-data-download","title":"Step 1: Data Download","text":"<p>Download the required data files from the following sources: - Population Data: Obtain CSV files from Missouri Census Data Center (MCDC). - Census Block Groups/Tract GeoJSON: Retrieve the required GeoJSON files from the US Census Bureau or relevant sources:      - As described above, download files from https://www.census.gov/cgi-bin/geo/shapefiles/index.php, or contact abeesen3@gatech.edu for full files.</p>"},{"location":"24fa-mobility-pei/#step-2-update-generator-scripts","title":"Step 2: Update Generator Scripts","text":"<p>Modify the generator scripts (<code>PDI_Generator.ipynb</code>, <code>CDI_Generator.ipynb</code>, <code>LDI_Generator.ipynb</code>, <code>IDI_Generator.ipynb</code>) to include your specific file paths and input parameters. For all the subindex files, they will have a portion like the code shown below. This is the only part you must update as required:</p> <pre><code>calculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2013,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n\ncalculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2017,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n\ncalculate_&lt;subindex&gt;(\n    input_geojson=\"path_to_your_geojson_file.geojson\",  # Replace with your census tract or blockgroup GeoJSON file\n    output_prefix=\"&lt;tracts&gt; or &lt;block_groups&gt;\", # tracts or bg based on if we are analyzing tracts or blockgroups\n    year=2022,\n    aggregate_file=\"&lt;subindex&gt;_&lt;tract/bg&gt;_all.csv\"  # update the &lt;subindex&gt; and choose tracts or bg\n)\n</code></pre>"},{"location":"24fa-mobility-pei/#step-3-run-scripts-in-the-following-order","title":"Step 3: Run Scripts in the Following Order","text":"<ol> <li>Run the Subindex Generators:    Execute the following scripts to calculate raw subindices:</li> <li><code>CDI_Generator.ipynb</code></li> <li><code>LDI_Generator.ipynb</code></li> <li> <p><code>IDI_Generator.ipynb</code>    These can be run in any order.</p> </li> <li> <p>Run PDI</p> </li> <li>For small input files (not many tracts or geojsons), run our current <code>PDI_Generator.ipynb</code>.</li> <li> <p>For larger files, a custom approach using CSV files from Missouri Census Data Center (MCDC) is requied:         - For this, please contact cnguyen369@gatech.edu</p> </li> <li> <p>Normalize Subindices:    Run <code>Normalizer.ipynb</code> to normalize the raw subindices across all years and cities.</p> </li> <li> <p>Generate PEI:    Finally, run <code>PEI_Generator.ipynb</code> to calculate the Pedestrian Environment Index.</p> </li> </ol>"},{"location":"24fa-mobility-pei/#step-4-output","title":"Step 4: Output","text":"<ul> <li>This process will output normalized subindex files and the final PEI results as CSV and GeoJSON files.</li> <li>The file format will be:<ul> <li><code>&lt;subindex&gt;_&lt;city&gt;_&lt;year&gt;.csv/geojson</code></li> </ul> </li> <li>Utilize the <code>Subindex_Visualizer.ipynb</code> file to visualize your geojson file output!</li> </ul>"},{"location":"24fa-mobility-pei/#7-challenges","title":"7. Challenges","text":""},{"location":"24fa-mobility-pei/#the-biggest-challege-in-our-statistic-generators-was-developing-the-pdi-generator","title":"The biggest challege in our statistic generators was developing the PDI Generator.","text":"<ul> <li> <p>While most of our subindexes - <code>CDI</code>, <code>LDI</code>, <code>IDI</code> - use the <code>Overpass API (OSM data)</code> to gather data, this is not possible for the <code>PDI</code> as population data is not provided by OSM.</p> </li> <li> <p>Because of this, we were forced to utilize the <code>Census API</code>, which had 2 main issues:</p> <ul> <li>It often returned simply the latest data i.e. 2024 data - even when we requested historical population data.</li> <li>On large geoJSONs, where we have to make hundreds and thousands of API calls, the Census API frequently errored due to API call limits.<ul> <li>This became a considerable problem when running our files using <code>PACE</code> to generate Census Tract data for Dr Ku. Our code would run for 10 or so hours and then fail - as we would run out of API tokens.</li> </ul> </li> </ul> </li> <li> <p>We got over this challenge by downloading population data by tract/block group directly - from Missouri Census Data Center (MCDC)</p> </li> <li>We could then easily calculate <code>Population Density</code> and hence <code>PDI</code> by block_group/tract by merging this data with our block_groups/tracts geoJSON files - which contain an area column.</li> </ul>"},{"location":"24fa-mobility-pei/#8-future-work-potential-statistic-creation-enhancements","title":"8. Future Work - Potential Statistic Creation Enhancements","text":"<p>While this semester we started working on the idea of normalization across all urban areas and years \u2013 which ensures our statistics can be properly used for comparisons - we still have a few more potential enhancements:</p> <ol> <li> <p>Logarithmic normalization:    While we currently create percentile ranks to evaluate indexes, utilizing a logarithmic normalization would mean scores are less spread out and more realistic.</p> </li> <li> <p>Improved normalization reliability:    As we add new cities to our database - which we hope to do by continuing to run our generators over the course of next semester - our scores will automatically become more reliable as we normalize with larger datasets.</p> </li> <li> <p>Expanding CDI tags:    We aim to add more tags to the Commercial Density Index (CDI), as it is currently too narrow.</p> </li> </ol>"},{"location":"24fa-mobility-pei/#9-contributing","title":"9. Contributing","text":"<p>We welcome contributions to this project.  </p>"},{"location":"24fa-mobility-pei/#steps-to-contribute","title":"Steps to Contribute:","text":"<ol> <li>Fork the repository.</li> <li>Create a feature branch:    <pre><code>git checkout -b feature/new-feature\n</code></pre></li> <li>Push your changes and submit a pull request.</li> </ol>"},{"location":"24fa-mobility-pei/#10-license","title":"10. License","text":"<p>This project is shared for research and educational purposes. Please do not redistribute for commercial use.</p>"},{"location":"24fa-mobility-pei/#web-app-documentation","title":"Web App Documentation","text":"<p>The web app is currently deployed at this link: https://vip-pei-app-2.onrender.com/ \ud83d\ude0a</p> <p>This deployment is dynamic and so any updates to our codebase (https://github.com/AtharvaBeesen/vip-pei-app-2) will automatically be displayed.</p>"},{"location":"24fa-mobility-pei/#1-introduction","title":"1. Introduction","text":"<ul> <li>App Name: VIP SMUR PEI Proof of Concept</li> <li>Purpose: Visualize the work we have done in creating the aforementioned subindexes. We also wanted to allow the data we generate to be available online in a visually appealing, paletable, and easy-to-download way.</li> </ul>"},{"location":"24fa-mobility-pei/#key-features","title":"Key Features:","text":"<ul> <li>Interactive map with GeoJSON visualization for the subindexes - PDI, IDI, CDI, LDI, PEI - across different cities and years.</li> <li>Dynamic city, statistic, and year selection.</li> <li>Ability to download CSV and GeoJSON files for selected data.</li> </ul>"},{"location":"24fa-mobility-pei/#technology-stack","title":"Technology Stack:","text":"<ul> <li>Frontend: React, JavaScript, HTML, CSS</li> <li>Backend: All functionality contained within JavaScript</li> <li>Mapping Library: Leaflet</li> <li>Data Source: Amazon S3 Buckets</li> </ul>"},{"location":"24fa-mobility-pei/#2-getting-started_1","title":"2. Getting Started","text":""},{"location":"24fa-mobility-pei/#prerequisites_1","title":"Prerequisites","text":"<ol> <li> <p>Node.js and npm/yarn:    Ensure Node.js and npm (or yarn) are installed on your system. You can check this by running:    <pre><code>node -v\nnpm -v\n</code></pre>    If not installed, download them from Node.js official site.</p> </li> <li> <p>Code Editor (Optional):    Install a code editor like Visual Studio Code.</p> </li> <li> <p>Browser:    A modern browser like Chrome, Firefox, or Edge to test your app.</p> </li> <li> <p>Git:    Install Git for cloning the repository. Check installation by running:    <pre><code>git --version\n</code></pre></p> </li> <li> <p>Leaflet Library Dependencies:    The app uses Leaflet for maps, which requires:</p> </li> <li>A valid internet connection to download Leaflet assets via npm or yarn.</li> <li>Ensure the browser supports Leaflet.</li> </ol>"},{"location":"24fa-mobility-pei/#installation_1","title":"Installation","text":"<ol> <li>Clone the repository:    <pre><code>git clone https://github.com/AtharvaBeesen/vip-pei-app-2.git\n</code></pre></li> <li>Install dependencies:    <pre><code>npm install\n</code></pre></li> <li>Ensure Leaflet is installed:    <pre><code>npm install leaflet\n</code></pre></li> <li>Run the application:    <pre><code>npm start\n</code></pre></li> <li>Access the app at <code>http://localhost:3000</code>.</li> </ol>"},{"location":"24fa-mobility-pei/#deployment","title":"Deployment","text":"<ul> <li>Already deployed! We deployed using <code>Render</code>: https://vip-pei-app-2.onrender.com/ </li> </ul>"},{"location":"24fa-mobility-pei/#3-features","title":"3. Features","text":""},{"location":"24fa-mobility-pei/#31-interactive-map","title":"3.1 Interactive Map","text":"<ul> <li>Displays GeoJSON data visualized on a Leaflet map.</li> <li>Map dynamically updates based on city, statistic, and year selections.</li> </ul>"},{"location":"24fa-mobility-pei/#32-city-statistic-and-year-selection","title":"3.2 City, Statistic, and Year Selection","text":"<ul> <li>Dropdown menus for users to select:</li> <li>Cities: Atlanta, New York, Los Angeles.</li> <li>Statistics: IDI, PDI, CDI, LDI, PEI.</li> <li>Years: 2022, 2013.</li> </ul>"},{"location":"24fa-mobility-pei/#33-file-downloads","title":"3.3 File Downloads","text":"<ul> <li>CSV and GeoJSON files for the selected data can be downloaded with a single click.</li> </ul>"},{"location":"24fa-mobility-pei/#4-components","title":"4. Components","text":""},{"location":"24fa-mobility-pei/#41-appjs","title":"4.1 App.js","text":"<ul> <li>The main entry point for the application.</li> <li>Manages state for selected city, statistic, and year.</li> <li>Renders <code>CitySelector</code>, <code>DownloadButton</code>, and <code>MapComponent</code>.</li> </ul>"},{"location":"24fa-mobility-pei/#42-cityselectorjs","title":"4.2 CitySelector.js","text":"<ul> <li>Dropdown menus for selecting city, statistic, and year.</li> <li>Capitalizes city names and statistics for user-friendly display.</li> </ul>"},{"location":"24fa-mobility-pei/#43-mapcomponentjs","title":"4.3 MapComponent.js","text":"<ul> <li>Displays the Leaflet map and GeoJSON data.</li> <li>Dynamically fetches data from S3 Buckets based on user selections (more on this below).</li> <li>Highlights GeoJSON features with a color-coded scheme based on statistic values.</li> </ul>"},{"location":"24fa-mobility-pei/#44-downloadbuttonjs","title":"4.4 DownloadButton.js","text":"<ul> <li>Provides buttons to download CSV and GeoJSON files from S3.</li> <li>Dynamically constructs download URLs based on user selections.</li> </ul>"},{"location":"24fa-mobility-pei/#5-api-integration","title":"5. API Integration","text":"<p>The app dynamically fetches GeoJSON data from an Amazon S3 bucket: - URL format: <code>https://vip-censusdata.s3.us-east-2.amazonaws.com/{city}_blockgroup_{statistic}_{year}.geojson</code></p>"},{"location":"24fa-mobility-pei/#example","title":"Example:","text":"<p>For Atlanta, IDI, and 2022: <code>https://vip-censusdata.s3.us-east-2.amazonaws.com/atlanta_blockgroup_IDI_2022.geojson</code></p>"},{"location":"24fa-mobility-pei/#6-future-work","title":"6. Future Work","text":""},{"location":"24fa-mobility-pei/#there-are-3-key-goals-we-hope-to-achieve","title":"There are 3 key goals we hope to achieve:","text":"<ol> <li> <p>Increase the number of cities and years supported:    This would simply require us to continue running our subindex generators over the course of the next semester(s) in order to continue to grow the size of our database.</p> </li> <li> <p>Seek Collaboration/Monetization Opportunities:    As we grow the site and our footprint in the space, we could seek to replicate WalkScore's monetization and collaboration business model:</p> </li> <li> <p>Collaborate with products/sites:       Work with products or sites that require walkability statistics (e.g., Zillow and City Planning Companies) to create customized statistics at a cost.</p> </li> <li> <p>Direct collaboration with local government:       Assist local governments in achieving their goals of improving walkability in urban areas.</p> </li> <li> <p>Developing a for-cost API:       Create an API that allows third-party researchers to use our data.  </p> <ul> <li>For Example: Collaborating with researchers like Dr. Ku, who uses our data to enhance his psychology research.</li> </ul> </li> <li> <p>Improve the UI:    This goal is less essential and is more about improving user-experience in the case that we decide to push towards becoming a standalone software for third-parties to gather walkability data on different urban areas.</p> </li> </ol>"},{"location":"24fa-mobility-pei/#7-contributing","title":"7. Contributing","text":"<ul> <li>Please contact abeesen3@gatech.edu before doing so.</li> <li>Example of how to contribute:</li> <li>Fork the repository (https://github.com/AtharvaBeesen/vip-pei-app-2)</li> <li>Create a feature branch:      <pre><code>git checkout -b feature/new-feature\n</code></pre></li> <li>Push your changes and submit a pull request.</li> </ul>"},{"location":"24fa-mobility-pei/#8-license","title":"8. License","text":"<p>This project is shared for research and educational purposes. Please do not redistribute for commercial use.</p>"},{"location":"24fa-mobility-pei/#presentation","title":"Presentation","text":""},{"location":"24fa-mobility-pei/#team","title":"Team","text":"Name Seniority Major Department GitHub Handle C. \"Albert\" Le Sophomore Computer Engineering ECE balbertle Chunlan Wang Masters Architecture (DC) ARCH wang-123-xi Yichao Shi PhD Architecture ARCH SHIyichao98 Atharva Beesen Junior Computer Science COC AtharvaBeesen"},{"location":"24sp-energyinbuildings/","title":"Multivariate Regression of Energy Consumption","text":""},{"location":"24sp-energyinbuildings/#introduction","title":"Introduction","text":"<p>This notebook is part of the repository 'Optimization of Building Energy Consumption' aimed at using machine learning models to optimize building design parameters to minimize energy consumption for heating and cooling. This notebook focuses on multivariate regression to predict both heating and cooling energy loads based on building design parameters.</p>"},{"location":"24sp-energyinbuildings/#repository-overview","title":"Repository Overview","text":"<ul> <li>Repository: Optimization of Building Energy Consumption</li> <li>File: Notebook1B_Multivariate_regression_heating_cooling_load_final.ipynb</li> </ul>"},{"location":"24sp-energyinbuildings/#notebook-summary","title":"Notebook Summary","text":"<p>This notebook includes comprehensive steps for preprocessing, analyzing, and modeling building energy data with the goal of predicting heating and cooling loads. The process includes:</p> <ol> <li>Data loading and initial exploration.</li> <li>Descriptive statistics to understand the dataset.</li> <li>Data visualization to infer relationships and data distribution.</li> <li>Data cleaning and transformation to prepare for modeling.</li> <li>Model building using various machine learning techniques including Linear Regression, KNN, Support Vector Machine, and a neural network model using Keras.</li> <li>Evaluation of models using cross-validation and comparison based on mean squared error.</li> <li>Final model selection and saving the model for future use.</li> </ol>"},{"location":"24sp-energyinbuildings/#usage","title":"Usage","text":"<p>The notebook is structured to be followed sequentially. Detailed comments and markdown notes provide guidance through each step of the analysis and modeling process.</p>"},{"location":"24sp-energyinbuildings/#models-and-algorithms-used","title":"Models and Algorithms Used","text":"<ul> <li>Linear Regression</li> <li>Random Forest</li> <li>KNN (K-Nearest Neighbors)</li> <li>Support Vector Machine (SVM)</li> <li>Neural Networks (Keras Sequential Model)</li> </ul> <p>The notebook also discusses the use of early stopping in neural network training to prevent overfitting and improve model generalization.</p>"},{"location":"24sp-energyinbuildings/#data-description","title":"Data Description","text":"<p>The dataset used (<code>EPB_data.csv</code>) includes various building parameters such as orientation, area, and glazing area among others, and the target variables are 'Heating Load' and 'Cooling Load'.</p>"},{"location":"24sp-energyinbuildings/#key-findings-and-observations","title":"Key Findings and Observations","text":"<ul> <li>Multivariate regression can effectively predict energy consumption when appropriate preprocessing and feature engineering are applied.</li> <li>The Random Forest algorithm showed superior performance in predicting the energy loads compared to other models.</li> <li>Neural Networks provided competitive results, highlighting their potential in complex regression tasks.</li> </ul>"},{"location":"24sp-energyinbuildings/#conclusions","title":"Conclusions","text":"<p>This notebook serves as a detailed example of using statistical and machine learning methods to predict building energy consumption. The methodologies outlined here can be adapted and expanded for other types of predictive modeling tasks within the building energy domain.</p>"},{"location":"24sp-energyinbuildings/#references","title":"References","text":"<ul> <li>Tsanas, A. and Xifara, A. (2012). Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. Energy and Buildings, 49, 560-567. DOI: 10.1016/j.enbuild.2012.03.003</li> </ul>"},{"location":"24sp-energyinbuildings/#demand-ninja-energy-demand-forecasting-model","title":"Demand Ninja - Energy Demand Forecasting Model","text":""},{"location":"24sp-energyinbuildings/#overview","title":"Overview","text":"<p>Demand Ninja is a sophisticated tool that provides hourly energy demand forecasts based on environmental data and building characteristics. It employs advanced algorithms and machine learning techniques to predict heating and cooling needs with high accuracy.</p>"},{"location":"24sp-energyinbuildings/#repository-structure","title":"Repository Structure","text":"<p>The repository consists of several Python scripts each designed to perform specific roles in the data processing and forecasting pipeline:</p>"},{"location":"24sp-energyinbuildings/#core-scripts","title":"Core Scripts","text":"<ul> <li><code>core.py</code>: Contains the primary logic for calculating energy demands based on the Building-Adjusted Internal Temperature (BAIT) model.</li> <li><code>demand_ninja_example.py</code>: Demonstrates how to use the Demand Ninja model to compute energy demand using custom input data.</li> <li><code>geo_json_file.py</code>: Converts processed energy demand data into GeoJSON format for easy integration with geospatial applications.</li> <li><code>test_download.py</code>: Automates the downloading of EPW files for various locations using API calls.</li> <li><code>epw_to_dataframe.py</code>: Consolidates key weather parameters from multiple EPW files into a single CSV file for easier analysis.</li> <li><code>clean_weather_with_demand.py</code>: Cleans and preprocesses weather data combined with demand forecasts to prepare for analysis.</li> <li><code>aggregate_data.py</code>: Processes and aggregates weather and energy demand data by geographic coordinates.</li> </ul>"},{"location":"24sp-energyinbuildings/#features","title":"Features","text":"<ul> <li>Energy Demand Forecasting: Utilize historical weather data and building parameters to forecast energy needs.</li> <li>Data Enrichment: Enhance your datasets with calculated energy demand metrics to aid in further analyses or model training.</li> <li>GeoJSON Conversion: Export your enriched datasets to GeoJSON for use in mapping and other geospatial applications.</li> <li>Automated Data Retrieval: Automatically download weather data required for demand calculations.</li> </ul>"},{"location":"24sp-energyinbuildings/#getting-started","title":"Getting Started","text":"<p>To start using the Demand Ninja scripts, follow these steps:</p> <ol> <li>Clone the repository to your local machine.</li> <li>Ensure that all dependencies are installed via <code>pip install -r requirements.txt</code> (ensure you have this file configured based on the scripts needs).</li> <li>Run the scripts individually as needed:</li> </ol> <pre><code>python demand_ninja_example.py\npython clean_weather_with_demand.py\npython geo_json_file.py\n</code></pre>"},{"location":"24sp-energyinbuildings/#data-requirements","title":"Data Requirements","text":"<p>Each script is designed to be modular but certain data standards must be maintained for seamless functionality:</p> <ul> <li>Weather data should include key metrics like temperature, humidity, wind speed, and radiation levels.</li> </ul>"},{"location":"24sp-energyinbuildings/#credits","title":"Credits","text":"<p>Demand Ninja was developed by the Renewables Ninja team, including notable contributions from Iain Staffell, Stefan Pfenninger, and Nathan Johnson.</p>"},{"location":"24sp-energyinbuildings/#rank-5-of-ashrae-great-energy-predictor-iii-gepiii","title":"Rank 5 of ASHRAE Great Energy Predictor III (GEPIII)","text":""},{"location":"24sp-energyinbuildings/#overview_1","title":"Overview","text":"<p>We refer to \"rank 5\" as the 5<sup>th</sup> winning solution of the ASHRAE Great Energy Predictor III (GEPIII) contest which is hosted on Kaggle. We originally were working on 'rank 1', or the highets ranked solution but decided to first go through 'rank 5' as it had a much quicker time to complete with not as much difference compared to 'rank 1'. Accorrding to ASHRAE, \"This competition's overall objective was to find the most accurate modeling solutions for the prediction of over 41 million private and public test data points.\" There are many models within the solutions, with many libraries and a need to run on a very, very fast computers. We used GaTech's PACE system to run these jobs. </p>"},{"location":"24sp-energyinbuildings/#rank-5-github-tutorial","title":"Rank 5 GitHub Tutorial","text":"<ul> <li>Rank 5 Kaggle Documentation</li> <li>Rank 5 Github Walkthrough</li> </ul>"},{"location":"24sp-energyinbuildings/#directory-structure","title":"Directory Structure","text":"<ul> <li><code>model</code>: - trained model binary files</li> <li><code>output</code>: - model predictions and the final submission file</li> <li><code>train_code</code>: - code to train models from scratch</li> <li><code>predict_code</code>: - code to generate predictions from model binaries</li> <li><code>ensemble_code</code>: - code to ensemble the predictions</li> <li><code>preproceeding_code</code>: - code to pre-process the data</li> <li><code>prepare_data</code>: - pre-processed data files</li> <li><code>external_data</code>: - external files required by this solution such as leak data</li> <li><code>requirements.txt</code>: - python package dependencies</li> <li><code>SETTINGS.json</code>: - a json configuration file</li> </ul>"},{"location":"24sp-energyinbuildings/#issues-with-rank-5","title":"Issues with Rank 5","text":"<p>There were many issues running Rank 5, here are some of them and possible solutions:</p> <ol> <li>When running on PACE, using sudo is not allowed without special permissions. Hence getting git installed would be hard to do. Instead for ease, just download the files and use PACE ICE onDemand and upload the files onto the instance machine directly, without using git.</li> <li>The requirements file has a LOT of libraries, many which are outdated and will give compilation errors. You will have to see which ones would work, and whenever an error occurs pip install seperatley and keep running the file. This is tedious. An issue that isnt resolved yet is the complilation problems with the Cython libraries with pandas and others.</li> <li>The GitHub will ask to make a virtual environment using myenv. In PACE you should use Ananconda, which comes along with it.</li> <li>Kaggle API is a bit different with the outdated version of this Kaggle competition. Ther emay be multiple times where you have to uninstall kaggle and reinstall it. Scroll down here. Issues occurs where the files for Kaggle are not aligned with the process of getting training data. So you would have to download the training data and upload it onto PACE.</li> <li>There was an issue uploading the training files onto PACE, as it keeps giving an error that it cant upload half of the files. Will have to figure this one out later.</li> </ol>"},{"location":"24sp-microclimate/","title":"Urban Microclimate using the Urban Weather Generator","text":"<p>The Urban Weather Generator models the urban heat island using EnergyPlus (.epw) weather files. The Python model utilizes various parameters to reflect urban canyon conditions.</p>"},{"location":"24sp-microclimate/#introduction","title":"Introduction","text":"<p>This notebook is a documentation for the urban microclimate sub-team progress and outcomes.</p>"},{"location":"24sp-microclimate/#notebook-summary","title":"Notebook Summary","text":"<p>This notebook includes steps, process, and issues related to using the Urban Weather Generator (UWG) to have quick urban microclimate results. Below are the summarized steps of the process:</p> <ol> <li>Test run the UWG script using a selected .epw file retrieved from https://climate.onebuilding.org/.</li> <li>Perform sensitivity analysis test to select the most affective UWG inputs.</li> <li>Collect the exact values for the selected inputs in the selected .epw file location (Using Grasshopper script).</li> <li>Run the UWG with the correct inputs.</li> <li>Compare the UWG .epw results with the initial .epw file.</li> </ol>"},{"location":"24sp-microclimate/#usage","title":"Usage","text":"<p>The notebook is structured in chronological order, where each heading is a step and below the step are its issues and process.</p>"},{"location":"24sp-microclimate/#key-findings-and-observations","title":"Key Findings and Observations","text":"<ul> <li>The most affective inputs to be used in Atlanta, GA are: min wind speed, avg bldg height, veg start/end month, vert horiz ratio, rural avg obstacle height, albedo of veg, and sens anthro heat.</li> </ul>"},{"location":"24sp-microclimate/#steps","title":"Steps","text":""},{"location":"24sp-microclimate/#1-test-run-the-uwg","title":"1. Test Run the UWG","text":"<ul> <li>Clone the repository of the MIT UWG GitHub, and follow the instructions listed there. Test with the provided Singapore EPW file or download another one of your choice.</li> </ul>"},{"location":"24sp-microclimate/#getting-started","title":"Getting Started","text":"<ol> <li>Clone repository to local machine:</li> </ol> <p><pre><code>git clone https://github.com/ladybug-tools/uwg\n</code></pre> 2. Install dependencies:</p> <p><pre><code>cd uwg\npip install -r dev-requirements.txt\npip install -r requirements.txt\n</code></pre> 3. Run the scripts individually as needed.</p>"},{"location":"24sp-microclimate/#issues","title":"Issues","text":"<ul> <li>There are over 60 parameters available for testing, however, the documentation does not provide an accurate measure of the range for input, and so it must be tested out manually. </li> <li>The outputted EPW file requires a bit of cleaning, as the values of the vectors are shifted one to the left.</li> </ul>"},{"location":"24sp-microclimate/#2-sensitivity-analysis","title":"2. Sensitivity Analysis","text":""},{"location":"24sp-microclimate/#process","title":"Process","text":"<p>For the Sobol sensitivity analysis, we define an objective function that takes in our parameters to measure the correlation coefficient and covariance. In this case, we went with measuring the RMSE value to simulated dry bulb temperature to the canyon temperature of the Georgia Tech Campus. Due to the design of the function, the more that the values differ from the actual, the more it would penalize the performance, leading to more accurate outputs. Within our final plotting, we see that our data tends to be normally distributed, which further supports the accuracy of the sensitivity analysis.</p>"},{"location":"24sp-microclimate/#issues_1","title":"Issues","text":"<ul> <li>A chance for bias within dataset: Sobol sensitivity analysis generates a fixed amount of samples for a determined number of inputs. However, due to the combination restriction of the parameters (building density, tree cover, and grass cover), the sum of these three parameters must add up to less than or equal to 1.0. Because of this, we've decided to randomize each of the data views such that the sum of the three values meet this criteria. This may lead to bias as each of the samples have a set determined number of homogenous outputs.</li> <li>Due to the large test size of our samples (100,000), we resorted to using the campus HPC cluster to quickly receive the simulation output of the sensitivity analysis.</li> </ul>"},{"location":"24sp-microclimate/#3-data-collection","title":"3. Data Collection","text":""},{"location":"24sp-microclimate/#process_1","title":"Process","text":"<ul> <li>A Grasshopper script was developed to collect the data based on the OSM coordinates of the 125m tile.</li> <li>The coordinates of the tile are inputted manually in GH to modify the bounding box and get the data of the specific lot.</li> <li>Ladybug in GH is used to get the wind speed.</li> <li>The spatial references of the trees cover, grass cover, buildings, and vert horiz ratio has been utilized to find the percentage of the parameters.</li> <li>Map Tiler: This tool allows us to input a specific geographic location and allows us to adjust the zoom level fitting to our region of interest within a bounding box. Then, it allows us to evenly partition the region into subsets of maps, all of which contain coordinates that can later be utilized within the Rhino 3D tool to fetch the data specific to that subset of our region of interest, which we would apply to the UWG to output simulations of more specific parts of the campus.</li> </ul>"},{"location":"24sp-microclimate/#issuesnotes","title":"Issues/Notes","text":"<ul> <li>Map tiler uses Mercator tiling approach. Web Mercator projection using unique sets of coordinates to input the coordinates of each tile in the location in GH.</li> <li>Building heights are retrieved from FEMA.</li> <li>LiDAR is used to find the building height to area ratio.</li> <li>To avoid any issues, toggle the true or false instantly after getting each result or when making any changes.</li> <li>Due to .gh files, we are unable to simulate the campus into sufficiently small math tiles. Thus, we resorted to using the average values of the inputs parameters on the entire Georgia Tech campus. Many of these inputs, although impactful, were not easy to fetch data for. Examples include HVAC coefficient, urban boundary layer, and vegetation albedo coefficient.</li> <li>Upon retrieving the data from Rhino, input it into the parameters of the UWG parameter function, and adjust it accordingly for each part of the subset map tiles. For each of the outputted EPW file, utilize Grasshopper tool, or geopandas with a geojson file of campus, to display the diurnal, monthly, and yearly averages across each subset, forming a complete heat map.</li> </ul>"},{"location":"24sp-microclimate/#4-run-accurate-uwg","title":"4. Run Accurate UWG","text":""},{"location":"24sp-microclimate/#process_2","title":"Process","text":"<p>To run the UWG tool:</p> <ol> <li>Clone this directory and install the required dependencies. </li> <li>Make sure to have your desired location's EPW file in the directory. </li> <li>Each of the parameters have a specific range for their values of input, which can be viewed within the Parameters.py file. </li> <li>Upon running, the UWG will start simulating the desired parameter/conditions onto the location of the EPW file, and will output a new simulated EPW.</li> </ol>"},{"location":"24sp-microclimate/#5-useful-tool","title":"5. Useful Tool","text":""},{"location":"24sp-microclimate/#gt-pace-ice-cluster","title":"GT PACE ICE Cluster","text":"<p>PACE's Instructional Cluster Environment (ICE) offers an educational environment with opportunities to gain scientific computing experience.</p> <p>To access:</p> <ol> <li>Navigate to terminal and enter: <code>ssh gburdell3@login-ice.pace.gatech.edu</code></li> <li>Enter GT password at prompt </li> </ol>"},{"location":"24sp-microclimate/#references","title":"References","text":"<ol> <li> <p>Mao, J., Norford, L.K. (2021). Urban Weather Generator: Physics-Based Microclimate Simulation for Performance-Oriented Urban Planning. In: Palme, M., Salvati, A. (eds) Urban Microclimate Modelling for Comfort and Energy Studies. Springer, Cham. https://doi.org/10.1007/978-3-030-65421-4_12</p> </li> <li> <p>Harnessing cooling from urban trees: Interconnecting background climates, urban morphology, and tree traits, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2024-234, 2024.</p> </li> <li> <p>Bhatt MM, Gupta K, Danodia A, Chakroborty SD, Patel NR. Detailed urban roughness parametrization for anthropogenic heat flux estimation using earth observation data. Heliyon. 2023 Jul 17;9(7):e18361. doi: 10.1016/j.heliyon.2023.e18361. Erratum in: Heliyon. 2023 Sep 10;9(9):e19953. PMID: 37519678; PMCID: PMC10375860</p> </li> </ol>"},{"location":"24sp-microclimate/#gni-abstract","title":"GNI Abstract","text":"<p>https://github.com/kastnerp/Abstract-GNI-Symposium-Microclimate</p>"},{"location":"24sp-microclimate/#gni-data-processing","title":"GNI Data Processing","text":"<p>https://github.com/kastnerp/GNI-Microclimate-Paper</p>"},{"location":"24sp-mobility-pei/","title":"Pedestrian Environment Index (PEI) Documentation","text":"<p>The Pedestrian Environment Index (PEI) is a composite measure of walkability that combines four key subindices to evaluate pedestrian-friendly environments.</p>"},{"location":"24sp-mobility-pei/#core-subindices","title":"Core Subindices","text":"<ol> <li>Population Density Index (PDI)</li> <li>Measures residential population density within defined areas</li> <li>Data sourced from Census block groups</li> <li> <p>Implementation: <code>PDI_generator.ipynb</code></p> </li> <li> <p>Commercial Density Index (CDI)</p> </li> <li>Evaluates density of commercial establishments per Block Group</li> <li>Indicates availability of walkable destinations and services</li> <li> <p>Implementation: <code>CDI_generator.ipynb</code></p> </li> <li> <p>Intersection Density Index (IDI)</p> </li> <li>Quantifies intersection density within an area</li> <li>Evaluates route options and pedestrian safety</li> <li> <p>Implementation: <code>IDI_generator.ipynb</code></p> </li> <li> <p>Land-use Diversity Index (LDI)</p> </li> <li>Analyzes mix of land-use types (residential, commercial, industrial)</li> <li>Assesses environment walkability through land use diversity</li> <li>Implementation: <code>LDI_generator.ipynb</code></li> </ol>"},{"location":"24sp-mobility-pei/#implementation-workflow","title":"Implementation Workflow","text":"<ol> <li>Subindex Calculation</li> <li>Individual Jupyter notebooks (<code>*_generator.ipynb</code>) process Census block group shapefiles</li> <li>Each generator computes its respective subindex score</li> <li> <p>Outputs saved as CSV or GeoJSON files</p> </li> <li> <p>PEI Compilation</p> </li> <li><code>PEI_generator.ipynb</code> combines subindex outputs</li> <li> <p>Computes final PEI score for each block group</p> </li> <li> <p>Visualization</p> </li> <li>Results displayed as geographic maps</li> <li>PEI scores visualized across census block groups</li> </ol> <p>Note: Project is transitioning to standardize all output files to GeoJSON format.</p>"},{"location":"24sp-mobility-pei/#detailed-index-methodologies","title":"Detailed Index Methodologies","text":""},{"location":"24sp-mobility-pei/#commercial-density-index-cdi","title":"Commercial Density Index (CDI)","text":""},{"location":"24sp-mobility-pei/#overview","title":"Overview","text":"<p>Calculates amenity counts per block group, normalized against the region's maximum commercial density.</p>"},{"location":"24sp-mobility-pei/#input-data","title":"Input Data","text":"<ul> <li>Source: <code>atl_bg.geojson</code></li> <li>Contains Atlanta neighborhood data</li> <li>Uses OSMNx for amenity quantification</li> </ul>"},{"location":"24sp-mobility-pei/#amenity-categories","title":"Amenity Categories","text":"<ul> <li>Groceries: supermarket, convenience, grocery, food, organic</li> <li>Restaurants: restaurant, cafe, food_court, bistro, fast_food</li> <li>Banks: bank, atm</li> <li>Schools: school, college, university, kindergarten, music_school, language_school, driving_school</li> <li>Entertainment: cinema, theatre, nightclub, casino, arts_centre, sports_centre, stadium, amusement_arcade, dance, bowling_alley, attraction, theme_park, zoo</li> <li>Parks: recreation_ground, grass, greenfield</li> </ul>"},{"location":"24sp-mobility-pei/#output","title":"Output","text":"<p>Normalized commercial density values relative to regional maximum</p>"},{"location":"24sp-mobility-pei/#intersection-density-index-idi","title":"Intersection Density Index (IDI)","text":""},{"location":"24sp-mobility-pei/#overview_1","title":"Overview","text":"<p>Analyzes intersection patterns within block groups to evaluate street connectivity.</p>"},{"location":"24sp-mobility-pei/#input-requirements","title":"Input Requirements","text":"<ul> <li>GeoJSON file containing:</li> <li>Block group geometries</li> <li>State and county FIPS codes</li> </ul>"},{"location":"24sp-mobility-pei/#output-data-csv","title":"Output Data (CSV)","text":"<ul> <li>Polygon: Block group geometry</li> <li>Area: Block group area</li> <li>Intersection: Sum of intersection-connected roads</li> <li>IDI: Normalized intersection density value</li> </ul>"},{"location":"24sp-mobility-pei/#processing-steps","title":"Processing Steps","text":"<ol> <li>Read GeoJSON geometry data</li> <li>Extract intersection data via OSMNx</li> <li>Calculate equivalency factors</li> <li>Compute population density</li> <li>Generate visualization-ready output</li> </ol>"},{"location":"24sp-mobility-pei/#land-diversity-index-ldi","title":"Land Diversity Index (LDI)","text":""},{"location":"24sp-mobility-pei/#overview_2","title":"Overview","text":"<p>Evaluates land use diversity within block groups.</p>"},{"location":"24sp-mobility-pei/#input-requirements_1","title":"Input Requirements","text":"<ul> <li>GeoJSON file containing:</li> <li>Block group geometries</li> <li>State and county FIPS codes</li> </ul>"},{"location":"24sp-mobility-pei/#output-data-csv_1","title":"Output Data (CSV)","text":"<ul> <li>Polygon: Block group geometry</li> <li>Land_use_dict: Land use type areas</li> <li>Entropy: Block entropy value</li> <li>LDI: Normalized land diversity value</li> </ul>"},{"location":"24sp-mobility-pei/#processing-steps_1","title":"Processing Steps","text":"<ol> <li>Extract GeoJSON geometry</li> <li>Gather land use data via OSMNx</li> <li>Calculate block entropy</li> <li>Compute land diversity</li> <li>Prepare visualization data</li> </ol>"},{"location":"24sp-mobility-pei/#population-density-index-pdi","title":"Population Density Index (PDI)","text":""},{"location":"24sp-mobility-pei/#overview_3","title":"Overview","text":"<p>Processes Census Bureau population data to calculate density metrics.</p>"},{"location":"24sp-mobility-pei/#input-requirements_2","title":"Input Requirements","text":"<ul> <li>GeoDataFrame with:</li> <li>Block group geometries</li> <li>State/county FIPS codes</li> <li>Census API key (from parameter or <code>census_api_key.txt</code>)</li> </ul>"},{"location":"24sp-mobility-pei/#output-data-geodataframe","title":"Output Data (GeoDataFrame)","text":"<ul> <li>POP: Block group population</li> <li>POPDENSITY: Persons per square kilometer</li> <li>NORMPOPDENSITY: Normalized population density</li> </ul>"},{"location":"24sp-mobility-pei/#processing-steps_2","title":"Processing Steps","text":"<ol> <li>Validate API credentials</li> <li>Extract FIPS codes</li> <li>Retrieve Census data</li> <li>Integrate population data</li> <li>Calculate density metrics</li> <li>Clean and format output</li> </ol>"},{"location":"24sp-mobility-pei/#error-handling","title":"Error Handling","text":"<p>Raises ValueError if Census API key is unavailable</p>"},{"location":"24sp-mobility-seg/","title":"Segregation in the 15-Minute City","text":""},{"location":"24sp-mobility-seg/#introduction","title":"Introduction","text":"<p>This notebook focuses on the concept of the 15-minute city and investigates segregation on a basis of mobility. In this notebook, 15-minute usage is defined as the proportion of consumption-related trips made within a 15-minute walk from a home. 15-minute access is defined as the number of essential amenities within the 15-minute walk from a home. Segregation is examined within this context to measure and assess the distribution of amenities within urban areas.</p>"},{"location":"24sp-mobility-seg/#notebook-summary","title":"Notebook Summary","text":"<p>This project includes procedures for loading, analyzing, processing, then modeling mobility and segregation density within a defined 15-minute city. The process includes:</p> <ol> <li>Data loading and initial analysis.</li> <li>Define 15-minute city parameters for the given dataset.</li> <li>Identifying data file tags to define residents, streets, amenities, and places of work.</li> <li>Calculate routes between coordinates of residents and amenities through the shortest path profile.</li> <li>Project a grid of points to routes.</li> <li>Estimate populations in provided buildings.</li> <li>Interpret relations between routes and intersection density (segregation) with populations weighted.</li> <li>Calculate and model final data normalized with heatmap through Grasshopper and Rhino.</li> </ol>"},{"location":"24sp-mobility-seg/#usage","title":"Usage","text":"<p>The notebook is structured to be followed sequentially. Detailed comments and markdown notes guide through each step of the analysis and modeling process.</p> <p></p>"},{"location":"24sp-mobility-seg/#models-and-algorithms-used","title":"Models and Algorithms Used","text":"<ul> <li>Kernel Densities</li> <li>Space-Time Prisms</li> <li>Volumetric Population Estimation</li> <li>Vehicle Profile Routing (Itinero)</li> </ul>"},{"location":"24sp-mobility-seg/#data-description","title":"Data Description","text":"<p>Densities for segregation are calculated and output through the heatmap weighted by population. In Rhino, the heatmap overlays a segment of data from OSM that will display darker blue for greater density and red for lower. Aggregated results can be generated through dataset and certain amenity types to compare the average encounter densities.</p>"},{"location":"24sp-mobility-seg/#key-findings-and-observations","title":"Key Findings and Observations","text":"<ul> <li>Kernel densities allow for a simple calculation of segregation under the definition of interaction between pedestrians in a defined 15-minute city</li> <li>Volumetric Method with building area, building height, and census population provides general estimate for populations with data from https://opendata.atlantaregional.com/</li> <li>Potential for interaction is best calculated through space-time prisms which are more accurately representing spatial and temporal dynamics and constraints</li> <li>Increased local usage correlates with higher experienced segregation for low-income residents.</li> </ul>"},{"location":"24sp-mobility-seg/#conclusions","title":"Conclusions","text":"<p>This notebook serves as a detailed example of using methods within provided data and activity spaces to calculate segregation values for a 15-minute city. The methodologies outlined here can be adapted and expanded for other types of assessment for pedestrian mobility and accessibility.</p>"},{"location":"24sp-mobility-seg/#references","title":"References","text":"<ul> <li>Abbiasov, et al. (2024) The 15-minute city quantified using human mobility data.</li> <li>Patterson &amp; Farber (2015) Potential Path Areas and Activity Spaces in Application: A Review</li> <li>Sch\u00f6nfelder (2002) Measuring the size and structure of human activity spaces: The longitudinal perspective.</li> </ul>"},{"location":"24sp-mobility-seg/#itinero","title":"Itinero","text":""},{"location":"24sp-mobility-seg/#overview","title":"Overview","text":"<p>Itinero is a flexible open-source routing engine for a variety of transportation modes such as walking, cycling, and driving. It provides sophisticated tools to integrate customizable routing solutions into their applications, enabling efficient navigation. Itinero emphasizes versatility, offering support for various map data formats and allowing customization to suit specific needs. Most importantly, features like offline routing and routing across multiple transportation modes are provided. For the sake of this project, the pedestrian shortest path profile is utilized to calculate and map routes for individuals within the city.</p>"},{"location":"24sp-mobility-seg/#repository","title":"Repository","text":"<p>Itinero Routing</p>"},{"location":"24sp-mobility-seg/#features","title":"Features","text":"<ul> <li>Routing: The Router uses the RouterDb data to calculate routes for a given Profile. It starts and ends the Route at a RouterPoint.</li> <li>RouterDb: Contains the routing network, all meta-data, restrictions and so on.</li> <li>Profile: Defines vehicles and their behaviour.</li> <li>RouterPoint: A location on the routing network to use as a start or endpoint of a route.</li> <li>Router: The router is where you ask for routes.</li> <li>GeoJSON Conversion: Export calculated routing to GeoJSON for use in mapping and other geospatial applications.</li> <li>Open Street Maps Data Retrieval: Automatically download street and building data required for demand calculations.</li> </ul>"},{"location":"24sp-mobility-seg/#getting-started","title":"Getting Started","text":"<p>To start using Itinero, follow these steps: 1. Install following Itinero packages to .NET project:     - Itinero: The Itinero routing core, this is usually the only package you need to install.     - Itinero.Geo: This package ensures compatibility with NTS.     -   Itinero.IO.Osm: This package contains code to load OSM data.     -   Itinero.IO.Shape: This package contains code to load data from shapefiles. 2. Specify OSM file as needed 3. Run project through determined routing coordinates</p>"},{"location":"24sp-mobility-seg/#data-requirements","title":"Data Requirements","text":"<ul> <li>Street data should include both OSM or FEMA tag attributes for project defined amenities and places of work</li> <li>Open Street Maps (OSM): amenities and workplaces</li> <li>Federal Emergency Management Agency (FEMA): residentials</li> </ul>"},{"location":"24sp-mobility-seg/#credits","title":"Credits","text":"<p>Itinero is open-source and commercially supported, developed by the Itinero BVBA team. Itinero was built using OpenStreetMap</p>"},{"location":"24sp-mobility-seg/#future-work","title":"Future Work","text":"<ul> <li>Integrate temporal layer to find effective rates of encounter between pedestrians.</li> <li>Generate daily routines to represent more realistic behavior.</li> <li>Normalization of results to allow comparisons across sites with different total populations.</li> </ul>"}]}